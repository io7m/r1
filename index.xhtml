<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>io7m-r1 0.10.0 Documentation</title><link rel="stylesheet" type="text/css" href="jstructural-2.0.0-layout.css"/><link rel="stylesheet" type="text/css" href="jstructural-2.0.0-colour.css"/><link rel="stylesheet" type="text/css" href="documentation.css"/></head><body><div class="st200_body"><div class="brand">
  <div class="brand_left">
    <a href="http://io7m.com/">io7m</a>
  </div>
  <div class="brand_right">
    <a href="http://mvn.io7m.com/io7m-r1/">io7m-r1</a> 0.10.0
  </div>
</div><div class="st200_document_title">io7m-r1 0.10.0 Documentation</div><ul class="st200_contents st200_document_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_part"><a href="#st200_p1">1. Package Information</a><ul class="st200_contents st200_part_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p1s1">1.1. Orientation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p1s2">1.2. Installation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p1s3">1.3. Platform Specific Issues</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p1s4">1.4. License</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_part"><a href="#st200_p2">2. Design and Implementation</a><ul class="st200_contents st200_part_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s1">2.1. Conventions</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s2">2.2. Concepts</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s3">2.3. Coordinate systems</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s4">2.4. Rendering Process</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s5">2.5. Materials</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s6">2.6. Regular Materials</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s7">2.7. Depth Materials</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s8">2.8. Meshes</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s9">2.9. Transforms</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s10">2.10. Instances</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s11">2.11. Visible Sets</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s12">2.12. Deferred Rendering</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s13">2.13. Deferred Rendering: Position Reconstruction</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s14">2.14. Logarithmic Depth</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s15">2.15. Forward Rendering (Translucents)</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s16">2.16. Normal Mapping</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s17">2.17. Environment Mapping</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s18">2.18. Lighting</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s19">2.19. Directional Lighting</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s20">2.20. Spherical Lighting</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s21">2.21. Projective Lighting</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s22">2.22. Shadows</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s23">2.23. Shadow mapping - Basic</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s24">2.24. Shadow mapping - Variance</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s25">2.25. Generic Refraction</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s26">2.26. Filter: Blur</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s27">2.27. Filter: Emission</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s28">2.28. Filter: FXAA</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s29">2.29. Filter: Z Fog</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p2s30">2.30. Filter: Y Fog</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_part"><a href="#st200_p3">3. API Reference</a><ul class="st200_contents st200_part_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_section"><a href="#st200_p3s1">3.1. Javadoc</a></li></ul></li></ul><div class="st200_part_container"><div class="st200_part_title_number"><a id="st200_p1" href="#st200_p1">1</a></div><div class="st200_part_title">Package Information</div><ul class="st200_contents st200_part_contents_outer st200_part_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p1s1">1.1. Orientation</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p1s1ss1">1.1.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p1s1ss2">1.1.2. Features</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p1s1ss3">1.1.3. Non-features</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p1s2">1.2. Installation</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p1s2ss1">1.2.1. Source compilation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p1s2ss2">1.2.2. Maven</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p1s3">1.3. Platform Specific Issues</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p1s4">1.4. License</a></li></ul><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p1s1" href="#st200_p1s1">1.1</a></div><div class="st200_section_title">Orientation</div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p1s1ss1" href="#st200_p1s1ss1">1.1.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s1ss1pg1" href="#st200_p1s1ss1pg1">1</a></div><div class="st200_paragraph">
          The <span class="st200_term package">io7m-r1</span> package 
          implements an aggressively minimalist 3D renderer.
        </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p1s1ss2" href="#st200_p1s1ss2">1.1.2</a></div><div class="st200_subsection_title">Features</div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p1s1ss2fo1" href="#st200_p1s1ss2fo1">1.1.2.1. Features</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
              A <span class="st200_term term">deferred rendering</span> core for 
              <span class="st200_term term">opaque</span> objects.
            </li><li class="st200_list_item">
              A <span class="st200_term term">forward renderer</span>, supporting
              a subset of the features of the 
              <span class="st200_term term">deferred renderer</span>, for 
              rendering <span class="st200_term term">translucent</span> objects.
            </li><li class="st200_list_item">
              A full dynamic lighting system, including both
              <span class="st200_term term">basic</span> and
              <span class="st200_term term">variance</span> shadow mapping. The use
              of <span class="st200_term term">deferred rendering</span> allows for
              potentially hundreds of dynamic lights per scene.
            </li><li class="st200_list_item">
              A detailed material system, allowing for artists and developers
              to create surfaces with a wide variety of effects such as 
              <span class="st200_term term">normal mapping</span>,
              <span class="st200_term term">environment-mapped reflections</span>,
              <span class="st200_term term">generic refraction</span>,
              <span class="st200_term term">surface emission</span>,
              <span class="st200_term term">mapped specular highlights</span>, etc,
              without writing a single line of shader code. All materials are
              immutable but are created via simple mutable builders in code, and so
              are effectively dynamic
                <span class="st200_footnote_reference"><a id="st200_fn_0_ref" href="#st200_fn_0">[0]</a></span>.
            </li><li class="st200_list_item">
              A variety of postprocessing effects such as 
              <span class="st200_term term">box blurring</span>, 
              <span class="st200_term term">fast approximate antialiasing (FXAA)</span>,
              <span class="st200_term term">color correction</span>,
              <span class="st200_term term">bloom</span>, etc.
              Effects can be applied in any order.
            </li><li class="st200_list_item">
              Explicit control over all resource loading and caching. For
              all <span class="st200_term term">transient</span> resources
              <span class="st200_footnote_reference"><a id="st200_fn_1_ref" href="#st200_fn_1">[1]</a></span>, the
              programmer is required to provide the renderer with explicit 
              <span class="st200_term term">caches</span>, and the caches themselves
              are responsible for allocating and loading resources.
            </li><li class="st200_list_item">
              Extensive use of immutable objects for the purposes of correctness.
              One of the driving design concepts is that the programmer passes
              an immutable "snapshot" of the scene to be rendered to a rendering
              function, and that rendering function will always return the same
              image for that snapshot.
            </li><li class="st200_list_item">
              Simplicity. The implementation consists of a few thousand shaders
              generated at compile-time from the Java <span class="st200_term term">material</span> 
              and <span class="st200_term term">light</span> types defined in the renderer's
              API. All of the usual bugs that plague programmers using 3D renderers that
              directly expose shaders (such as passing incorrect parameters to shaders,
              forgetting to pass required parameters, etc), are simply not present. The
              system knows every possible <span class="st200_term term">light</span> and
              <span class="st200_term term">material</span> combination, statically, and
              knows how to pass the right parameters to the shaders that implement them.
              The programmer doesn't have to worry about it.
            </li><li class="st200_list_item">
              Extensive use of static types. As with all
              <a class="st200_link_external" href="http://io7m.com">io7m</a> packages,
              there is extreme emphasis on using the type system to make it difficult to
              use the APIs incorrectly.
            </li><li class="st200_list_item">
              Portability. The renderer will run on any system supporting either
              OpenGL <span class="st200_term constant">&gt;= 3.0</span> or
              OpenGL ES <span class="st200_term constant">&gt;= 3</span>.
            </li></ul></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p1s1ss3" href="#st200_p1s1ss3">1.1.3</a></div><div class="st200_subsection_title">Non-features</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s1ss3pg1" href="#st200_p1s1ss3pg1">1</a></div><div class="st200_paragraph">
          The intention of the <span class="st200_term package">io7m-r1</span> 
          package is to essentially expose an advanced <span class="st200_term term">fixed-function</span>
          rendering pipeline that just happens to provide all of the advanced rendering
          techniques expected of a modern computer game. Features specifically not implemented
          by the package include:
        </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p1s1ss3fo1" href="#st200_p1s1ss3fo1">1.1.3.1. Non-features</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
              A scene graph. The renderer expects the programmer to provide
              a set of <span class="st200_term term">instances</span> (with associated
              <span class="st200_term term">materials</span>) and 
              <span class="st200_term term">lights</span> once per frame, and the
              renderer will obediently draw exactly those instances. This frees
              the programmer from having to interact with a clumsy and type-unsafe
              "object-oriented" scene graph as with other 3D engines, and from 
              having to try to crowbar their own program's data structures into 
              an existing graph system.
            </li><li class="st200_list_item">
              Spatial partitioning. The renderer knows nothing of the world
              the programmer is trying to render. The programmer is expected to
              have done the work of deciding which <span class="st200_term term">instances</span>
              and <span class="st200_term term">lights</span> contribute to the current
              image, and to provide only those <span class="st200_term term">lights</span>
              and <span class="st200_term term">instances</span> for the current frame.
              This means that the programmer is free to use any spatial
              partitioning system desired.
            </li><li class="st200_list_item">
              Input handling. The renderer knows nothing about keyboards, mice, joysticks.
              The programmer passes an immutable snapshot of a scene to the renderer, and
              the renderer returns an image. This means that the programmer is free to use any 
              input system desired without having to painfully integrate their own code with
              an existing input system as with other 3D engines.
            </li><li class="st200_list_item">
              Audio. The renderer makes images, not sounds. This allows programmers to use
              any audio system they want in their programs.
            </li><li class="st200_list_item">
              Skeletal animation. The input to the renderer is a set of triangle
              <span class="st200_term term">meshes</span> in the form of
              <span class="st200_term term">vertex buffer objects</span>. This means that
              the programmer is free to use any skeletal animation system desired,
              providing that the system is capable of producing 
              <span class="st200_term term">vertex buffer objects</span> of the correct type
              as a result.
            </li><li class="st200_list_item">
              Model loading. The input to the renderer is a set of triangle
              <span class="st200_term term">meshes</span> in the form of
              <span class="st200_term term">vertex buffer objects</span>. This means that
              the programmer is free to use any model loading system desired,
              providing that the system is capable of producing 
              <span class="st200_term term">vertex buffer objects</span> of the correct type
              as a result
                <span class="st200_footnote_reference"><a id="st200_fn_3_ref" href="#st200_fn_3">[3]</a></span>.
            </li><li class="st200_list_item">
              Future proofing. The average lifetime of a rendering system is about
              five years. Due to the extremely rapid pace of advancement in graphics
              hardware, the methods use to render graphics
              <span class="st200_term term">today</span> will bear almost no relation to those
              used five years into the future. The <span class="st200_term package">io7m-r1</span>
              package is under no illusion that it will still be relevant in a decade's
              time. It is designed to get work done <span class="st200_term term">today</span>,
              using exactly those techniques that are relevant <span class="st200_term term">today</span>.
              It will not be indefinitely expanded and grown organically, as this would
              directly contradict the goal of having a 
              <span class="st200_term term">minimalist</span> and <span class="st200_term term">correct</span> 
              rendering system.
            </li><li class="st200_list_item">
              OpenGL ES 2 support. The ES 2 standard was written as a reaction to the
              insane committee politics that plagued the OpenGL 2.* standards. It is
              crippled to the point that it essentially cannot support almost any of
              the rendering techniques present in the 
              <span class="st200_term package">io7m-r1</span> package, and is
              becoming increasingly irrelevant as the much saner ES 3 is adopted by
              hardware vendors.
            </li></ul></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p1s2" href="#st200_p1s2">1.2</a></div><div class="st200_section_title">Installation</div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p1s2ss1" href="#st200_p1s2ss1">1.2.1</a></div><div class="st200_subsection_title">Source compilation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s2ss1pg1" href="#st200_p1s2ss1pg1">1</a></div><div class="st200_paragraph">
          The project can be compiled and installed with
          <a class="st200_link_external" href="http://maven.apache.org">Maven</a>:
        </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s2ss1pg2" href="#st200_p1s2ss1pg2">2</a></div><div class="st200_paragraph">
          <pre class="st200_verbatim example">$ mvn -C clean install</pre>
        </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p1s2ss2" href="#st200_p1s2ss2">1.2.2</a></div><div class="st200_subsection_title">Maven</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s2ss2pg1" href="#st200_p1s2ss2pg1">1</a></div><div class="st200_paragraph">
          Regular releases are made to the
          <a class="st200_link_external" href="http://search.maven.org/#search%7Cga%7C1%7Cio7m-r1">Central Repository</a>,
          so it's possible to use the <span class="st200_term package">io7m-r1</span>
          package in your projects with the following Maven dependency:
        </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s2ss2pg2" href="#st200_p1s2ss2pg2">2</a></div><div class="st200_paragraph">
          <pre class="st200_verbatim example">&lt;dependency&gt;
  &lt;groupId&gt;com.io7m.r1&lt;/groupId&gt;
  &lt;artifactId&gt;io7m-r1-kernel&lt;/artifactId&gt;
  &lt;version&gt;0.10.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
        </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s2ss2pg3" href="#st200_p1s2ss2pg3">3</a></div><div class="st200_paragraph">
          All <a class="st200_link_external" href="http://io7m.com">io7m.com</a>
          packages use Semantic Versioning
          <span class="st200_footnote_reference"><a id="st200_fn_4_ref" href="#st200_fn_4">[4]</a></span>, which implies that it is always safe to use version ranges
          with an exclusive upper bound equal to the next major version - the API of
          the package will not change in a backwards-incompatible manner before the
          next major version.
        </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p1s3" href="#st200_p1s3">1.3</a></div><div class="st200_section_title">Platform Specific Issues</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s3pg1" href="#st200_p1s3pg1">1</a></div><div class="st200_paragraph">
        There are currently no known platform-specific issues.
      </div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p1s4" href="#st200_p1s4">1.4</a></div><div class="st200_section_title">License</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p1s4pg1" href="#st200_p1s4pg1">1</a></div><div class="st200_paragraph">
        All files distributed with the <span class="st200_term package">io7m-r1</span>
        package are placed under the following license:
        <pre class="st200_verbatim license">Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
        </pre>
      </div></div></div></div><div class="st200_part_container"><div class="st200_part_title_number"><a id="st200_p2" href="#st200_p2">2</a></div><div class="st200_part_title">Design and Implementation</div><ul class="st200_contents st200_part_contents_outer st200_part_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s1">2.1. Conventions</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s1ss1">2.1.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s1ss2">2.1.2. Mathematics</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s2">2.2. Concepts</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss1">2.2.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss2">2.2.2. Renderers</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss3">2.2.3. Visible Sets</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss4">2.2.4. Framebuffers</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss5">2.2.5. Meshes</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss6">2.2.6. Transforms</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss7">2.2.7. Camera</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss8">2.2.8. Materials</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss9">2.2.9. Instances</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss10">2.2.10. Lights</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss11">2.2.11. Light groups</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss12">2.2.12. Image Filters</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s2ss13">2.2.13. Image Sources</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s3">2.3. Coordinate systems</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss1">2.3.1. Conventions</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss2">2.3.2. Types</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss3">2.3.3. Object space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss4">2.3.4. World space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss5">2.3.5. Eye space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss6">2.3.6. Clip space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss7">2.3.7. Normalized-device space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s3ss8">2.3.8. Screen space</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s4">2.4. Rendering Process</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s5">2.5. Materials</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s5ss1">2.5.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s5ss2">2.5.2. Types</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s5ss3">2.5.3. Shaders</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s6">2.6. Regular Materials</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss1">2.6.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss2">2.6.2. Albedo Properties</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss3">2.6.3. Emission Properties</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss4">2.6.4. Normal Properties</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss5">2.6.5. Specular Properties</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s6ss6">2.6.6. Environment Properties</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s7">2.7. Depth Materials</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s7ss1">2.7.1. Overview</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s8">2.8. Meshes</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s8ss1">2.8.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s8ss2">2.8.2. Attributes</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s8ss3">2.8.3. Types</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s9">2.9. Transforms</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s9ss1">2.9.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s9ss2">2.9.2. KTransformMatrix4x4</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s9ss3">2.9.3. KTransformOST</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s10">2.10. Instances</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s10ss1">2.10.1. Overview</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s11">2.11. Visible Sets</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s11ss1">2.11.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s11ss2">2.11.2. Batching</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s11ss3">2.11.3. Shadow Geometry</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s12">2.12. Deferred Rendering</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss1">2.12.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss2">2.12.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss3">2.12.3. G-Buffer</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss4">2.12.4. Light Group Stencil</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss5">2.12.5. Normal Compression</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s12ss6">2.12.6. Light Volumes</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s13">2.13. Deferred Rendering: Position Reconstruction</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss1">2.13.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss2">2.13.2. Recovering Eye-space Z</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss3">2.13.3. Recovering Eye-space Z (Logarithmic depth encoding)</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss4">2.13.4. Recovering Eye-space Z (Screen-space depth encoding)</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss5">2.13.5. Recovering Eye-space Position</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s13ss6">2.13.6. Implementation</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s14">2.14. Logarithmic Depth</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s14ss1">2.14.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s14ss2">2.14.2. OpenGL Depth Issues</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s14ss3">2.14.3. Logarithmic Encoding</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s15">2.15. Forward Rendering (Translucents)</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s15ss1">2.15.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s15ss2">2.15.2. Lit</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s15ss3">2.15.3. Unlit</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s16">2.16. Normal Mapping</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s16ss1">2.16.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s16ss2">2.16.2. Tangent Space</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s16ss3">2.16.3. Tangent/Bitangent Generation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s16ss4">2.16.4. Normal Maps</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s16ss5">2.16.5. Rendering With Normal Maps</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s17">2.17. Environment Mapping</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s17ss1">2.17.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s17ss2">2.17.2. Cube Maps</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s17ss3">2.17.3. Reflections</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s17ss4">2.17.4. Handedness</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s18">2.18. Lighting</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s18ss1">2.18.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s18ss2">2.18.2. Diffuse/Specular Terms</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s18ss3">2.18.3. Diffuse-Only Lights</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s18ss4">2.18.4. Attenuation</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s19">2.19. Directional Lighting</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s19ss1">2.19.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s19ss2">2.19.2. Types</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s19ss3">2.19.3. Attenuation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s19ss4">2.19.4. Application</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s20">2.20. Spherical Lighting</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s20ss1">2.20.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s20ss2">2.20.2. Types</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s20ss3">2.20.3. Attenuation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s20ss4">2.20.4. Application</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s20ss5">2.20.5. Shadows</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s21">2.21. Projective Lighting</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss1">2.21.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss2">2.21.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss3">2.21.3. Back projection</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss4">2.21.4. Clamping</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss5">2.21.5. Types</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss6">2.21.6. Attenuation</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss7">2.21.7. Application</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s21ss8">2.21.8. Pseudo-Spherical Lights</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s22">2.22. Shadows</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s22ss1">2.22.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s22ss2">2.22.2. Caching</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s23">2.23. Shadow mapping - Basic</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s23ss1">2.23.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s23ss2">2.23.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s23ss3">2.23.3. Issues</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s23ss4">2.23.4. Types</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s24">2.24. Shadow mapping - Variance</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s24ss1">2.24.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s24ss2">2.24.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s24ss3">2.24.3. Types</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s25">2.25. Generic Refraction</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s25ss1">2.25.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s25ss2">2.25.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s25ss3">2.25.3. Masking</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s25ss4">2.25.4. Vectors</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s25ss5">2.25.5. Color</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s26">2.26. Filter: Blur</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s26ss1">2.26.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s26ss2">2.26.2. Algorithm</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s27">2.27. Filter: Emission</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s27ss1">2.27.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s27ss2">2.27.2. Algorithm</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s28">2.28. Filter: FXAA</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s28ss1">2.28.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s28ss2">2.28.2. Implementation</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s29">2.29. Filter: Z Fog</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s29ss1">2.29.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s29ss2">2.29.2. Algorithm</a></li></ul></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p2s30">2.30. Filter: Y Fog</a><ul class="st200_contents st200_section_contents"><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s30ss1">2.30.1. Overview</a></li><li class="st200_contents_item st200_contents_item2 st200_contents_item_subsection"><a href="#st200_p2s30ss2">2.30.2. Algorithm</a></li></ul></li></ul><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s1" href="#st200_p2s1">2.1</a></div><div class="st200_section_title">Conventions</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s1ss1">2.1.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s1ss2">2.1.2. Mathematics</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s1ss1" href="#st200_p2s1ss1">2.1.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s1ss1pg1" href="#st200_p2s1ss1pg1">1</a></div><div class="st200_paragraph">
      This section attempts to document the mathematical and typographical
      conventions used in the rest of the documentation.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s1ss2" href="#st200_p2s1ss2">2.1.2</a></div><div class="st200_subsection_title">Mathematics</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s1ss2pg1" href="#st200_p2s1ss2pg1">1</a></div><div class="st200_paragraph">
      Rather than rely on untyped and ambiguous mathematical notation, this
      documentation expresses all mathematics in strict
      <a class="st200_link_external" href="http://www.haskell.org/onlinereport/haskell2010/">Haskell 2010</a>
      with no extensions. All Haskell sources are included along with
      the documentation and can therefore be executed from the command
      line <a class="st200_link_external" href="http://www.haskell.org/haskellwiki/GHC/GHCi">GHCi</a>
      tool in order to interactively check results and experiment with
      functions.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s1ss2pg2" href="#st200_p2s1ss2pg2">2</a></div><div class="st200_paragraph">
      When used within prose, functions are referred to using fully qualified 
      notation, such as 
      <span class="st200_term expression">(Vector3f.cross n t)</span>. This
      is the application of the <span class="st200_term function">cross</span> function
      defined in the <a class="st200_link_external" href="haskell/Vector3f.hs">Vector3f</a>
      module, to the arguments <span class="st200_term variable">n</span> and
      <span class="st200_term variable">t</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s1ss2pg3" href="#st200_p2s1ss2pg3">3</a></div><div class="st200_paragraph">
      Formal examples and definitions, however, will typically be defined
      within their own modules, possibly with import statements used to allow 
      for shorter names. As an example
      [<a class="st200_link_external" href="haskell/LightDiffuse.hs">LightDiffuse.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s1ss2fo1" href="#st200_p2s1ss2fo1">2.1.2.1. Diffuse light</a></div><pre class="st200_verbatim">module LightDiffuse where

import qualified Color3
import qualified Direction
import qualified Normal
import qualified Spaces
import qualified Vector3f

diffuse ::  Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Vector3f.T
diffuse stl n light_color light_intensity =
  let 
    factor       = max 0.0 (Vector3f.dot3 stl n)
    light_scaled = Vector3f.scale light_color light_intensity
  in 
    Vector3f.scale light_scaled factor</pre></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s2" href="#st200_p2s2">2.2</a></div><div class="st200_section_title">Concepts</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss1">2.2.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss2">2.2.2. Renderers</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss3">2.2.3. Visible Sets</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss4">2.2.4. Framebuffers</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss5">2.2.5. Meshes</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss6">2.2.6. Transforms</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss7">2.2.7. Camera</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss8">2.2.8. Materials</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss9">2.2.9. Instances</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss10">2.2.10. Lights</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss11">2.2.11. Light groups</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss12">2.2.12. Image Filters</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s2ss13">2.2.13. Image Sources</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss1" href="#st200_p2s2ss1">2.2.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss1pg1" href="#st200_p2s2ss1pg1">1</a></div><div class="st200_paragraph">
      This section attempts to provide a rough overview of the concepts
      present in the <span class="st200_term package">io7m-r1</span> package.
      Specific implementation details, mathematics, and other technical information
      is given in later sections that focus on each concept in detail.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss2" href="#st200_p2s2ss2">2.2.2</a></div><div class="st200_subsection_title">Renderers</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss2pg1" href="#st200_p2s2ss2pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      consists of a set of <span class="st200_term term">renderers</span>. A
      <span class="st200_term term">renderer</span> consumes an immutable
      <a class="st200_link" href="#st200_p2s2ss3">visible set</a>
      and produces an image, writing the image to a given
      <a class="st200_link" href="#st200_p2s2ss4">framebuffer</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss2pg2" href="#st200_p2s2ss2pg2">2</a></div><div class="st200_paragraph">
      The renderers expose
      an interface of <span class="st200_term term">conceptually</span> pure 
      functions from visible sets to images. That is, the renderers should be
      considered to simply take visible sets as input and return images as output.
      In reality, because the Java language is not pure and because the code
      is required to perform I/O in order to speak to the GPU, the renderer
      functions are not <span class="st200_term term">really</span> pure. Nevertheless,
      for the sake of ease of use, lack of surprising results, and correctness,
      the renderers at least attempt to adhere to the idea of pure functional
      rendering! This means that the renderers are very easy to integrate into
      any existing system: They are simply functions that are evaluated whenever
      the programmer wants an image. The renderers do not have their own "main loop",
      they do not have any concept of time, do not remember any images that they
      have produced previously, do not maintain any state of their own,
      and simply write their results to a programmer-provided 
      <a class="st200_link" href="#st200_p2s2ss4">framebuffer</a>.
      Passing the same immutable visible set to a renderer multiple times should 
      result in the same image each time.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss3" href="#st200_p2s2ss3">2.2.3</a></div><div class="st200_subsection_title">Visible Sets</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss3pg1" href="#st200_p2s2ss3pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">visible set</span> is an immutable snapshot
      of all <a class="st200_link" href="#st200_p2s2ss9">instances</a>
      and <a class="st200_link" href="#st200_p2s2ss10">lights</a>
      that contribute to an image. The name implies that a renderer expects to 
      receive only those instances and lights that are actually visible from the 
      perspective of the observer. This is a conscious design decision that frees 
      the renderer from the complicated task of trying to decide which objects are visible and
      which are not. A programmer using the renderer is expected to be using
      some sort of spatial partitioning data structure
        <span class="st200_footnote_reference"><a id="st200_fn_5_ref" href="#st200_fn_5">[5]</a></span>
      to efficiently decide
      which objects are visible for the current rendering call. This is essentially
      the same approach taken by the OpenGL API: The API draws what it is told to draw,
      and does not try (beyond clipping primitives based on the viewing frustum), to
      intelligently decide what should and should not be drawn.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss4" href="#st200_p2s2ss4">2.2.4</a></div><div class="st200_subsection_title">Framebuffers</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss4pg1" href="#st200_p2s2ss4pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">framebuffer</span> is a
      rectangular region of memory allocated on the GPU that can accept 
      the results of rendering.
      The programmer typically allocates one framebuffer, passes it to
      a <span class="st200_term term">renderer</span> along with a
      <a class="st200_link" href="#st200_p2s2ss3">visible set</a>,
      and the renderer populates the given framebuffer with an image
      of the rendered visible set. The programmer can then copy the contents of
      this framebuffer to the screen for viewing, pass it on to a separate
      <a class="st200_link" href="#st200_p2s2ss12">filter</a>
      for extra visual effects, use it as a texture to be applied to objects
      in further rendered visible sets, etc.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss5" href="#st200_p2s2ss5">2.2.5</a></div><div class="st200_subsection_title">Meshes</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss5pg1" href="#st200_p2s2ss5pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">mesh</span> is a collection of vertices 
      that define a polyhedral object, along with a list of indices
      that describe how to make triangles out of the given vertices.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss5pg2" href="#st200_p2s2ss5pg2">2</a></div><div class="st200_paragraph">
      Meshes are allocated on the GPU and can be shared between any number
      of <a class="st200_link" href="#st200_p2s2ss9">instances</a> (meaning
      that rendering 100 identical objects does not require storing 100 copies
      of the mesh data).
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss6" href="#st200_p2s2ss6">2.2.6</a></div><div class="st200_subsection_title">Transforms</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss6pg1" href="#st200_p2s2ss6pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">transform</span> moves coordinates in
      one <a class="st200_link" href="#st200_p2s3">coordinate space</a>
      to another. Essentially, a transform is used to position and orient a
      <a class="st200_link" href="#st200_p2s2ss5">mesh</a> inside
      a <span class="st200_term term">visible set</span>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss7" href="#st200_p2s2ss7">2.2.7</a></div><div class="st200_subsection_title">Camera</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss7pg1" href="#st200_p2s2ss7pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">camera</span> defines both the
      <span class="st200_term term">viewing position</span> and
      <span class="st200_term term">viewing projection</span> for the
      visible set. The <span class="st200_term term">viewing projection</span>
      describes the <span class="st200_term term">orthographic</span>
      or <span class="st200_term term">perspective</span> projection used to
      render the visible set, and the <span class="st200_term term">viewing position</span>
      is used to <a class="st200_link" href="#st200_p2s2ss6">transform</a>
      all instances and lights in the visible set to
      <a class="st200_link" href="#st200_p2s3ss5">eye-space</a>
      during rendering. The camera is represented by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KCamera.html">KCamera</a>
      type.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss7pg2" href="#st200_p2s2ss7pg2">2</a></div><div class="st200_paragraph">
      A visible set always contains a single <span class="st200_term term">camera</span>,
      because, as mentioned earlier, a visible set is supposed to represent the
      instances and lights that are visible from the observation point that
      the camera describes.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss8" href="#st200_p2s2ss8">2.2.8</a></div><div class="st200_subsection_title">Materials</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss8pg1" href="#st200_p2s2ss8pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">material</span> describes the surface properties
      of an object. A <span class="st200_term term">material</span> may either be
      <span class="st200_term term">opaque</span> or
      <span class="st200_term term">translucent</span>. An object with a 
      <span class="st200_term term">opaque</span>
      material completely occludes the pixels of all other objects that appear
      behind it. An object with a <span class="st200_term term">translucent</span>
      material is blended with the objects that appear behind it.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss8pg2" href="#st200_p2s2ss8pg2">2</a></div><div class="st200_paragraph">  
      Materials consist of a multitude
      of different properties describing different aspects of the surface. For example,
      most opaque materials have data describing all of the following:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss8fo1" href="#st200_p2s2ss8fo1">2.2.8.1. Opaque material data</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          The surface <span class="st200_term term">albedo</span>;  
          the basic color of the surface prior to any lighting.
        </li><li class="st200_list_item">
          The surface <span class="st200_term term">depth</span> properties;  
          to give per-pixel control over "transparency" without requiring
          the overhead of making the material translucent.
        </li><li class="st200_list_item">
          The surface <span class="st200_term term">emissive</span> properties;  
          to present the illusion of surfaces emitting light.
        </li><li class="st200_list_item">
          The surface <span class="st200_term term">environment</span> properties;  
          to provide environment-mapped reflections and other effects.
        </li><li class="st200_list_item">
          The surface <span class="st200_term term">normal</span> properties;  
          to provide per-pixel control of surface normal vectors ("normal mapping").
        </li><li class="st200_list_item">
          The surface <span class="st200_term term">specular</span> properties;  
          to provide per-pixel control of surface specularity.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss8pg3" href="#st200_p2s2ss8pg3">3</a></div><div class="st200_paragraph">
      An extremely trivial material (with a simple red albedo and no other properties) 
      applied to a square, lit by a directional light:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss8fo2" href="#st200_p2s2ss8fo2">2.2.8.2. Material with plain red albedo</a></div><img class="st200_image" alt="Plain red albedo" src="images/albedo_red.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss8pg4" href="#st200_p2s2ss8pg4">4</a></div><div class="st200_paragraph">
      A complex material (with mapped normals, specular highlights, an environment map, and a textured albedo) 
      applied to the same square, lit by a spherical light:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss8fo3" href="#st200_p2s2ss8fo3">2.2.8.3. Complex material</a></div><img class="st200_image" alt="Complex material" src="images/material_complex.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss8pg5" href="#st200_p2s2ss8pg5">5</a></div><div class="st200_paragraph">
      Materials are immutable once created, but are created through the use
      of mutable builder types. This allows renderers to effectively support
      "animated" materials without actually needing to know anything about them; 
      the renderers see ordinary immutable materials, but the programmer is supplying
      new materials each time the renderer is called, giving the illusion that one 
      material is changing over time. As an example, the type of builders for 
      opaque materials is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialOpaqueBuilderType.html">KMaterialOpaqueBuilderType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss9" href="#st200_p2s2ss9">2.2.9</a></div><div class="st200_subsection_title">Instances</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss9pg1" href="#st200_p2s2ss9pg1">1</a></div><div class="st200_paragraph">
      An <span class="st200_term term">instance</span> is essentially
      a reference to a <a class="st200_link" href="#st200_p2s2ss5">mesh</a>,
      a <a class="st200_link" href="#st200_p2s2ss6">transform</a> (to
      position that mesh in the visible set), and a
      <a class="st200_link" href="#st200_p2s2ss8">material</a> to define
      the appearance of the mesh surface.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss10" href="#st200_p2s2ss10">2.2.10</a></div><div class="st200_subsection_title">Lights</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss10pg1" href="#st200_p2s2ss10pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">light</span> describes a light source
      within a visible set. There are many different types of lights, each
      with different behaviours. Lights may or may not cast shadows,
      depending on their type. All lighting in the 
      <span class="st200_term package">io7m-r1</span> package
      is completely dynamic; there is no support for static lighting
      in any form. Shadows are exclusively provided via
      <span class="st200_term term">shadow-mapping</span>, resulting in
      efficient per-pixel shadows.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss10pg2" href="#st200_p2s2ss10pg2">2</a></div><div class="st200_paragraph">  
      Types of lights include:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss10fo1" href="#st200_p2s2ss10fo1">2.2.10.1. Light types</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightDirectional.html">KLightDirectional</a>
          - a <span class="st200_term term">directional</span> light that 
          simulates parallel light rays without any origin.
          Directional lights cannot cast shadows (because directional lights do not have origins).
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereWithoutShadow.html">KLightSphereWithoutShadow</a>
          - a <span class="st200_term term">spherical</span> light. A spherical
          light casts light in all directions from a  given position in 
          world-space, up to a given 
          <span class="st200_term term">radius</span>. The emitted light is
          attenuated over distance based on a configurable 
          <span class="st200_term term">falloff</span> value. This type of light
          is often referred to as a <span class="st200_term term">point</span> light
          in other renderers.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithoutShadow.html">KLightProjectiveWithoutShadow</a>
          - a <span class="st200_term term">projective</span> light. 
          A projective light effectively projects a given image onto the
          visible set from a given position in world-space, up to a given 
          <span class="st200_term term">radius</span>. The emitted light is
          attenuated over distance based on a configurable 
          <span class="st200_term term">falloff</span> value.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowBasic.html">KLightProjectiveWithShadowBasic</a>
          - a <span class="st200_term term">projective</span> light that can
          also cast <span class="st200_term term">basic shadows</span>.
          Basic shadows are very cheap to compute, but can suffer from
          aliasing issues (resulting in sharp edges to shadows).
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowVariance.html">KLightProjectiveWithShadowVariance</a>
          - a <span class="st200_term term">projective</span> light that can
          also cast <span class="st200_term term">variance shadows</span>.
          Variance shadows are slightly more expensive to compute than
          <span class="st200_term term">basic shadows</span>, but can be filtered
          by hardware, resulting in attractive soft shadows.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithShadowBasic.html">KLightSpherePseudoWithShadowBasic</a>
          - a <span class="st200_term term">pseudo-spherical</span> light. A 
          pseudo-spherical light behaves like a 
          <span class="st200_term term">spherical</span> light but is emulated via 
          at most six <span class="st200_term term">projective</span> lights 
          arranged such that each light provides a section of the sphere. 
          Individual lights can be enabled and disabled, and the lights can 
          project <span class="st200_term term">basic shadows</span>.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithShadowVariance.html">KLightSpherePseudoWithShadowVariance</a>
          - is to <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithShadowBasic.html">KLightSpherePseudoWithShadowBasic</a>
          as
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowVariance.html">KLightProjectiveWithShadowVariance</a>
          is to
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowBasic.html">KLightProjectiveWithShadowBasic</a>.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereTexturedCubeWithoutShadow.html">KLightSphereTexturedCubeWithoutShadow</a>
          - a <span class="st200_term term">spherical</span> light that projects
          a <span class="st200_term term">cube map</span> in all directions.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss10pg3" href="#st200_p2s2ss10pg3">3</a></div><div class="st200_paragraph">
      As with <a class="st200_link" href="#st200_p2s2ss8">materials</a> 
      (and indeed, all other objects in the <span class="st200_term package">io7m-r1</span> package),
      all lights are immutable once created, but are created through the use
      of mutable builder types. This allows renderers to effectively support
      "animated" lights without actually needing to know anything about them; 
      the renderers see ordinary immutable lights, but the programmer is supplying
      new lights each time the renderer is called, giving the illusion that lights are changing
      over time. As an example, the type of builders for spherical lights
      without shadows is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereWithoutShadowBuilderType.html">KLightSphereWithoutShadowBuilderType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss11" href="#st200_p2s2ss11">2.2.11</a></div><div class="st200_subsection_title">Light groups</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg1" href="#st200_p2s2ss11pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Light groups</span> are a means to partition
      a visible set into separate lighting environments. An 
      <span class="st200_term term">instance</span> belongs to exactly one
      <span class="st200_term term">light group</span>, but a given 
      <span class="st200_term term">light</span> can be placed into any number
      of light groups.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg2" href="#st200_p2s2ss11pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package,
      due to the current state of graphics hardware, implements purely
      <span class="st200_term term">local illumination</span>
      <span class="st200_footnote_reference"><a id="st200_fn_6_ref" href="#st200_fn_6">[6]</a></span>. Because of this,
      when using lights that do not project shadows, it is possible for
      lights to "bleed" through objects that would normally occlude their 
      radiance had the renderer implemented physically correct lighting. As
      an example:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss11fo1" href="#st200_p2s2ss11fo1">2.2.11.1. Room without groups</a></div><img class="st200_image" alt="Room without groups" src="images/room_no_groups.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg3" href="#st200_p2s2ss11pg3">3</a></div><div class="st200_paragraph">
      The visible set contains three lights: A red spherical light 
      <span class="st200_term expression">s0</span> in the left room,
      a white spherical light 
      <span class="st200_term expression">s1</span> in the middle room, 
      and a blue spherical light <span class="st200_term expression">s2</span>
      in the right room. The visible set contains four instances: The left room 
      <span class="st200_term expression">i0</span>,
      the middle room  <span class="st200_term expression">i1</span>, 
      a piece of furniture <span class="st200_term expression">i2</span>
      in the middle room, and the right room <span class="st200_term expression">i3</span>. 
      None of the lights are configured to cast shadows. Note
      that the red and blue lights bleed into the center room as if the two
      dividing walls were not even there! Light groups can help to
      solve this issue (without requiring shadow mapping).
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg4" href="#st200_p2s2ss11pg4">4</a></div><div class="st200_paragraph">
      First, three light groups are created:
      <span class="st200_term expression">g0</span>, 
      <span class="st200_term expression">g1</span>, and
      <span class="st200_term expression">g2</span>. The light
      <span class="st200_term expression">s0</span> and instance
      <span class="st200_term expression">i0</span>, are added to
      <span class="st200_term expression">g0</span>. The light
      <span class="st200_term expression">s1</span> and instances
      <span class="st200_term expression">i1</span> and
      <span class="st200_term expression">i2</span>, are added to
      <span class="st200_term expression">g1</span>. Finally,
      light <span class="st200_term expression">s2</span> and
      instance <span class="st200_term expression">i3</span> are
      added to <span class="st200_term expression">g2</span>. With these
      groups configured, the renderer produces the following image:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s2ss11fo2" href="#st200_p2s2ss11fo2">2.2.11.2. Room with groups</a></div><img class="st200_image" alt="Room with groups" src="images/room_groups.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg5" href="#st200_p2s2ss11pg5">5</a></div><div class="st200_paragraph">
      Instances <span class="st200_term expression">i1</span> and
      <span class="st200_term expression">i2</span> are no longer affected
      by lights <span class="st200_term expression">s0</span> and
      <span class="st200_term expression">s2</span>, and so on. The image
      looks more physically correct, at the expense of having somewhat
      hard transitions between the rooms, without actually having to 
      calculate any shadows
      <span class="st200_footnote_reference"><a id="st200_fn_7_ref" href="#st200_fn_7">[7]</a></span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg6" href="#st200_p2s2ss11pg6">6</a></div><div class="st200_paragraph">
      Light groups can also be used for other miscellaneous visual effects.
      For example, an object in a visible set could be highlighted by placing it
      in its own light group, and adding a strong red directional light
      to that group. No other objects in the visible set would be affected by the
      light and the object would, as a result, be displayed very conspicuously!
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss11pg7" href="#st200_p2s2ss11pg7">7</a></div><div class="st200_paragraph">
      The majority of visible sets will contain only a single light group. They
      are intended to assist with working around the lack of 
      <span class="st200_term term">global illumination</span>, and with 
      implementing specific visual effects.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss12" href="#st200_p2s2ss12">2.2.12</a></div><div class="st200_subsection_title">Image Filters</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss12pg1" href="#st200_p2s2ss12pg1">1</a></div><div class="st200_paragraph">
      An <span class="st200_term term">image filter</span> is similar to a
      <a class="st200_link" href="#st200_p2s2ss2">renderer</a>
      except that it accepts
      a <a class="st200_link" href="#st200_p2s2ss4">framebuffer</a>
      as input
      (as opposed to a <a class="st200_link" href="#st200_p2s2ss3">visible set</a>),
      processes the image in the framebuffer in some manner, and
      then writes the results to an output framebuffer (possibly the same
      as the input framebuffer). It is used to provide visual effects such
      as full-screen <span class="st200_term term">blurring</span>,
      <span class="st200_term term">color-correction</span>, 
      <span class="st200_term term">emission</span>, and
      others.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss12pg2" href="#st200_p2s2ss12pg2">2</a></div><div class="st200_paragraph">
      Typically, an <span class="st200_term term">image filter</span> accepts
      a framebuffer that was populated by a 
      <span class="st200_term term">deferred renderer</span>, and therefore has
      access to much more per-pixel data than a typical image processor. For
      example, for each pixel in the image, a framebuffer from a deferred
      renderer will contain at least the linear
       <span class="st200_term term">depth</span>
      value of that pixel, and the <span class="st200_term term">normal vector</span>
      of the surface at that pixel. If the filter also has access to the
      <span class="st200_term term">viewing projection</span> that was used to produce
      the image, then it can actually efficiently 
      <a class="st200_link" href="#st200_p2s13">reconstruct</a>
      the original <a class="st200_link" href="#st200_p2s3ss5">eye-space</a>
      position of the pixel! This allows for interesting effects
      such as <span class="st200_term term">fog</span> and
      <span class="st200_term term">depth-of-field</span> simulation, that rely on
      knowing the original positions of objects within the visible set - information
      that would not usually be available to a simple image-based filter.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s2ss13" href="#st200_p2s2ss13">2.2.13</a></div><div class="st200_subsection_title">Image Sources</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s2ss13pg1" href="#st200_p2s2ss13pg1">1</a></div><div class="st200_paragraph">
      An <span class="st200_term term">image source</span> is analogous
      to an <a class="st200_link" href="#st200_p2s2ss12">image filter</a>
      that does not take a
      <a class="st200_link" href="#st200_p2s2ss4">framebuffer</a> as
      input. They are usually provided as a convenience (such as conveniently
      populating a framebuffer with a fixed image prior to rendering).
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s3" href="#st200_p2s3">2.3</a></div><div class="st200_section_title">Coordinate systems</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss1">2.3.1. Conventions</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss2">2.3.2. Types</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss3">2.3.3. Object space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss4">2.3.4. World space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss5">2.3.5. Eye space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss6">2.3.6. Clip space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss7">2.3.7. Normalized-device space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s3ss8">2.3.8. Screen space</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss1" href="#st200_p2s3ss1">2.3.1</a></div><div class="st200_subsection_title">Conventions</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg1" href="#st200_p2s3ss1pg1">1</a></div><div class="st200_paragraph">
      This section attempts to describe the mathematical conventions
      that the <span class="st200_term package">io7m-r1</span> package
      uses with respect to coordinate systems. The
      <span class="st200_term package">io7m-r1</span> package generally
      does not deviate from standard OpenGL conventions, and this section does
      not attempt to give a rigorous formal definition of these existing conventions. It
      does however attempt to establish the <span class="st200_term term">naming conventions</span>
      that the package uses to refer to the standard coordinate spaces
      <span class="st200_footnote_reference"><a id="st200_fn_8_ref" href="#st200_fn_8">[8]</a></span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg2" href="#st200_p2s3ss1pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      uses the <a class="st200_link_external" href="http://mvn.io7m.com/io7m-jtensors">jtensors</a>
      package for all mathematical operations on the CPU, and therefore
      shares its conventions with regards to coordinate system handedness.
      Important parts are repeated here, but the documentation for the
      <span class="st200_term package">jtensors</span> package should be inspected
      for details.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg3" href="#st200_p2s3ss1pg3">3</a></div><div class="st200_paragraph">
      Any of the matrix functions that deal with rotations
      assume a right-handed coordinate system. This
      matches the system conventionally used by <a class="st200_link_external" href="http://opengl.org">OpenGL</a> (and most
      mathematics literature). A right-handed coordinate system
      assumes that if the viewer is standing at the origin and
      looking towards negative infinity on the Z axis, then the
      X axis runs horizontally (left towards negative infinity
      and right towards positive infinity), and the Y axis runs
      vertically (down towards negative infinity and up towards
      positive infinity). The following image demonstrates this
      axis configuration:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo1" href="#st200_p2s3ss1fo1">2.3.1.1. Right-handed coordinate system</a></div><img class="st200_image" alt="Right-handed coordinate system" src="images/axes2.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg4" href="#st200_p2s3ss1pg4">4</a></div><div class="st200_paragraph">
      The <span class="st200_term package">jtensors</span> package adheres
      to the convention that a positive rotation around an axis
      represents a counter-clockwise rotation when viewing the
      system along the negative direction of the axis in question.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo2" href="#st200_p2s3ss1fo2">2.3.1.2. Right-handed rotations</a></div><img class="st200_image" alt="Right-handed rotations" src="images/rotations.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg5" href="#st200_p2s3ss1pg5">5</a></div><div class="st200_paragraph">
      The package uses the following matrices to define rotations
      around each axis:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo3" href="#st200_p2s3ss1fo3">2.3.1.3. Rotation of r radians around the X axis</a></div><img class="st200_image" alt="Rotation of r radians around the X axis" src="images/matrix_rx.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo4" href="#st200_p2s3ss1fo4">2.3.1.4. Rotation of r radians around the Y axis</a></div><img class="st200_image" alt="Rotation of r radians around the Y axis" src="images/matrix_ry.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo5" href="#st200_p2s3ss1fo5">2.3.1.5. Rotation of r radians around the Z axis</a></div><img class="st200_image" alt="Rotation of r radians around the Z axis" src="images/matrix_rz.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss1pg6" href="#st200_p2s3ss1pg6">6</a></div><div class="st200_paragraph">
      Which results in the following matrix for rotating <span class="st200_term variable">r</span> radians around the axis given
      by <span class="st200_term constant">(x, y, z)</span>, assuming
      <span class="st200_term variable">s = sin(r)</span> and <span class="st200_term variable">c = cos(r)</span>
      <span class="st200_footnote_reference"><a id="st200_fn_9_ref" href="#st200_fn_9">[9]</a></span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss1fo6" href="#st200_p2s3ss1fo6">2.3.1.6. Rotation of r radians around an arbitrary axis</a></div><img class="st200_image" alt="Rotation of r radians around an arbitrary axis" src="images/rot_matrix.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss2" href="#st200_p2s3ss2">2.3.2</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss2pg1" href="#st200_p2s3ss2pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      uses so-called <span class="st200_term term">phantom type parameters</span>
      to statically indicate the coordinate systems of vectors, and the
      types of transformations that matrices represent. For example, a
      value of type <span class="st200_term expression">RVectorI3F&lt;RSpaceObjectType&gt;</span>
      represents an immutable three-dimension vectors with coordinate 
      specified in <a class="st200_link" href="#st200_p2s3ss3">object space</a>.
      A value of type <span class="st200_term expression">RMatrixI4x4F&lt;RSpaceTransformViewType&gt;</span>
      represents an immutable 4x4 matrix that contains a transformation from
      <a class="st200_link" href="#st200_p2s3ss4">world space</a> to
      <a class="st200_link" href="#st200_p2s3ss5">eye space</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss2pg2" href="#st200_p2s3ss2pg2">2</a></div><div class="st200_paragraph">
      Due to the limited nature of Java's type system, it is obviously
      possible for the programmer to deliberately construct vectors and
      matrices that do not represent valid coordinates or transforms in
      any coordinate space. However, mistakes involving the mixing up
      of coordinate systems are rampant in graphics programming, and
      in practice, the system as implemented catches many of the mistakes
      at compile time.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss2pg3" href="#st200_p2s3ss2pg3">3</a></div><div class="st200_paragraph">
      The package contains the following coordinate system and transform
      indexed types:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss2fo1" href="#st200_p2s3ss2fo1">2.3.2.1. Vector and matrix types</a></div><table class="st200_table" summary="Vector and matrix types"><thead class="st200_table_head"><tr><th class="st200_table_column_name">Type</th><th class="st200_table_column_name">Description</th></tr></thead><tbody class="st200_table_body"><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RMatrixI3x3F.html">RMatrixI3x3F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Immutable 3x3 matrix type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RMatrixI4x4F.html">RMatrixI4x4F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Immutable 4x4 matrix type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RMatrixM4x4F.html">RMatrixM4x4F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Mutable 4x4 matrix type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RMatrixM3x3F.html">RMatrixM3x3F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Mutable 3x3 matrix type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RVectorI2F.html">RVectorI2F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Immutable 2D vector type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RVectorI3F.html">RVectorI3F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Immutable 3D vector type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RVectorI4F.html">RVectorI4F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Immutable 4D vector type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RVectorM3F.html">RVectorM3F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Mutable 3D vector type</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><a class="st200_link_external" href="apidocs/com/io7m/r1/types/RVectorM4F.html">RVectorM4F&lt;T extends RTransformType&gt;</a></td><td class="st200_table_cell">Mutable 4D vector type</td></tr></tbody></table></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss3" href="#st200_p2s3ss3">2.3.3</a></div><div class="st200_subsection_title">Object space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss3pg1" href="#st200_p2s3ss3pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Object space</span> is the local
      coordinate system used to describe the positions of vertices
      in <a class="st200_link" href="#st200_p2s8">meshes</a>. For
      example, a <span class="st200_term term">unit cube</span> with the
      origin placed at the center of the cube would have eight
      vertices with positions expressed as object-space coordinates:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss3fo1" href="#st200_p2s3ss3fo1">2.3.3.1. Unit cube vertices</a></div><pre class="st200_verbatim">cube = {
    (-0.5, -0.5, -0.5),
    ( 0.5, -0.5, -0.5),
    ( 0.5, -0.5,  0.5),
    (-0.5, -0.5,  0.5),
  
    (-0.5,  0.5, -0.5),
    ( 0.5,  0.5, -0.5),
    ( 0.5,  0.5,  0.5),
    (-0.5,  0.5,  0.5)
  }</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss3pg2" href="#st200_p2s3ss3pg2">2</a></div><div class="st200_paragraph">
      In other rendering systems, <span class="st200_term term">object space</span>
      is sometimes referred to as <span class="st200_term term">local space</span>,
      or <span class="st200_term term">model space</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss3pg3" href="#st200_p2s3ss3pg3">3</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">object space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceObjectType.html">RSpaceObjectType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss4" href="#st200_p2s3ss4">2.3.4</a></div><div class="st200_subsection_title">World space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss4pg1" href="#st200_p2s3ss4pg1">1</a></div><div class="st200_paragraph">
      In order to position objects in a scene, they must be
      assigned a <a class="st200_link" href="#st200_p2s2ss6">transform</a>
      that can be applied to each of their 
      <a class="st200_link" href="#st200_p2s3ss3">object space</a> vertices
      to yield absolute positions in so-called 
      <span class="st200_term term">world space</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss4pg2" href="#st200_p2s3ss4pg2">2</a></div><div class="st200_paragraph">
      As an example, if the unit cube described above was
      assigned a transform that moved its origin to
      <span class="st200_term expression">(3, 5, 1)</span>, then its
      object space vertex <span class="st200_term expression">(-0.5, 0.5, 0.5)</span>
      would end up at
      <span class="st200_term expression">(3 + -0.5, 5 + 0.5, 1 + 0.5) = (2.5, 5.5, 1.5)</span>
      in world space.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss4pg3" href="#st200_p2s3ss4pg3">3</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package,
      a <a class="st200_link" href="#st200_p2s2ss6">transform</a> applied
      to an object produces a 4x4
      <span class="st200_term term">model matrix</span>. Multiplying the model matrix
      with the positions of the object space vertices yields vertices in
      world space.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss4pg4" href="#st200_p2s3ss4pg4">4</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">world space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceWorldType.html">RSpaceWorldType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss5" href="#st200_p2s3ss5">2.3.5</a></div><div class="st200_subsection_title">Eye space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg1" href="#st200_p2s3ss5pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Eye space</span> represents the coordinate 
      system of the 
      <a class="st200_link" href="#st200_p2s2ss7">camera</a> of
      a given <a class="st200_link" href="#st200_p2s2ss3">visible set</a>.
      In eye space, the observer is implicitly fixed at the origin
      <span class="st200_term expression">(0.0, 0.0, 0.0)</span> and is
      looking towards infinity in the negative Z direction.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg2" href="#st200_p2s3ss5pg2">2</a></div><div class="st200_paragraph">
      The main purpose of eye space is to simplify
      the mathematics required to implement various algorithms such
      as lighting. The problem with implementing these sorts of
      algorithms in world space is that one must constantly take into
      account the position of the observer (typically by subtracting
      the location of the observer from each set of world space
      coordinates and accounting for any change in orientation of the
      observer). By fixing the orientation of the observer towards 
      negative Z, and the position of the observer at
      <span class="st200_term expression">(0.0, 0.0, 0.0)</span>, and
      by transforming all vertices of all objects into the same system, 
      the mathematics of lighting are greatly simplified.
      The majority of the rendering algorithms used in the
      <span class="st200_term package">io7m-r1</span> package
      are implemented in eye space.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg3" href="#st200_p2s3ss5pg3">3</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package,
      the <a class="st200_link" href="#st200_p2s2ss7">camera</a> produces
      a 4x4 <span class="st200_term term">view matrix</span>. Multiplying 
      the view matrix with any given world space position yields 
      a position in eye space. In practice, the view matrix 
      <span class="st200_term expression">v</span>
      and the current object's model matrix 
      <span class="st200_term expression">m</span> are concatenated (multiplied)
      to produce a <span class="st200_term term">model-view matrix</span>
      <span class="st200_term expression">mv = v * m</span>
      <span class="st200_footnote_reference"><a id="st200_fn_10_ref" href="#st200_fn_10">[10]</a></span>, and <span class="st200_term expression">mv</span> is then
      passed directly to the renderer's
      <span class="st200_term term">vertex shaders</span> to transform the
      current object's vertices
      <span class="st200_footnote_reference"><a id="st200_fn_11_ref" href="#st200_fn_11">[11]</a></span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg4" href="#st200_p2s3ss5pg4">4</a></div><div class="st200_paragraph">
      Additionally, as the <span class="st200_term package">io7m-r1</span> package
      does all lighting in eye space, it's necessary to transform the
      <a class="st200_link" href="#st200_p2s8ss2">object space normal vectors</a>
      given in mesh data to eye space. However, the usual model-view matrix
      will almost certainly contain some sort of translational component and possibly
      a scaling component. Normal vectors are not supposed to be translated; they 
      represent directions! A non-uniform scale applied to an object will also deform the
      normal vectors, making them non-perpendicular to the surface they're associated 
      with:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss5fo1" href="#st200_p2s3ss5fo1">2.3.5.1. Scaling deforms normal vectors</a></div><img class="st200_image" alt="Scaling deforms normal vectors" src="images/normal_deform.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg5" href="#st200_p2s3ss5pg5">5</a></div><div class="st200_paragraph">
      With the scaled triangle on the right, the normal vector is now not perpendicular
      to the surface (in addition to no longer being of unit length). The red vector
      indicates what the surface normal <span class="st200_term emphasis">should</span> be.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg6" href="#st200_p2s3ss5pg6">6</a></div><div class="st200_paragraph">
      Therefore it's necessary to derive another 3x3 matrix known as the 
      <span class="st200_term term">normal matrix</span> from the model-view matrix that
      contains just the rotational component of the original matrix. The full
      derivation of this matrix is given in
      <a class="st200_link_external" href="http://www.mathfor3dgameprogramming.com/">Mathematics for 3D Game Programming and Computer Graphics, Third Edition</a>
      <span class="st200_footnote_reference"><a id="st200_fn_12_ref" href="#st200_fn_12">[12]</a></span>. Briefly, the normal matrix is equal to
      the <span class="st200_term term">inverse transpose</span> of the top left
      3x3 elements of an arbitrary 4x4 model-view matrix.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg7" href="#st200_p2s3ss5pg7">7</a></div><div class="st200_paragraph">
      In other rendering systems, <span class="st200_term term">eye space</span>
      is sometimes referred to as <span class="st200_term term">camera space</span>,
      or <span class="st200_term term">view space</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss5pg8" href="#st200_p2s3ss5pg8">8</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">eye space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceEyeType.html">RSpaceEyeType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss6" href="#st200_p2s3ss6">2.3.6</a></div><div class="st200_subsection_title">Clip space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss6pg1" href="#st200_p2s3ss6pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Clip space</span> is a homogeneous coordinate
      system in which OpenGL performs <span class="st200_term term">clipping</span>
      of primitives (such as triangles). In OpenGL,
      <span class="st200_term term">clip space</span> is effectively a
      left-handed coordinate system by default
      <span class="st200_footnote_reference"><a id="st200_fn_13_ref" href="#st200_fn_13">[13]</a></span>. Intuitively, coordinates in
      <span class="st200_term term">eye space</span> are transformed with a
      <span class="st200_term term">projection</span> (normally either an
      <span class="st200_term term">orthographic</span> or
      <span class="st200_term term">perspective</span> projection) such that
      all vertices are projected into a homogeneous unit cube placed at
      the origin - <span class="st200_term term">clip space</span> - resulting
      in four-dimensional <span class="st200_term expression">(x, y, z, w)</span>
      positions. Positions that end up outside of the cube are 
      <span class="st200_term term">clipped</span> (discarded) by dedicated
      clipping hardware, typically producing more triangles as a result.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss6fo1" href="#st200_p2s3ss6fo1">2.3.6.1. Primitive clipping</a></div><img class="st200_image" alt="Primitive clipping" src="images/clipping.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss6pg2" href="#st200_p2s3ss6pg2">2</a></div><div class="st200_paragraph">
      A <span class="st200_term term">projection</span> effectively
      determines how objects in the three-dimensional scene are projected
      onto the two-dimensional <span class="st200_term term">viewing plane</span>
      (a computer screen, in most cases).
      A <span class="st200_term term">perspective</span> projection
      transforms vertices such that objects that are further away from
      the viewing plane appear to be smaller than objects that are close
      to it, while an <span class="st200_term term">orthographic</span>
      projection preserves the perceived sizes of objects regardless of
      their distance from the viewing plane.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss6fo2" href="#st200_p2s3ss6fo2">2.3.6.2. Perspective projection</a></div><img class="st200_image" alt="Perspective projection" src="images/proj_perspective.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss6fo3" href="#st200_p2s3ss6fo3">2.3.6.3. Orthographic projection</a></div><img class="st200_image" alt="Orthographic projection" src="images/proj_ortho.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss6pg3" href="#st200_p2s3ss6pg3">3</a></div><div class="st200_paragraph">
      Because <a class="st200_link" href="#st200_p2s3ss5">eye space</a> is
      a right-handed coordinate system by convention, but by default
      <a class="st200_link" href="#st200_p2s3ss6">clip space</a> is
      left-handed, the projection matrix used will invert the sign of the
      <span class="st200_term expression">z</span> component of any given point.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss6pg4" href="#st200_p2s3ss6pg4">4</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package,
      the <a class="st200_link" href="#st200_p2s2ss7">camera</a> produces
      a 4x4 <span class="st200_term term">projection matrix</span>. The
      <span class="st200_term term">projection matrix</span> is passed, along with
      the <a class="st200_link" href="#st200_p2s3ss5pg3">model-view</a>
      matrix, to the renderer's <span class="st200_term term">vertex shaders</span>.
      As is normal in OpenGL, the vertex shader produces 
      <span class="st200_term term">clip space</span> coordinates which are then
      used by the hardware rasterizer to produce color fragments onscreen.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss6pg5" href="#st200_p2s3ss6pg5">5</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">clip space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceClipType.html">RSpaceClipType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss7" href="#st200_p2s3ss7">2.3.7</a></div><div class="st200_subsection_title">Normalized-device space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss7pg1" href="#st200_p2s3ss7pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Normalized-device space</span> is, by default, a left-handed
      <span class="st200_footnote_reference"><a id="st200_fn_14_ref" href="#st200_fn_14">[14]</a></span>
      coordinate
      space in which <a class="st200_link" href="#st200_p2s3ss6">clip space</a>
      coordinates have been divided by their own <span class="st200_term expression">w</span>
      component (discarding the resulting <span class="st200_term expression">w = 1</span>
      component in the process), yielding three dimensional coordinates. The
      range of values in the resulting coordinates are effectively normalized by the division
      to fall within the ranges <span class="st200_term expression">[(-1, -1, -1), (1, 1, 1)]</span>
      <span class="st200_footnote_reference"><a id="st200_fn_15_ref" href="#st200_fn_15">[15]</a></span>.
      The coordinate space represents a simplifying intermediate step 
      between having <a class="st200_link" href="#st200_p2s3ss6">clip space</a>
      coordinates and getting something projected into a two-dimensional image
      (<a class="st200_link" href="#st200_p2s3ss8">screen space</a>) for viewing.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss7pg2" href="#st200_p2s3ss7pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      does not directly use or manipulate values in 
      <span class="st200_term term">normalized-device space</span>; it is mentioned
      here for completeness.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss7pg3" href="#st200_p2s3ss7pg3">3</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">normalized-device space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceNDCType.html">RSpaceNDCType</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s3ss8" href="#st200_p2s3ss8">2.3.8</a></div><div class="st200_subsection_title">Screen space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss8pg1" href="#st200_p2s3ss8pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Screen space</span> is, by default, a left-handed coordinate
      system representing the screen (or window) that is displaying the actual
      results of rendering. If the screen is of width <span class="st200_term expression">w</span>
      and height <span class="st200_term expression">h</span>,
      and the current <span class="st200_term term">depth range</span> of the window
      is <span class="st200_term expression">[n, f]</span>, then the range of values
      in screen space coordinates runs from <span class="st200_term expression">[(0, 0, n), (w, h, f)]</span>.
      The origin <span class="st200_term expression">(0, 0, 0)</span> is assumed to be at
      the bottom-left corner.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss8pg2" href="#st200_p2s3ss8pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term term">depth range</span> is actually a configurable
      value, but the <span class="st200_term package">io7m-r1</span> package
      keeps the OpenGL default. From the <span class="st200_term expression">glDepthRange</span>
      function manual page:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s3ss8fo1" href="#st200_p2s3ss8fo1">2.3.8.1. glDepthRange</a></div><pre class="st200_verbatim">After clipping and division by w, depth coordinates range from -1 to 1, 
corresponding to the near and far clipping planes. glDepthRange specifies a 
linear mapping of the normalized depth coordinates in this range to window 
depth coordinates. Regardless of the actual depth buffer implementation, 
window coordinate depth values are treated as though they range from 0 
through 1 (like color components). Thus, the values accepted by 
glDepthRange are both clamped to this range before they are accepted.
The setting of (0,1) maps the near plane to 0 and the far plane to 1. 
With this mapping, the depth buffer range is fully utilized.</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss8pg3" href="#st200_p2s3ss8pg3">3</a></div><div class="st200_paragraph">
      As OpenGL, by default, specifies a depth range of 
      <span class="st200_term expression">[0, 1]</span>, the positive Z axis
      points away from the observer, making the coordinate system left handed.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s3ss8pg4" href="#st200_p2s3ss8pg4">4</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, 
      <span class="st200_term term">screen space</span> is indicated by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/types/RSpaceWindowType.html">RSpaceWindowType</a>.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s4" href="#st200_p2s4">2.4</a></div><div class="st200_section_title">Rendering Process</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg1" href="#st200_p2s4pg1">1</a></div><div class="st200_paragraph">
    This section attempts to give a high-level view of the rendering
    process as it occurs in the <span class="st200_term package">io7m-r1</span> 
    package.
  </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg2" href="#st200_p2s4pg2">2</a></div><div class="st200_paragraph">
    A rough diagram of the rendering process for a typical program is as follows,
    with red nodes indicating actions taken by the programmer, and blue nodes
    indicating actions performed by the 
    <span class="st200_term package">io7m-r1</span> package:
  </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s4fo1" href="#st200_p2s4fo1">2.4.1. Rendering Flow Chart</a></div><img class="st200_image" alt="Rendering Flow Chart" src="images/process_flow.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg3" href="#st200_p2s4pg3">3</a></div><div class="st200_paragraph">
    During the <span class="st200_term term">initialization</span> stage, the
    programmer is required to create a <span class="st200_term term">framebuffer</span>
    that will contain the results of rendering. Then, the programmer loads
    all of the <a class="st200_link" href="#st200_p2s8">meshes</a> that will be
    used during rendering <span class="st200_footnote_reference"><a id="st200_fn_16_ref" href="#st200_fn_16">[16]</a></span>. Then, the programmer creates instances of any
    <span class="st200_term term">renderers</span> and/or 
    <span class="st200_term term">filters</span> that will be used during
    rendering.
  </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg4" href="#st200_p2s4pg4">4</a></div><div class="st200_paragraph">
    Most applications will enter into some form of 
    <span class="st200_term term">rendering loop</span>, where a new image is
    produced onto the screen at a rate of sixty or so per second. The
    <span class="st200_term package">io7m-r1</span> package does
    not have its own rendering loop: The programmer is simply required to
    call the renderers provided by the package whenever a new image is
    needed.
  </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg5" href="#st200_p2s4pg5">5</a></div><div class="st200_paragraph">
    Ordinarily, the programmer will be rendering a scene of some description.
    Most 3D simulations contain some sort of representation of a world containing
    objects and entities, with at least one observer placed within that world,
    with images produced of that world from the perspective of the observer. Almost
    certainly, the world contains some sort of 
    <span class="st200_term term">spatial data structure</span> that partitions
    the world into sections in order to efficiently implement collision detection
    algorithms, physics simulations, and for determining exactly which objects are
    potentially visible from the perspective of the observer. The
    <span class="st200_term package">io7m-r1</span> package remains
    completely ignorant of these details: It expects the programmer to pass it
    a list of objects and light sources to render, and does not make any attempt
    to do any spatial partitioning or visibility calculations of its own. Therefore,
    the first step taken by the programmer in most rendering loops is to work out
    exactly what needs to be rendered, and then put together a list of things that
    need to be rendered in a form that the 
    <span class="st200_term package">io7m-r1</span> package can use.
    Concretely, the programmer constructs
    <a class="st200_link" href="#st200_p2s10">instances</a> (associated with
    <a class="st200_link" href="#st200_p2s5">materials</a>) and
    <a class="st200_link" href="#st200_p2s18">lights</a>, placing them into
    an immutable snapshot known as a <a class="st200_link" href="#st200_p2s11">visible set</a>.
    Because all objects in the <span class="st200_term package">io7m-r1</span> package
    are immutable, it may be that instances, materials, and lights are re-used from the
    previous loop iteration (or submitted again with minor modifications via the use of mutable 
    builders). This is how the illusion of animated materials, lights, and instances
    are achieved in the <span class="st200_term package">io7m-r1</span> package:
    If the programmer has created a light <span class="st200_term variable">L0</span> in
    the previous rendering loop iteration, and submits a light <span class="st200_term variable">L1</span>
    in the current loop iteration that is structurally identical to 
    <span class="st200_term variable">L0</span> but with a slightly different intensity, then
    there will appear to be a single light in the scene with an intensity that varies over 
    time. The <span class="st200_term package">io7m-r1</span> package remains 
    completely ignorant of the passage of time and doesn't need to be concerned with 
    keeping any sort of internal state to handle animation - simplifying the 
    implementation drastically.
  </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg6" href="#st200_p2s4pg6">6</a></div><div class="st200_paragraph">
    The <span class="st200_term package">io7m-r1</span> package takes the
    immutable scene produced by the programmer and efficiently batches all of the
    instances by material, aiming to reduce the number of state changes required
    to render all of the given instances. The instances in the scene are also
    separated into <span class="st200_term term">translucent</span> and 
    <span class="st200_term term">opaque</span> groups. The programmer then passes
    this batched visible set to whichever renderer is currently being used. The renderer
    generates any shadow maps required for the lights in the visible set and then renders
    all of the opaque instances to the given framebuffer. The programmer can then
    optionally pass this framebuffer to a filter if desired. Then, the
    programmer submits the same visible set to the renderer in order to allow
    it to render the remaining translucent instances. Again, the programmer can
    optionally pass the framebuffer to another filter, or the contents of
    the framebuffer can simply be copied to the screen for display.
  </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s4pg7" href="#st200_p2s4pg7">7</a></div><div class="st200_paragraph">
    Of course, the above process is simply one possible way to use the
    <span class="st200_term package">io7m-r1</span> package. Real
    applications might use the renderers to produce images that will then
    be re-used in further visible sets. For example, if a visible set uses materials that
    use <a class="st200_link" href="#st200_p2s17">environment mapping</a>,
    the programmer might pass six drastically simplified versions of a scene
    to the renderer in order to produce the six faces of a 
    <span class="st200_term term">cube map</span>.
    This cube map may then be used in materials that are used with instances
    to render a visible set that will actually be displayed to the screen.
  </div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s5" href="#st200_p2s5">2.5</a></div><div class="st200_section_title">Materials</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s5ss1">2.5.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s5ss2">2.5.2. Types</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s5ss3">2.5.3. Shaders</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s5ss1" href="#st200_p2s5ss1">2.5.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss1pg1" href="#st200_p2s5ss1pg1">1</a></div><div class="st200_paragraph">
      This section attempts to provide information on the
      <span class="st200_term term">material</span> system used in the
      <span class="st200_term package">io7m-r1</span> package
      as well as the rationale for its existence.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss1pg2" href="#st200_p2s5ss1pg2">2</a></div><div class="st200_paragraph">
      In contrast to most other rendering systems, the
      <span class="st200_term package">io7m-r1</span> package
      uses a typed <span class="st200_term term">material</span> system configured
      directly from code, rather than having programmers and artists write 
      <span class="st200_term term">shaders</span> in a shading language directly. It was a
      conscious design decision to reduce <span class="st200_term term">flexibility</span>
      in order to increase <span class="st200_term term">ease of use</span> and
      <span class="st200_term term">correctness</span>. The material system
      has the following disadvantages:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s5ss1fo1" href="#st200_p2s5ss1fo1">2.5.1.1. Material system disadvantages</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          The material system was designed to accomodate the majority
          of rendering techniques seen in computer games circa 2014 (such as
          normal mapping, environment mapped reflections, etc). If the
          <span class="st200_term package">io7m-r1</span> package
          doesn't provide direct support for a technique, then the programmer
          is required to modify the <span class="st200_term package">io7m-r1</span> 
          package to use it.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss1pg3" href="#st200_p2s5ss1pg3">3</a></div><div class="st200_paragraph">
      However, the design also allows for the following advantages:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s5ss1fo2" href="#st200_p2s5ss1fo2">2.5.1.2. Material system advantages</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          The material system was designed to accomodate the majority
          of rendering techniques seen in computer games circa 2014 (such as
          normal mapping, environment mapped reflections, etc). Rather than
          having to tediously re-implement error-prone techniques such as 
          normal mapping over and over, the programmer simply enables
          normal mapping for a material.
        </li><li class="st200_list_item">
          The material system provides enough <span class="st200_term term">metadata</span>
          about a given surface for all renderers in the
          <span class="st200_term package">io7m-r1</span> package to
          give consistently correct results regardless of the lighting in a scene. 
          For example, other rendering
          systems that utilize <span class="st200_term term">shadow mapping</span>
          often give incorrect results when a user-written shader conditionally
          <span class="st200_term term">discards</span> pixels. Shadow mapping is implemented
          by rendering a depth-only image of an object from a different perspective,
          and so the same pixels have to be discarded when rendering the depth-only 
          image as when rendering the actual color image. In systems where the
          user is required to write shaders, the system has no way of knowing that
          some pixels need to be discarded and often has to fall back to running
          the full material shader with writes to the color buffer masked.
          The material system
          in the <span class="st200_term package">io7m-r1</span> package
          indicates <span class="st200_term term">statically</span> when this can occur,
          and so the system simply uses a very efficient depth-only shader to
          render accurate shadow maps.
        </li><li class="st200_list_item">
          In other rendering systems (particularly those that use 
          <span class="st200_term term">forward rendering</span>), the programmer is
          required to write one shader per combination of <span class="st200_term term">material</span>
          and <span class="st200_term term">light</span>. That is, the programmer
          is expected to re-implement each of the different lighting techniques
          for every single material so that each can be used in any possible lighting environment. 
          Many systems use a shader generation system
          to work around these sorts of problems, requiring the development of
          (and the programmer to learn) even more complex tools and development environments.
          This issue is simply not present with a static material system.
        </li><li class="st200_list_item">
          Because the set of possible material and light types in the
          <span class="st200_term package">io7m-r1</span> package is
          fixed, the system knows exactly how to correctly send data to all
          of the possible <span class="st200_term term">shaders</span>. The programmer
          is not required to laboriously configure all of the connections between
          shader parameters and the data that must be supplied to shaders. All of
          the usual classes of bugs involving forgetting to set parameters, sending
          parameters of the wrong type, etc, are simply not possible.
        </li><li class="st200_list_item">
          The material system allows for extremely rapid development and
          previewing of materials. Because the components of the material
          systems are exposed as simple pseudo-algebraic Java types, it is
          extremely easy to put together a graphical user interface for
          configuring materials. Rendering systems that require programmers
          to write shaders typically end up implementing their own complete
          integrated development environments!
        </li><li class="st200_list_item">
          Because the GLSL language is fundamentally poorly designed and entirely
          anti-modular, any rendering system requiring the programmer to write
          shaders must implement its own custom shading language to give good
          type errors and to work identically across all of the different possible
          versions of OpenGL
          <span class="st200_footnote_reference"><a id="st200_fn_17_ref" href="#st200_fn_17">[17]</a></span>. It is simply not possible, in the <span class="st200_term package">io7m-r1</span> package,
          for the programmer to create a material that will work on some of the
          supported OpenGL versions and not others.
        </li><li class="st200_list_item">
          The material system has predictable performance characteristics. In
          systems that require programmers to write their own shaders, it is
          standard practice for programmers to repeatedly re-visit and do
          tedious optimization work to get their materials to run faster. The
          <span class="st200_term package">io7m-r1</span> package
          tries to expose a very minimalist material system and delegates the
          work of, for example, procedural texture generation to external systems
          <span class="st200_footnote_reference"><a id="st200_fn_18_ref" href="#st200_fn_18">[18]</a></span>.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss1pg4" href="#st200_p2s5ss1pg4">4</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package is
      generally developed under the assumption that if a programmer is competent
      enough to write all of their own shading and lighting algorithms, then they
      might as well have written their own rendering system in the first place
      <span class="st200_footnote_reference"><a id="st200_fn_19_ref" href="#st200_fn_19">[19]</a></span>!
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s5ss2" href="#st200_p2s5ss2">2.5.2</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg1" href="#st200_p2s5ss2pg1">1</a></div><div class="st200_paragraph">
      All materials implement
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialType.html">KMaterialType</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg2" href="#st200_p2s5ss2pg2">2</a></div><div class="st200_paragraph">
      All materials have a 3x3 texture matrix which is concatenated with
      a per-instance 3x3 texture matrix during rendering. The texture
      matrix affects all textures (such as the <span class="st200_term term">albedo map</span>,
      <span class="st200_term term">normal map</span>, <span class="st200_term term">specular map</span>, etc)
      in the material simultaneously. This allows for the orientation, scale
      and position of a texture to be set on a per-material basis, and then
      adjusted on a per-instance basis later.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg3" href="#st200_p2s5ss2pg3">3</a></div><div class="st200_paragraph">
      All materials have a unique <span class="st200_term term">material code</span>
      (a simple string) that allows the rendering system to select a 
      <span class="st200_term term">shader</span> in 
      <span class="st200_term expression">O(1)</span> time to render the material.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg4" href="#st200_p2s5ss2pg4">4</a></div><div class="st200_paragraph">
      All materials take the form <span class="st200_term term">pseudo-algebraic</span>
      data types, with each <span class="st200_term term">case</span> (or 
      <span class="st200_term term">constructor</span> in typed functional languages - not used here
      because the term already exists in Java and means something else) being
      represented by a single type. For example, the type of
      <span class="st200_term term">albedo</span> material properties is represented
      by the <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoType.html">KMaterialAlbedoType</a>
      type, with specific cases represented by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoTextured.html">KMaterialAlbedoTextured</a>
      and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoUntextured.html">KMaterialAlbedoUntextured</a>
      types. When given a value of type
      <span class="st200_term constant">KMaterialAlbedoType</span>, it is necessary to
      <span class="st200_term term">pattern-match</span> on the value to find out which
      of the specific types the value actually is. This is achieved in Java by the
      use of <span class="st200_term term">generic visitors</span>. As an example:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s5ss2fo1" href="#st200_p2s5ss2fo1">2.5.2.1. Pattern matching</a></div><pre class="st200_verbatim">/*
 * Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com
 *
 * Permission to use, copy, modify, and/or distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
 * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
 * IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

package com.io7m.r1.documentation.examples;

import com.io7m.jfunctional.Unit;
import com.io7m.junreachable.UnreachableCodeException;
import com.io7m.r1.kernel.types.KMaterialAlbedoTextured;
import com.io7m.r1.kernel.types.KMaterialAlbedoType;
import com.io7m.r1.kernel.types.KMaterialAlbedoUntextured;
import com.io7m.r1.kernel.types.KMaterialAlbedoVisitorType;
import com.io7m.r1.types.RException;

/**
 * An example of pattern matching on materials.
 */

public final class Match0
{
  private Match0()
  {
    throw new UnreachableCodeException();
  }

  public static void whichAlbedoType(
    final KMaterialAlbedoType m)
    throws RException
  {
    m
      .albedoAccept(new KMaterialAlbedoVisitorType&lt;Unit, UnreachableCodeException&gt;() {
        @Override public Unit textured(
          final KMaterialAlbedoTextured mt)
        {
          System.out.println("Textured");
          return Unit.unit();
        }

        @Override public Unit untextured(
          final KMaterialAlbedoUntextured mu)
        {
          System.out.println("Untextured");
          return Unit.unit();
        }
      });
  }
}
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg5" href="#st200_p2s5ss2pg5">5</a></div><div class="st200_paragraph">
      Essentially, the method <span class="st200_term constant">albedoAccept</span> is
      passed a value <span class="st200_term expression">v</span> of type
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoVisitorType.html">KMaterialAlbedoVisitorType</a>.
      The <span class="st200_term constant">textured</span> method of 
      <span class="st200_term expression">v</span> is called if 
      <span class="st200_term expression">m</span> is of type
      <span class="st200_term constant">KMaterialAlbedoTextured</span>, and
      the <span class="st200_term constant">untextured</span> method of 
      <span class="st200_term expression">v</span> is called if 
      <span class="st200_term expression">m</span> is of type
      <span class="st200_term constant">KMaterialAlbedoUntextured</span>. The
      methods of <span class="st200_term expression">v</span> can return values
      of type <span class="st200_term expression">A</span> (in this case, because
      the visitor simply prints a message and doesn't return anything, the
      visitor returns a value of type <span class="st200_term expression">Unit</span>),
      and can raise exceptions of type 
      <span class="st200_term expression">E</span> (in this case, the visitor does
      not raise any exceptions and so throws an unchecked
      <span class="st200_term expression">UnreachableCodeException</span>).
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg6" href="#st200_p2s5ss2pg6">6</a></div><div class="st200_paragraph">
      This method of representing types with a small number of fixed cases
      is used throughout the <span class="st200_term package">io7m-r1</span> 
      package <span class="st200_footnote_reference"><a id="st200_fn_20_ref" href="#st200_fn_20">[20]</a></span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss2pg7" href="#st200_p2s5ss2pg7">7</a></div><div class="st200_paragraph">
      Materials are divided into <span class="st200_term term">opaque</span> and
      <span class="st200_term term">translucent</span> types, represented by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialOpaqueType.html">KMaterialOpaqueType</a>
      and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentType.html">KMaterialTranslucentType</a>
      types. Specific cases of the <span class="st200_term term">translucent</span> types
      allow for effects such as <span class="st200_term term">specular-only</span> 
      rendering (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentSpecularOnly.html">KMaterialTranslucentSpecularOnly</a>)
      and <a class="st200_link" href="#st200_p2s25">generic refraction</a>
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRefractive.html">KMaterialTranslucentRefractive</a>).
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s5ss3" href="#st200_p2s5ss3">2.5.3</a></div><div class="st200_subsection_title">Shaders</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss3pg1" href="#st200_p2s5ss3pg1">1</a></div><div class="st200_paragraph">
      In order to render an object on modern graphics hardware,
      it's necessary to use one or more <span class="st200_term term">shaders</span>
      (<span class="st200_term term">shading programs</span>) to actually
      render surface details and/or apply lighting.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss3pg2" href="#st200_p2s5ss3pg2">2</a></div><div class="st200_paragraph">
      When performing <a class="st200_link" href="#st200_p2s15">forward rendering</a>,
      one shader is used per combination of surface material type and
      <a class="st200_link" href="#st200_p2s18">light type</a>. When performing
      <a class="st200_link" href="#st200_p2s12">deferred rendering</a>, one
      shader is used to render the surface properties into a buffer, and another
      shader is used to calculate lighting using the data in the buffer.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss3pg3" href="#st200_p2s5ss3pg3">3</a></div><div class="st200_paragraph">
      It's therefore necessary to be able to, given an arbitrary material and light,
      efficiently choose shaders with which to perform rendering. Because
      all possible material and light combinations in the 
      <span class="st200_term package">io7m-r1</span> package are
      known ahead of time, the <span class="st200_term package">io7m-r1</span> 
      package simply picks one from the complete set of possible shaders that were generated
      when the package was built. When an object with a given material <span class="st200_term variable">m</span>
      is placed into a scene, the <span class="st200_term package">io7m-r1</span> package
      reads the <span class="st200_term term">material code</span> (a simple unique identifier string)
      for the material and uses that code to select a shader. The shader is
      then compiled, loaded, and cached. The next time a material 
      (or material and light combination) appears with the same code, the 
      cached shader is re-used.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s5ss3pg4" href="#st200_p2s5ss3pg4">4</a></div><div class="st200_paragraph">
      The advantage of this approach, somewhat ironically, is a reduction
      in the number of shaders that have to be loaded at any given time. In
      other rendering systems that equate materials with shaders, a scene
      containing a thousand different material types requires a thousand
      different shaders to be loaded (even though many of those shaders may
      be functionally identical). The same scene using the material system
      in the <span class="st200_term package">io7m-r1</span> package
      may only require dozens of shaders, because a shader essentially 
      represents a combination of material properties 
      (such as "normal mapped, environment mapped, textured albedo"), 
      as opposed to representing an entire material. This also reduces the
      number of rendering state changes that have to be performed during
      rendering: If two materials differ structurally only in the actual 
      textures that they use, then the same shader will be used for both
      and therefore the rendering system does not need to switch shaders
      during rendering to render objects using either material.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s6" href="#st200_p2s6">2.6</a></div><div class="st200_section_title">Regular Materials</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss1">2.6.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss2">2.6.2. Albedo Properties</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss3">2.6.3. Emission Properties</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss4">2.6.4. Normal Properties</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss5">2.6.5. Specular Properties</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s6ss6">2.6.6. Environment Properties</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss1" href="#st200_p2s6ss1">2.6.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss1pg1" href="#st200_p2s6ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package uses
      a loose categorization for certain materials, based on observations taken
      whilst studying the range of surface types used in the average commercial
      3D game circa 2014. Basically, a material is 
      <span class="st200_term term">regular</span> if it allows for control over
      the surface <a class="st200_link" href="#st200_p2s6ss2">albedo</a>,
      <a class="st200_link" href="#st200_p2s6ss3">emission</a>,
      <a class="st200_link" href="#st200_p2s6ss4">normal</a>,
      <a class="st200_link" href="#st200_p2s6ss5">specular</a>,
      and <a class="st200_link" href="#st200_p2s6ss6">environment</a>
      properties. This combination of five properties is sufficient for expressing the
      vast majority of surface materials implemented in most computer games. 
      The type of <span class="st200_term term">regular</span> materials is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialRegularType.html">KMaterialRegularType</a>.
      The type of <span class="st200_term term">opaque</span> <span class="st200_term term">regular</span>
      materials is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialOpaqueRegular.html">KMaterialOpaqueRegular</a>.
      The type of <span class="st200_term term">translucent</span> <span class="st200_term term">regular</span>
      materials is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRegular.html">KMaterialTranslucentRegular</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss2" href="#st200_p2s6ss2">2.6.2</a></div><div class="st200_subsection_title">Albedo Properties</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg1" href="#st200_p2s6ss2pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">albedo</span> of a surface is defined
      as the coefficient of <span class="st200_term term">diffuse reflectivity</span>
      of a surface. In practical terms, it can be thought of as the
      color that a given surface will appear when lit with a pure white
      light, prior to the application of any other surface-modifying
      effects such as <a class="st200_link" href="#st200_p2s6ss6">environment mapping</a>.
      As an example, an object with a pure red albedo will appear to be
      red when lit with a white light; conceptually, all other parts
      of the light are absorbed by the surface.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg2" href="#st200_p2s6ss2pg2">2</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package,
      the albedo for a surface can be defined as a simple <span class="st200_term term">base color</span>
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoUntextured.html">KMaterialAlbedoUntextured</a>),
      or as a configurable mix (linear interpolation) between a 
      <span class="st200_term term">base color</span> and a 
      <span class="st200_term term">texture</span>
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialAlbedoTextured.html">KMaterialAlbedoTextured</a>).
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg3" href="#st200_p2s6ss2pg3">3</a></div><div class="st200_paragraph">
      An example square lit by a white light, with an untextured
      albedo with a red base color and no other surface properties:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo1" href="#st200_p2s6ss2fo1">2.6.2.1. Red albedo (Result)</a></div><img class="st200_image" alt="Red albedo (Result)" src="images/albedo_plain_red_0.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg4" href="#st200_p2s6ss2pg4">4</a></div><div class="st200_paragraph">
      The same square and light, but with a textured albedo mixing in 
      <span class="st200_term constant">100%</span>
      of the texture, effectively replacing the base color:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo2" href="#st200_p2s6ss2fo2">2.6.2.2. Albedo texture</a></div><img class="st200_image" alt="Albedo texture" src="images/specular_tiles_albedo.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo3" href="#st200_p2s6ss2fo3">2.6.2.3. Textured albedo (Result)</a></div><img class="st200_image" alt="Textured albedo (Result)" src="images/albedo_plain_tiles.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg5" href="#st200_p2s6ss2pg5">5</a></div><div class="st200_paragraph">
      The same sphere and light with a textured albedo mixing in <span class="st200_term constant">100%</span>
      of the texture, but using a texture that has an alpha channel so that transparent parts of
      the texture can show the underlying base color:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo4" href="#st200_p2s6ss2fo4">2.6.2.4. Albedo texture</a></div><img class="st200_image" alt="Albedo texture" src="images/albedo_plain_red_mix_0_texture.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo5" href="#st200_p2s6ss2fo5">2.6.2.5. Textured albedo (Result)</a></div><img class="st200_image" alt="Textured albedo (Result)" src="images/albedo_plain_red_mix_0.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg6" href="#st200_p2s6ss2pg6">6</a></div><div class="st200_paragraph">
      The same sphere and light with a textured albedo mixing in <span class="st200_term constant">50%</span>
      of the texture (indicating a simple linear interpolation between the texture and base color):
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo6" href="#st200_p2s6ss2fo6">2.6.2.6. Albedo texture</a></div><img class="st200_image" alt="Albedo texture" src="images/specular_tiles_albedo.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo7" href="#st200_p2s6ss2fo7">2.6.2.7. Textured albedo (Result)</a></div><img class="st200_image" alt="Textured albedo (Result)" src="images/albedo_plain_tiles_mix.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss2pg7" href="#st200_p2s6ss2pg7">7</a></div><div class="st200_paragraph">
      Specifically, the albedo of a given surface is given by <span class="st200_term function">albedo</span>
      [<a class="st200_link_external" href="haskell/Albedo.hs">Albedo.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss2fo8" href="#st200_p2s6ss2fo8">2.6.2.8. Albedo</a></div><pre class="st200_verbatim">module Albedo where

import qualified Color4
import qualified Vector4f

albedo :: Color4.T -&gt; Float -&gt; Color4.T -&gt; Color4.T
albedo base mix t =
  Vector4f.interpolate base ((Vector4f.w t) * mix) t</pre></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss3" href="#st200_p2s6ss3">2.6.3</a></div><div class="st200_subsection_title">Emission Properties</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss3pg1" href="#st200_p2s6ss3pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">emission</span> properties of a surface
      specify to what degree the surface appears to emit light. The color
      of the light is equal to the final surface color. Emission is implemented as a 
      <a class="st200_link" href="#st200_p2s27">filter</a> and
      therefore emissive surfaces do not represent true
      <a class="st200_link" href="#st200_p2s18">light sources</a>. Additionally,
      emission is not supported for translucent objects.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss4" href="#st200_p2s6ss4">2.6.4</a></div><div class="st200_subsection_title">Normal Properties</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss4pg1" href="#st200_p2s6ss4pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">normal</span> properties of a surface
      define whether the surface normal vectors will be taken directly
      from the vertex data of the associated mesh
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialNormalVertex.html">KMaterialNormalVertex</a>),
      or sampled from
      a texture to perform <a class="st200_link" href="#st200_p2s16">normal mapping</a>
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialNormalMapped.html">KMaterialNormalMapped</a>).
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss5" href="#st200_p2s6ss5">2.6.5</a></div><div class="st200_subsection_title">Specular Properties</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss5pg1" href="#st200_p2s6ss5pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">specular</span> properties of a surface
      define how that surface reflects the 
      <a class="st200_link" href="#st200_p2s18ss2pg4">specular term</a>
      of any given light source. Surfaces can absorb the specular term and
      not reflect it at all
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialSpecularNone.html">KMaterialSpecularNone</a>),
      or can multiply the incoming light with a constant color
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialSpecularConstant.html">KMaterialSpecularConstant</a>),
      or can multiply the incoming light with a color sampled from a provided texture
      (<a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialSpecularMapped.html">KMaterialSpecularMapped</a>).
      Each of the constant or mapped options also require the specification of
      a <a class="st200_link" href="#st200_p2s18ss2pg6">specular exponent</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss5pg2" href="#st200_p2s6ss5pg2">2</a></div><div class="st200_paragraph">
      The purpose of the specular color coefficients serve two purposes: A pure
      black coefficient means that the surface does not reflect any specular light
      (simulating a rough surface). A pure white coefficient means that the surface 
      reflects specular light exactly as received (simulating a shiny surface). 
      When these values are sampled from a texture, it becomes possible
      to control the "shininess" of a texture on a per-pixel basis. A good
      example would be that of a bathroom tile texture: The faces of the tiles themselves
      should be shiny, but the cement between the tiles should appear to be rough. A
      simple greyscale specular map achieves this effect:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo1" href="#st200_p2s6ss5fo1">2.6.5.1. Tiles (Albedo)</a></div><img class="st200_image" alt="Tiles (Albedo)" src="images/specular_tiles_albedo.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo2" href="#st200_p2s6ss5fo2">2.6.5.2. Tiles (Normal map)</a></div><img class="st200_image" alt="Tiles (Normal map)" src="images/specular_tiles_normal.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo3" href="#st200_p2s6ss5fo3">2.6.5.3. Tiles (Specular map)</a></div><img class="st200_image" alt="Tiles (Specular map)" src="images/specular_tiles_specular.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo4" href="#st200_p2s6ss5fo4">2.6.5.4. Tiles (Result)</a></div><img class="st200_image" alt="Tiles (Result)" src="images/specular_tiles.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss5pg3" href="#st200_p2s6ss5pg3">3</a></div><div class="st200_paragraph">
      Note how the black pixels in the specular map effectively prevent the areas
      between the tiles from receiving specular highlights, whereas the faces of tiles
      receive full highlights.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss5pg4" href="#st200_p2s6ss5pg4">4</a></div><div class="st200_paragraph">
      Using a specular map that contains colors other than shades of grey is often
      useful for modelling metals. Materials such as plastic and paint consist of
      layers, the topmost of which will ordinarily reflect light as it is received.
      This usually means that an orange plastic will reflect a white specular highlight
      when lit with a pure white light. Metals, however, often have specular 
      reflections similar in color to their diffuse reflection; An orange or gold
      metal will have orange/gold specular highlights when lit with a pure white
      light. Specular maps containing bizarre combinations of colors can be used
      to create materials that are supernatural and alien in appearance:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo5" href="#st200_p2s6ss5fo5">2.6.5.5. Tiles (Strange specular map)</a></div><img class="st200_image" alt="Tiles (Strange specular map)" src="images/specular_tiles_alien_specular.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s6ss5fo6" href="#st200_p2s6ss5fo6">2.6.5.6. Tiles (Strange result)</a></div><img class="st200_image" alt="Tiles (Strange result)" src="images/specular_tiles_strange.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s6ss6" href="#st200_p2s6ss6">2.6.6</a></div><div class="st200_subsection_title">Environment Properties</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s6ss6pg1" href="#st200_p2s6ss6pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">environment</span> properties of a surface
      specify a <a class="st200_link" href="#st200_p2s17ss2">cube map</a>
      and some properties controlling how the resulting
      <a class="st200_link" href="#st200_p2s17ss3">environment-mapped reflection</a>
      is combined with the surface color defined by all of the previously
      specified material parameters.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s7" href="#st200_p2s7">2.7</a></div><div class="st200_section_title">Depth Materials</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s7ss1">2.7.1. Overview</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s7ss1" href="#st200_p2s7ss1">2.7.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s7ss1pg1" href="#st200_p2s7ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">depth properties</span> of opaque 
      materials indicate how surfaces with those materials will affect
      the current <span class="st200_term term">depth buffer</span>. Essentially,
      parts of a surface can elect to effectively be discarded by not
      being written to the depth buffer, allowing parts of otherwise
      opaque instances to appear fully transparent (without requiring the
      overhead of using fully <a class="st200_link" href="#st200_p2s15">translucent</a>
      instances).
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s7ss1pg2" href="#st200_p2s7ss1pg2">2</a></div><div class="st200_paragraph">
      Depth properties are described by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialDepthType.html">KMaterialDepthType</a>,
      with
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialDepthConstant.html">KMaterialDepthConstant</a>
      indicating that an object is fully opaque, and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialDepthAlpha.html">KMaterialDepthAlpha</a>
      indicating that parts of the object with an
      <a class="st200_link" href="#st200_p2s6ss2">albedo</a>
      that has an opacity of less than a given threshold
      will appear to be completely translucent.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s7ss1pg3" href="#st200_p2s7ss1pg3">3</a></div><div class="st200_paragraph">
      Depth information is also taken into account during
      the application of
      <a class="st200_link" href="#st200_p2s23">shadow mapping</a>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s7ss1fo1" href="#st200_p2s7ss1fo1">2.7.1.1. Depth alpha</a></div><img class="st200_image" alt="Depth alpha" src="images/depth_alpha.png"/></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s8" href="#st200_p2s8">2.8</a></div><div class="st200_section_title">Meshes</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s8ss1">2.8.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s8ss2">2.8.2. Attributes</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s8ss3">2.8.3. Types</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s8ss1" href="#st200_p2s8ss1">2.8.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss1pg1" href="#st200_p2s8ss1pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">mesh</span> is a collection of vertices
      and triangles that define a polyhedral object, allocated on the
      GPU upon which the renderer is executing. In practical terms, a
      mesh is a pair
      <span class="st200_term expression">(a, i)</span>, where
      <span class="st200_term expression">a</span> is an OpenGL
      <span class="st200_term term">vertex buffer object</span> consisting
      of vertices of a
      <a class="st200_link" href="#st200_p2s8ss2">standard type</a>,
      <span class="st200_term expression">i</span> is an OpenGL
      <span class="st200_term term">element buffer object</span> consisting
      of indices that describe how to draw the mesh as a series of triangles.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss1pg2" href="#st200_p2s8ss1pg2">2</a></div><div class="st200_paragraph">
      The contents of <span class="st200_term expression">a</span> are mutable, but
      mesh references are considered to be immutable as with all other objects 
      in the renderer.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s8ss2" href="#st200_p2s8ss2">2.8.2</a></div><div class="st200_subsection_title">Attributes</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss2pg1" href="#st200_p2s8ss2pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">mesh</span> consists of 
      <span class="st200_term term">vertices</span>.
      A vertex can be considered to be a value of a
      <span class="st200_term term">record type</span>, with the fields of
      the record referred to as the <span class="st200_term term">attributes</span>
      of the vertex. In the <span class="st200_term package">io7m-r1</span> package,
      an array buffer containing vertex data is specified using the
      array buffer types from
      <a class="st200_link_external" href="http://mvn.io7m.com/io7m-jcanephora">jcanephora</a>.
      The <span class="st200_term package">jcanephora</span> package 
      allows programmers to specify the exact types of array buffers, 
      allows for the full inspection of type information at runtime, including 
      the ability to reference attributes by name, and allows for type-safe modification
      of the contents of array buffers using an efficient cursor interface. 
      In the <span class="st200_term package">io7m-r1</span> package,
      meshes must have at least the following attributes, in any order:
    </div></div><div class="st200_formal_item mesh_types"><div class="st200_formal_item_title mesh_types"><a id="st200_p2s8ss2fo1" href="#st200_p2s8ss2fo1">2.8.2.1. Required mesh attributes</a></div><table class="st200_table" summary="Required mesh attributes"><thead class="st200_table_head"><tr><th class="st200_table_column_name">Name</th><th class="st200_table_column_name">Type</th><th class="st200_table_column_name">Description</th></tr></thead><tbody class="st200_table_body"><tr class="st200_table_row"><td class="st200_table_cell"><span class="st200_term constant">v_position</span></td><td class="st200_table_cell"><span class="st200_term constant">vector_3f</span></td><td class="st200_table_cell">The object-space position of the vertex</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><span class="st200_term constant">v_normal</span></td><td class="st200_table_cell"><span class="st200_term constant">vector_3f</span></td><td class="st200_table_cell">The object-space normal vector of the vertex</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><span class="st200_term constant">v_uv</span></td><td class="st200_table_cell"><span class="st200_term constant">vector_2f</span></td><td class="st200_table_cell">The UV coordinates of the vertex</td></tr><tr class="st200_table_row"><td class="st200_table_cell"><span class="st200_term constant">v_tangent</span></td><td class="st200_table_cell"><span class="st200_term constant">vector_4f</span></td><td class="st200_table_cell">The tangent vector of the vertex</td></tr></tbody></table></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss2pg2" href="#st200_p2s8ss2pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package ignores
      any other attributes that happen to be present
      <span class="st200_footnote_reference"><a id="st200_fn_21_ref" href="#st200_fn_21">[21]</a></span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss2pg3" href="#st200_p2s8ss2pg3">3</a></div><div class="st200_paragraph">
      Meshes explicitly store per-vertex <span class="st200_term term">tangent</span>
      vectors. The purpose and format of these vectors is given in the section
      on <a class="st200_link" href="#st200_p2s16ss2">normal mapping</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s8ss3" href="#st200_p2s8ss3">2.8.3</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s8ss3pg1" href="#st200_p2s8ss3pg1">1</a></div><div class="st200_paragraph">
      Meshes are represented in the <span class="st200_term package">io7m-r1</span> package
      by the <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMesh.html">KMesh</a>
      type.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s9" href="#st200_p2s9">2.9</a></div><div class="st200_section_title">Transforms</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s9ss1">2.9.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s9ss2">2.9.2. KTransformMatrix4x4</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s9ss3">2.9.3. KTransformOST</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s9ss1" href="#st200_p2s9ss1">2.9.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss1pg1" href="#st200_p2s9ss1pg1">1</a></div><div class="st200_paragraph">
      The ultimate purpose of a <span class="st200_term term">transform</span>
      is to produce one or more matrices that can be combined with
      other matrices and then finally passed to a 
      <span class="st200_term term">shader</span>. The shader uses these
      matrices to transform vertices and normal vectors during the
      rendering of objects.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss1pg2" href="#st200_p2s9ss1pg2">2</a></div><div class="st200_paragraph">
      A transform is effectively responsible for producing a
      <span class="st200_term term">model matrix</span> that transforms
      positions in 
      <a class="st200_link" href="#st200_p2s3ss3">object-space</a>
      to 
      <a class="st200_link" href="#st200_p2s3ss4">world-space</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss1pg3" href="#st200_p2s9ss1pg3">3</a></div><div class="st200_paragraph">
      In practical terms, a <span class="st200_term term">transform</span> is
      a matrix used to position, scale, and rotate 
      <a class="st200_link" href="#st200_p2s2ss9">instances</a>
      in a scene. This is achieved by multiplying the matrix with the 
      object-space positions of all vertices of the mesh that makes up the 
      instance, during rendering. The type of transforms in the 
      <span class="st200_term package">io7m-r1</span> package is the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KTransformType.html">KTransformType</a>
      which, at the time of writing, is implemented by two specific types that
      are documented in the following sections.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s9ss2" href="#st200_p2s9ss2">2.9.2</a></div><div class="st200_subsection_title">KTransformMatrix4x4</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss2pg1" href="#st200_p2s9ss2pg1">1</a></div><div class="st200_paragraph">
      The
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KTransformMatrix4x4.html">KTransformMatrix4x4</a>
      type represents a model matrix directly. In other words, the programmer
      is assumed to be using some other system of producing transforms that
      directly produces a 4x4 model matrix as a result.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss2pg2" href="#st200_p2s9ss2pg2">2</a></div><div class="st200_paragraph">
      This kind of transform is useful for representing transforms that
      are the result of many other concatenated transforms. As an example,
      consider a robot arm with multiple joints: The transform for the tip 
      of the arm is the sum of the rotations of all of the ancestor joints.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s9ss3" href="#st200_p2s9ss3">2.9.3</a></div><div class="st200_subsection_title">KTransformOST</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss3pg1" href="#st200_p2s9ss3pg1">1</a></div><div class="st200_paragraph">
      The
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KTransformOST.html">KTransformOST</a>
      type represents a transform using a 
      <span class="st200_term term">quaternion</span> representing an orientation,
      a vector representing scaling values on three axes, and a translation vector
      given in <a class="st200_link" href="#st200_p2s3ss4">world-space</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s9ss3pg2" href="#st200_p2s9ss3pg2">2</a></div><div class="st200_paragraph">
      This representation is simple and allows for convenient positioning
      and rotation of objects in the world. Quaternions, scaling vectors, and
      translations are all easily interpolated, and are therefore convenient
      for producing simple animations. Assuming that 
      <span class="st200_term variable">mr</span> is a 4x4
      rotation matrix produced from the quaternion, 
      <span class="st200_term variable">ms</span> is a 4x4 scaling matrix produced
      from the scaling vector, and <span class="st200_term variable">mt</span> is a 4x4
      translation matrix produced from the translation vector, then the final
      model matrix <span class="st200_term variable">mm</span> is given by 
      <span class="st200_term expression">mm = mt * mr * ms</span>. This has the effect
      of first scaling the object along the global axes, and then rotating the
      scaled object, and then moving the scaled and rotated object to the world
      position given by the translation 
      <span class="st200_footnote_reference"><a id="st200_fn_22_ref" href="#st200_fn_22">[22]</a></span>.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s10" href="#st200_p2s10">2.10</a></div><div class="st200_section_title">Instances</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s10ss1">2.10.1. Overview</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s10ss1" href="#st200_p2s10ss1">2.10.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s10ss1pg1" href="#st200_p2s10ss1pg1">1</a></div><div class="st200_paragraph">
      An <span class="st200_term term">instance</span> is a 5-tuple
      <span class="st200_term expression">(f, m, k, t, u)</span>, where:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s10ss1fo1" href="#st200_p2s10ss1fo1">2.10.1.1. Instance components</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
        <span class="st200_term expression">f</span> is a value of type
        <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KFaceSelection.html">KFaceSelection</a>,
        which indicates which faces in the given <span class="st200_term term">mesh</span>
        will be rendered.
      </li><li class="st200_list_item">
        <span class="st200_term expression">m</span> is a
        <a class="st200_link" href="#st200_p2s5">material</a>.
      </li><li class="st200_list_item">
        <span class="st200_term expression">k</span> is a reference to
        a <a class="st200_link" href="#st200_p2s8">mesh</a>.
      </li><li class="st200_list_item">
        <span class="st200_term expression">t</span> is a
        <a class="st200_link" href="#st200_p2s2ss6">transform</a>.
      </li><li class="st200_list_item">
        <span class="st200_term expression">u</span> is a 
        <span class="st200_term term">texture matrix</span>.
      </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s10ss1pg2" href="#st200_p2s10ss1pg2">2</a></div><div class="st200_paragraph">
      If <span class="st200_term expression">m</span> is an
      <span class="st200_term term">opaque</span> material, then the instance is
      said to be <span class="st200_term term">opaque</span>. If
      <span class="st200_term expression">m</span> is a
      <span class="st200_term term">translucent</span> material, then the instance is
      said to be <span class="st200_term term">translucent</span>. This is actually
      enforced at the type level: An instance of type
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KInstanceOpaqueRegular.html">KInstanceOpaqueRegular</a>
      may only be associated with a material of type
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialOpaqueRegular.html">KMaterialOpaqueRegular</a>,
      and so on. Opaque instances implement 
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KInstanceOpaqueType.html">KInstanceOpaqueType</a>,
      whilst translucent instances implement
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KInstanceTranslucentType.html">KInstanceTranslucentType</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s10ss1pg3" href="#st200_p2s10ss1pg3">3</a></div><div class="st200_paragraph">
      The rendering of <span class="st200_term term">opaque</span> instances
      is handled differently from the rendering of 
      <span class="st200_term term">translucent</span> instances. The 
      <span class="st200_term package">io7m-r1</span> package
      uses a <a class="st200_link" href="#st200_p2s12">deferred renderer</a>
      to efficiently render large numbers of opaque instances lit by potentially hundreds
      of light sources. However, the nature of the deferred rendering
      algorithm makes it impossible for deferred renderers to support
      translucent objects. Therefore, the 
      <span class="st200_term package">io7m-r1</span> package
      provides a 
      <a class="st200_link" href="#st200_p2s15">forward renderer</a>
      that implements a subset of the features of the deferred renderer
      for rendering translucent instances. Keeping the different categories
      of instances as distinct types ensures that the programmer is statically
      prevented from accidentally passing an instance with an opaque material
      where one with a translucent material was expected, and vice versa.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s11" href="#st200_p2s11">2.11</a></div><div class="st200_section_title">Visible Sets</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s11ss1">2.11.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s11ss2">2.11.2. Batching</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s11ss3">2.11.3. Shadow Geometry</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s11ss1" href="#st200_p2s11ss1">2.11.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss1pg1" href="#st200_p2s11ss1pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">visible set</span> is the collection of
      <a class="st200_link" href="#st200_p2s10">instances</a> and
      <a class="st200_link" href="#st200_p2s18">lights</a> that contribute
      to the scene from the perspective of a given 
      <span class="st200_term term">observer</span>. As stated previously
      the <span class="st200_term package">io7m-r1</span> package
      assumes that the programmer is using some sort of spatial data structure
      to intelligently decide what is and is not visible at any given time:
      The <span class="st200_term package">io7m-r1</span> package
      draws exactly what it is told to draw, and does not attempt to work out
      if a given object is visible or not.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s11ss2" href="#st200_p2s11ss2">2.11.2</a></div><div class="st200_subsection_title">Batching</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss2pg1" href="#st200_p2s11ss2pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">visible set</span> is <span class="st200_term term">batched</span>
      in order that the renderer can draw the scene with as few internal state
      changes as possible. Instances and lights are submitted to a mutable
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSetBuilderType.html">builder</a>
      which produces an immutable
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSet.html">visible set</a>
      as a result. Opaque instances are associated with lights in
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSetLightGroup.html">light groups</a>,
      and translucent instances are submitted with groups of
      lights in draw order. The <span class="st200_term package">io7m-r1</span> package
      renders translucent instances in the order that they are given to the builder.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss2pg2" href="#st200_p2s11ss2pg2">2</a></div><div class="st200_paragraph">
      Because opaque instances can be drawn in any order due to depth buffering,
      the <span class="st200_term package">io7m-r1</span> package
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSetOpaques.html">groups opaque instances</a>
      by material type in order to come up with a draw order that will result in the 
      fewest internal state changes during rendering. It applies this same grouping methodology 
      to produce sets of
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSetShadows.html">shadow casters</a>
      for producing shadow maps for any shadow-projecting lights in the scene.
      Visible instances are batched by their <a class="st200_link" href="#st200_p2s5ss3">material code</a>,
      so if the materials differ only by, for example, their albedo color, then
      they will both have the same material code and will be in the same batch
      during rendering. The same batching logic is applied to shadow casting
      instances.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s11ss3" href="#st200_p2s11ss3">2.11.3</a></div><div class="st200_subsection_title">Shadow Geometry</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss3pg1" href="#st200_p2s11ss3pg1">1</a></div><div class="st200_paragraph">
      Because the system requires the programmer to explicitly and separately state 
      that an opaque instance is visible in the scene, and that an opaque instance
      is casting a shadow, it becomes possible to effectively specify different 
      <span class="st200_term term">shadow geometry</span> for a given instance. As an example,
      a very complex and high resolution mesh may still have the silhouette of a simple
      sphere, and therefore the user can separately add the high resolution mesh to
      a scene as a visible instance, but add a low resolution version of the mesh
      as an invisible shadow-casting instance with the same
      <a class="st200_link" href="#st200_p2s9">transform</a>. As a rather extreme
      example, assuming a high resolution mesh <span class="st200_term variable">m0</span>
      added to the scene as both a visible instance and a shadow caster:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s11ss3fo1" href="#st200_p2s11ss3fo1">2.11.3.1. Visible and shadow casting (High)</a></div><img class="st200_image" alt="Visible and shadow casting (High)" src="images/shadow_geo_0.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss3pg2" href="#st200_p2s11ss3pg2">2</a></div><div class="st200_paragraph">
      A low resolution mesh <span class="st200_term variable">m1</span> added to the
      scene as both a visible instance and shadow caster:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s11ss3fo2" href="#st200_p2s11ss3fo2">2.11.3.2. Visible and shadow casting (Low)</a></div><img class="st200_image" alt="Visible and shadow casting (Low)" src="images/shadow_geo_1.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss3pg3" href="#st200_p2s11ss3pg3">3</a></div><div class="st200_paragraph">
      Now, with <span class="st200_term variable">m1</span> added as only a shadow
      caster, and <span class="st200_term variable">m0</span> added as only a visible
      instance:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s11ss3fo3" href="#st200_p2s11ss3fo3">2.11.3.3. Visible and shadow casting (Low shadow, high visible)</a></div><img class="st200_image" alt="Visible and shadow casting (Low shadow, high visible)" src="images/shadow_geo_2.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s11ss3pg4" href="#st200_p2s11ss3pg4">4</a></div><div class="st200_paragraph">
      Using lower resolution geometry for shadow casters can lead to efficiency gains
      on systems where vertex processing is expensive.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s12" href="#st200_p2s12">2.12</a></div><div class="st200_section_title">Deferred Rendering</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss1">2.12.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss2">2.12.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss3">2.12.3. G-Buffer</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss4">2.12.4. Light Group Stencil</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss5">2.12.5. Normal Compression</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s12ss6">2.12.6. Light Volumes</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss1" href="#st200_p2s12ss1">2.12.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss1pg1" href="#st200_p2s12ss1pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Deferred rendering</span> is a rendering
      technique where all of the opaque objects in a given scene are
      rendered into a series of buffers, and then lighting is applied
      to those buffers in
      <a class="st200_link" href="#st200_p2s3ss8">screen-space</a>.
      This is in contrast to <span class="st200_term term">forward rendering</span>,
      where all lighting is applied to objects as they are rendered.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss1pg2" href="#st200_p2s12ss1pg2">2</a></div><div class="st200_paragraph">
      One major advantage of deferred rendering is a massive reduction in the number of
      shaders required (traditional forward rendering requires <span class="st200_term expression">s * l</span>
      shaders, where <span class="st200_term expression">s</span> is the number of
      different object surface types in the scene, and 
      <span class="st200_term expression">l</span> is the number of different light
      types). In contrast, deferred rendering requires
      <span class="st200_term expression">s + l</span> shaders, because surface
      and lighting shaders are applied separately.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss1pg3" href="#st200_p2s12ss1pg3">3</a></div><div class="st200_paragraph">
      Traditional forward rendering also suffers severe performance
      problems as the number of lights in the scene increases, because it
      is necessary to recompute all of the surface attributes of an
      object each time a light is applied. In contrast, deferred rendering
      calculates all surface attributes of all objects once, and then reuses
      them when lighting is applied.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss1pg4" href="#st200_p2s12ss1pg4">4</a></div><div class="st200_paragraph">
      However, deferred renderers are usually incapable of rendering
      translucent objects. The deferred renderer in the 
      <span class="st200_term package">io7m-r1</span> package
      is no exception, and a severely restricted
      <a class="st200_link" href="#st200_p2s15">forward renderer</a>
      is provided to render translucent objects.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss2" href="#st200_p2s12ss2">2.12.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss2pg1" href="#st200_p2s12ss2pg1">1</a></div><div class="st200_paragraph">
      An informal description of the <span class="st200_term term">deferred rendering</span> algorithm as 
      implemented in the <span class="st200_term package">io7m-r1</span> package
      is as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss2fo1" href="#st200_p2s12ss2fo1">2.12.2.1. Deferred Rendering</a></div><ol class="st200_list_ordered"><li class="st200_list_item">
          Clear the current <a class="st200_link" href="#st200_p2s12ss3">g-buffer</a>,
          depth buffer, stencil buffer, and optionally the color buffer. The stencil
          buffer is cleared to <span class="st200_term expression">0</span> and the depth
          buffer is cleared to <span class="st200_term expression">1</span>.
        </li><li class="st200_list_item">
          For each <span class="st200_term term">light group</span> 
          <span class="st200_term expression">g</span> in the scene:
          <ol class="st200_list_ordered"><li class="st200_list_item">
              Enable writing to the depth and stencil buffers, and disable stencil testing.
            </li><li class="st200_list_item">
              Set all non-zero values in the current stencil buffer to
              <span class="st200_term expression">1</span>. See
              the section on <a class="st200_link" href="#st200_p2s12ss4">light group stencils</a>
              for the meaning behind these values.
            </li><li class="st200_list_item">
              For each <span class="st200_term term">instance</span> <span class="st200_term expression">o</span> in
              <span class="st200_term expression">g</span>:
              <ol class="st200_list_ordered"><li class="st200_list_item">
                  Render the surface <span class="st200_term term">albedo</span>,
                  <span class="st200_term term">eye-space normals</span>, 
                  <span class="st200_term term">specular color</span>, and
                  <span class="st200_term term">emission level</span> 
                  of <span class="st200_term expression">o</span> into the
                  <a class="st200_link" href="#st200_p2s12ss3">g-buffer</a>.
                  <a class="st200_link" href="#st200_p2s16">Normal mapping</a>
                  is performed during rendering, and if
                  <span class="st200_term expression">o</span> does not have
                  specular highlights, then a pure black (zero intensity) 
                  specular color is written. Effects such as 
                  <a class="st200_link" href="#st200_p2s17">environment mapping</a>
                  are considered to be part of the surface albedo and so are performed
                  in this step. Depth testing is enabled, and a depth function that
                  only results in pixels being drawn if the depth of the current pixel is
                  <span class="st200_term term">less than or equal</span> to the current depth
                  buffer value is used. The corresponding 
                  stencil buffer value is set to <span class="st200_term expression">2</span>.
                </li></ol>
            </li><li class="st200_list_item">
              Disable depth buffer and stencil buffer writing. Keep depth testing enabled
              and set the depth function to <span class="st200_term term">greater than or equal</span>.
              Enable the stencil test, and configure it such that only pixels with
              a corresponding value of <span class="st200_term expression">2</span> in the
              stencil buffer will be affected.
            </li><li class="st200_list_item">
              For each <span class="st200_term term">light</span> <span class="st200_term expression">k</span> in
              <span class="st200_term expression">g</span>:
              <ol class="st200_list_ordered"><li class="st200_list_item">
                  Render a <a class="st200_link" href="#st200_p2s12ss6">light</a> volume
                  representing <span class="st200_term expression">k</span>. All pixels that are
                  overlapped by <span class="st200_term expression">k</span> and that satisfy the
                  depth test have lighting applied. Lighting is applied in
                  <a class="st200_link" href="#st200_p2s3ss5">eye-space</a>, and the
                  original eye-space position of the current surface is reconstructed
                  using a <a class="st200_link" href="#st200_p2s13">position reconstruction</a>
                  algorithm.
                </li></ol>
            </li></ol>
        </li></ol></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss2pg2" href="#st200_p2s12ss2pg2">2</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, deferred
      renderers have the type
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KRendererDeferredOpaqueType.html">KRendererDeferredOpaqueType</a>,
      and the primary implementation is given by
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KRendererDeferredOpaque.html">KRendererDeferredOpaque</a>.
      Deferred renderers are usually paired with simple
      <a class="st200_link" href="#st200_p2s15">forward renderers</a> in order
      to render any translucent instances in the scene. The type of paired deferred/forward
      renderers is
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KRendererDeferredType.html">KRendererDeferredType</a>
      with the primary implementation given by
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KRendererDeferred.html">KRendererDeferred</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss3" href="#st200_p2s12ss3">2.12.3</a></div><div class="st200_subsection_title">G-Buffer</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg1" href="#st200_p2s12ss3pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term term">g-buffer</span> (the abbreviated form of
      <span class="st200_term term">geometry buffer</span>) is the buffer in which
      the surface attributes of objects are stored prior to having lighting
      applied to produce a final rendered image.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg2" href="#st200_p2s12ss3pg2">2</a></div><div class="st200_paragraph">
      One of the main implementation issues in any deferred renderer is
      deciding which surface attributes (such as position, albedo, normals, etc)
      to store and which to reconstruct. The more attributes that are stored,
      the less work is required during rendering to reconstruct those values.
      However, storing more attributes requires a larger 
      <span class="st200_term term">g-buffer</span> and more memory bandwidth to
      actually populate that <span class="st200_term term">g-buffer</span> during
      rendering. The <span class="st200_term package">io7m-r1</span> package
      leans towards having a more compact <span class="st200_term term">g-buffer</span>
      and doing slightly more reconstruction work during rendering.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss3fo1" href="#st200_p2s12ss3fo1">2.12.3.1. G-Buffer</a></div><img class="st200_image" alt="G-Buffer" src="images/gbuffer.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg3" href="#st200_p2s12ss3pg3">3</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      explicitly stores the albedo, normals, emission level, and specular
      color of surfaces. Additionally, the depth buffer is sampled to recover
      the depth of surfaces. The eye-space positions of surfaces are recovered
      via an efficient <a class="st200_link" href="#st200_p2s13">position reconstruction</a>
      algorithm which uses the current viewing projection and 
      <span class="st200_term term">screen-space</span> depth value as input. In
      order to reduce the amount of storage required, three-dimensional
      eye-space normal vectors are stored compressed as two 
      <span class="st200_term expression">16</span> half-precision floating point components 
      via a simple <a class="st200_link" href="#st200_p2s12ss5">mapping</a>.
      This means that only <span class="st200_term expression">32</span> bits
      are required to store the vectors, and very little precision is lost.
      There is support for optionally storing the vectors as two 
      <span class="st200_term expression">8</span> bit components for systems that
      are memory-starved, with a noticeable loss in the visual quality of
      specular highlights.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg4" href="#st200_p2s12ss3pg4">4</a></div><div class="st200_paragraph">
      The precise format of the g-buffer when using <span class="st200_term expression">16</span>
      bit normals is as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss3fo2" href="#st200_p2s12ss3fo2">2.12.3.2. G-Buffer Format 0</a></div><img class="st200_image" alt="G-Buffer Format 0" src="images/gbuffer_format_0.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg5" href="#st200_p2s12ss3pg5">5</a></div><div class="st200_paragraph">
      The vertical lines indicate byte boundaries. Not including the depth/stencil
      buffer, the amount of storage required per pixel is <span class="st200_term expression">3 * 4 = 12 bytes = 96 bits</span>.
      When <span class="st200_term expression">8</span> bit normals are used, the layout
      format is:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss3fo3" href="#st200_p2s12ss3fo3">2.12.3.3. G-Buffer Format 1</a></div><img class="st200_image" alt="G-Buffer Format 1" src="images/gbuffer_format_1.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss3pg6" href="#st200_p2s12ss3pg6">6</a></div><div class="st200_paragraph">
      The <span class="st200_term variable">albedo_r</span>, <span class="st200_term variable">albedo_g</span>,
      and <span class="st200_term variable">albedo_b</span> components correspond to the
      red, green, and blue components of the surface, respectively. The
      <span class="st200_term variable">emission</span> component refers to the surface
      <a class="st200_link" href="#st200_p2s27">emission</a> level. The
      <span class="st200_term variable">normal_x</span> and
      <span class="st200_term variable">normal_y</span> components correspond to the
      two components of the <a class="st200_link" href="#st200_p2s12ss5">compressed surface normal</a>
      vector. The <span class="st200_term variable">specular_r</span>, 
      <span class="st200_term variable">specular_g</span>, and 
      <span class="st200_term variable">specular_b</span> components correspond to the
      red, green, and blue components of the surface specularity. Surfaces that will
      not receive specular highlights simply have
      <span class="st200_term expression">0</span> for each component. The
      <span class="st200_term variable">specular_e</span> component holds the
      surface <span class="st200_term term">specular exponent</span> divided by
      <span class="st200_term expression">256</span>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss4" href="#st200_p2s12ss4">2.12.4</a></div><div class="st200_subsection_title">Light Group Stencil</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss4pg1" href="#st200_p2s12ss4pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Light groups</span> partition the scene into
      separate lighting environments. A given light <span class="st200_term expression">k</span>
      can be in any number of groups, and will be applied to all instances that are
      in the same group. To implement this, the
      <span class="st200_term package">io7m-r1</span> package uses
      the stencil buffer to control which pixels will receive lighting during
      rendering of each group. Essentially:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss4fo1" href="#st200_p2s12ss4fo1">2.12.4.1. Deferred Rendering</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          A value of <span class="st200_term expression">0</span> in the stencil buffer
          indicates that the current pixel has never been affected by any light
          group. This is the initial state of all pixels.
        </li><li class="st200_list_item">
          A value of <span class="st200_term expression">1</span> in the stencil buffer
          indicates that the current pixel was previously affected by a light
          group.
        </li><li class="st200_list_item">
          A value of <span class="st200_term expression">2</span> in the stencil buffer
          indicates that the current pixel is in the current light group and will
          have lighting applied.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss4pg2" href="#st200_p2s12ss4pg2">2</a></div><div class="st200_paragraph">
      As noted by the <a class="st200_link" href="#st200_p2s12ss2">algorithm</a>
      given above, pixels belonging to the current light group are marked with
      a value of <span class="st200_term expression">2</span> in the stencil buffer
      when all of the surfaces in the light group are rendered into the 
      <span class="st200_term term">g-buffer</span>. Only pixels with a corresponding
      value of <span class="st200_term expression">2</span> in the stencil buffer have
      lighting applied. This is the step that prevents lights in one group from
      affecting surfaces in another group. When a light group has completed
      rendering, all pixels with a non-zero value in the stencil buffer have
      their stencil values set to <span class="st200_term expression">1</span>. When
      all light groups have been rendered, the stencil buffer will contain a
      non-zero value for all pixels that were touched during rendering - this
      fact can then be used in further postprocessing stages if desired.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss5" href="#st200_p2s12ss5">2.12.5</a></div><div class="st200_subsection_title">Normal Compression</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss5pg1" href="#st200_p2s12ss5pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      uses a
      <a class="st200_link_external" href="http://en.wikipedia.org/wiki/Lambert_azimuthal_equal-area_projection">Lambert azimuthal equal-area projection</a>
      to store surface normal vectors in two components instead of three. This
      makes use of the fact that normalized vectors represent points on the
      unit sphere. The mapping from normal vectors to two-dimensional spheremap coordinates
      is given by <span class="st200_term function">compress</span> 
      [<a class="st200_link_external" href="haskell/NormalCompress.hs">NormalCompress.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss5fo1" href="#st200_p2s12ss5fo1">2.12.5.1. Normal Compression</a></div><pre class="st200_verbatim">module NormalCompress where

import qualified Vector3f
import qualified Vector2f
import qualified Normal

compress :: Normal.T -&gt; Vector2f.T
compress n =
  let p = sqrt ((Vector3f.z n * 8.0) + 8.0)
      x = (Vector3f.x n / p) + 0.5
      y = (Vector3f.y n / p) + 0.5
  in Vector2f.V2 x y</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss5pg2" href="#st200_p2s12ss5pg2">2</a></div><div class="st200_paragraph">
      The mapping from two-dimensional spheremap coordinates to normal vectors is given by
      <span class="st200_term function">decompress</span> 
      [<a class="st200_link_external" href="haskell/NormalDecompress.hs">NormalDecompress.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss5fo2" href="#st200_p2s12ss5fo2">2.12.5.2. Normal Decompression</a></div><pre class="st200_verbatim">module NormalDecompress where

import qualified Vector3f
import qualified Vector2f
import qualified Normal

decompress :: Vector2f.T -&gt; Normal.T
decompress v =
  let fn = Vector2f.V2 ((Vector2f.x v * 4.0) - 2.0) ((Vector2f.y v * 4.0) - 2.0)
      f  = Vector2f.dot2 fn fn
      g  = sqrt (1.0 - (f / 4.0))
      x  = (Vector2f.x fn) * g
      y  = (Vector2f.y fn) * g
      z  = 1.0 - (f / 2.0)
  in Vector3f.V3 x y z</pre></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s12ss6" href="#st200_p2s12ss6">2.12.6</a></div><div class="st200_subsection_title">Light Volumes</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s12ss6pg1" href="#st200_p2s12ss6pg1">1</a></div><div class="st200_paragraph">
      In order to apply lighting during deferred rendering, it is necessary
      to render <span class="st200_term term">light volumes</span> representing the
      shape and size of the current light. All pixels that fall within this
      light volume have lighting applied. Specifically:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s12ss6fo1" href="#st200_p2s12ss6fo1">2.12.6.1. Light Volumes</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          <a class="st200_link" href="#st200_p2s20">Spherical</a> lights
          with radius <span class="st200_term expression">r</span> are represented by
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KUnitSphere.html">unit spheres</a>
          with a transform that scales them during rendering to spheres with a resulting radius of
          <span class="st200_term expression">r</span>.
        </li><li class="st200_list_item">
          <a class="st200_link" href="#st200_p2s19">Directional</a> lights
          are represented by full-screen
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KUnitQuad.html">quads</a>.
        </li><li class="st200_list_item">
          <a class="st200_link" href="#st200_p2s21">Projective</a> lights
          are represented by
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KFrustumMesh.html">frustums</a>
          that are created and cached on demand to match the size and shape of the light's projection.
        </li></ul></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s13" href="#st200_p2s13">2.13</a></div><div class="st200_section_title">Deferred Rendering: Position Reconstruction</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss1">2.13.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss2">2.13.2. Recovering Eye-space Z</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss3">2.13.3. Recovering Eye-space Z (Logarithmic depth encoding)</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss4">2.13.4. Recovering Eye-space Z (Screen-space depth encoding)</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss5">2.13.5. Recovering Eye-space Position</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s13ss6">2.13.6. Implementation</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss1" href="#st200_p2s13ss1">2.13.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss1pg1" href="#st200_p2s13ss1pg1">1</a></div><div class="st200_paragraph">
      Applying lighting during <span class="st200_term term">deferred rendering</span>
      is primarily a <a class="st200_link" href="#st200_p2s3ss8">screen space</a>
      technique. When the visible set has been rendered into the
      <a class="st200_link" href="#st200_p2s12ss3">g-buffer</a>, the
      original <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      positions of all of the surfaces that resulted in visible fragments 
      in the scene are lost (unless explicitly saved into the g-buffer). 
      However, given the knowledge of the <span class="st200_term term">projection</span> that was
      used to render the visible set (such as perspective or orthographic), it's
      possible to reconstruct the original eye-space position of the
      surfaces that produced each of the fragments in the g-buffer.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss1pg2" href="#st200_p2s13ss1pg2">2</a></div><div class="st200_paragraph">
      Specifically then, for each fragment <span class="st200_term variable">f</span>
      in the g-buffer for which lighting
      is being applied, a position reconstruction algorithm attempts to
      reconstruct <span class="st200_term expression">surface_eye</span> - the
      eye-space position of the surface that produced 
      <span class="st200_term variable">f</span> using the
      screen-space position of the current light volume fragment
      <span class="st200_term expression">position = (screen_x, screen_y)</span> and
      some form of <span class="st200_term term">depth</span> value (such as the
      screen-space depth of <span class="st200_term variable">f</span>).
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss1pg3" href="#st200_p2s13ss1pg3">3</a></div><div class="st200_paragraph">
      Position reconstruction is a fundamental technique in deferred rendering, 
      and there are a practically unlimited number of ways to reconstruct 
      eye-space positions for fragments, each with various advantages and
      disadvantages. Some rendering systems actually store 
      the eye-space position of each fragment in the g-buffer, meaning that
      reconstructing positions means simply reading a value directly from a 
      texture. Some systems store only a normalized eye-space depth value in a 
      separate texture: The first step of most position reconstruction algorithms
      is to compute the original eye-space Z value of a fragment, so having
      this value computed during the population of the g-buffer reduces the
      work performed later. Storing an entire eye-space position into the
      g-buffer is obviously the simplest and requires the least reconstruction
      work later on, but is costly in terms of memory bandwidth: Storing a full
      eye-space position requires an extra <span class="st200_term expression">4 * 4  = 16</span>
      bytes of storage per fragment (four 32-bit floating point values). As screen 
      resolutions increase, the costs can be prohibitive. Storing a normalized 
      depth value requires only a single 32-bit floating point value per fragment
      but even this can be too much on less capable hardware. Some algorithms
      take advantage of the fact that most projections used to render scenes 
      are perspective projections. Some naive algorithms use the full inverse
      of the current projection matrix to reconstruct eye-space positions
      having already calculated 
      <a class="st200_link" href="#st200_p2s3ss6">clip space</a> positions.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss1pg4" href="#st200_p2s13ss1pg4">4</a></div><div class="st200_paragraph">
      The algorithm that the <span class="st200_term package">io7m-r1</span> package
      uses for position reconstruction is generalized to handle both orthographic
      and perspective projections, and uses only the existing
      <a class="st200_link" href="#st200_p2s14">logarithmic depth values</a>
      that were written to the depth buffer during scene rendering. 
      This keeps the g-buffer compact, and memory bandwidth requirements 
      comparatively low. The algorithm works with symmetric and asymmetric viewing 
      frustums, but will only work with near and far planes that are parallel to the 
      screen.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss1pg5" href="#st200_p2s13ss1pg5">5</a></div><div class="st200_paragraph">
      The algorithm works in two steps: Firstly, the original 
      <a class="st200_link" href="#st200_p2s13ss2">eye-space Z value</a>
      of the fragment in question is recovered, and then this
      Z value is used to recover the full
      <a class="st200_link" href="#st200_p2s13ss5">eye-space position</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss2" href="#st200_p2s13ss2">2.13.2</a></div><div class="st200_subsection_title">Recovering Eye-space Z</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss2pg1" href="#st200_p2s13ss2pg1">1</a></div><div class="st200_paragraph">
      During rendering of arbitrary scenes, vertices specified in
      <a class="st200_link" href="#st200_p2s3ss3">object-space</a>
      are transformed to eye-space, and the eye-space coordinates
      are transformed to
      <a class="st200_link" href="#st200_p2s3ss6">clip-space</a>
      with a <span class="st200_term term">projection matrix</span>. The
      resulting 4D clip-space coordinates are divided by their own
      <span class="st200_term variable">w</span> components, resulting in
      <a class="st200_link" href="#st200_p2s3ss7">normalized-device space</a>
      coordinates. These normalized-device space coordinates are then
      transformed to <a class="st200_link" href="#st200_p2s3ss8">screen-space</a>
      by multiplying by the current <span class="st200_term term">viewport transform</span>.
      The transitions from clip-space to screen-space are handled automatically by
      the graphics hardware.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss2pg2" href="#st200_p2s13ss2pg2">2</a></div><div class="st200_paragraph">
      The first step required is to recover the original eye-space Z value
      of <span class="st200_term variable">f</span>. This involves sampling a
      depth value from the current depth buffer. Sampling
      from the depth buffer is achieved as with any other texture: A particular
      texel is addressed by using coordinates in the range 
      <span class="st200_term expression">[(0, 0), (1, 1)]</span>.
      The <span class="st200_term package">io7m-r1</span> package
      currently assumes that the size of the <span class="st200_term term">viewport</span>
      is the same as that of the framebuffer 
      <span class="st200_term expression">(width, height)</span> and that the bottom left corner
      of the viewport is positioned at <span class="st200_term expression">(0, 0)</span>
      in screen space. Given the assumption on the position and size of the viewport,
      and assuming that the screen-space position of the current light volume fragment 
      being shaded is <span class="st200_term expression">position = (screen_x, screen_y)</span>, 
      the texture coordinates <span class="st200_term expression">(screen_uv_x, screen_uv_y)</span> 
      used to access the current depth value are given by:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss2fo1" href="#st200_p2s13ss2fo1">2.13.2.1. Screen to texture</a></div><pre class="st200_verbatim">module ScreenToTexture where

import qualified Vector2f

screen_to_texture :: Vector2f.T -&gt; Float -&gt; Float -&gt; Vector2f.T
screen_to_texture position width height =
  let u = (Vector2f.x position) / width
      v = (Vector2f.y position) / height
  in Vector2f.V2 u v
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss2pg3" href="#st200_p2s13ss2pg3">3</a></div><div class="st200_paragraph">
      Intuitively, <span class="st200_term expression">(screen_uv_x, screen_uv_y) = (0, 0)</span>
      when the current screen-space position is the bottom-left corner of the screen,
      <span class="st200_term expression">(screen_uv_x, screen_uv_y) = (1, 1)</span> when
      the current screen-space position is the top-right corner of the screen, and
      <span class="st200_term expression">(screen_uv_x, screen_uv_y) = (0.5, 0.5)</span> when
      the current screen-space position is the exact center of the screen.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss2pg4" href="#st200_p2s13ss2pg4">4</a></div><div class="st200_paragraph">
      Originally, the <span class="st200_term package">io7m-r1</span> package
      used a standard depth buffer and so recovering the eye-space Z value
      required a slightly different method compared to the steps required for the
      <a class="st200_link" href="#st200_p2s14">logarithmic depth encoding</a> that
      the package now uses. For historical reasons and for completeness, the method
      to reconstruct an eye-space Z value from a traditional screen-space depth
      value is given in the section on
      <a class="st200_link" href="#st200_p2s13ss4">screen-space depth encoding</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss3" href="#st200_p2s13ss3">2.13.3</a></div><div class="st200_subsection_title">Recovering Eye-space Z (Logarithmic depth encoding)</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss3pg1" href="#st200_p2s13ss3pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package now
      uses a <a class="st200_link" href="#st200_p2s14">logarithmic depth buffer</a>.
      Depth values sampled from any depth buffer produced by the package can be
      transformed to a negated eye-space Z value by with a simple decoding
      <a class="st200_link" href="#st200_p2s14ss3">equation</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss4" href="#st200_p2s13ss4">2.13.4</a></div><div class="st200_subsection_title">Recovering Eye-space Z (Screen-space depth encoding)</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg1" href="#st200_p2s13ss4pg1">1</a></div><div class="st200_paragraph">
      Note: This section is for completeness and historical interest. Please skip
      ahead to the section on
      <a class="st200_link" href="#st200_p2s13ss5">eye-space position reconstruction</a>
      if you are not interested.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg2" href="#st200_p2s13ss4pg2">2</a></div><div class="st200_paragraph">
      Assuming a screen-space depth value <span class="st200_term variable">screen_depth</span>
      sampled from the depth buffer at <span class="st200_term expression">(screen_uv_x, screen_uv_y)</span>,
      it's now necessary to transform the depth value back into
      normalized-device space. In OpenGL, screen-space depth values are in the range
      <span class="st200_term expression">[0, 1]</span> by default, with
      <span class="st200_term expression">0</span> representing the near plane and
      <span class="st200_term expression">1</span> representing the far plane. However, in
      OpenGL, normalized-device space coordinates are in the range 
      <span class="st200_term expression">[(-1, -1, -1), (1, 1, 1)]</span>. The transformation
      from screen-space to normalized-device space is given by:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo1" href="#st200_p2s13ss4fo1">2.13.4.1. Screen-space depth to NDC Z</a></div><pre class="st200_verbatim">module ScreenDepthToNDC where

screen_depth_to_ndc :: Float -&gt; Float
screen_depth_to_ndc screen_depth =
  (screen_depth * 2.0) - 1.0</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg3" href="#st200_p2s13ss4pg3">3</a></div><div class="st200_paragraph">
      In order to understand how to calculate the eye-space depth value
      from the resulting NDC Z value 
      <span class="st200_term variable">ndc_z = screen_depth_to_ndc screen_depth</span>,
      it's necessary to understand how the normalized-device coordinates of
      <span class="st200_term variable">f</span>
      were derived in the first place. Given a standard 4x4 projection matrix 
      <span class="st200_term variable">m</span> and an eye-space position 
      <span class="st200_term variable">eye</span>, clip-space coordinates are
      calculated by <span class="st200_term variable">Matrix4x4f.mult_v m eye</span>.
      This means that the <span class="st200_term variable">z</span>
      component of the resulting clip-space coordinates is given by:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo2" href="#st200_p2s13ss4fo2">2.13.4.2. Clip-space Z Long (Diagram)</a></div><img class="st200_image" alt="Clip-space Z Long (Diagram)" src="images/matrix_clip_z_long.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo3" href="#st200_p2s13ss4fo3">2.13.4.3. Clip-space Z Long</a></div><pre class="st200_verbatim">module ClipSpaceZLong where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_z_long :: M4x4.T -&gt; V4.T -&gt; Float
clip_z_long m eye =
  let
    m20 = M4x4.row_column m (2, 0)
    m21 = M4x4.row_column m (2, 1)
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)

    k0 = (V4.x eye) * m20
    k1 = (V4.y eye) * m21
    k2 = (V4.z eye) * m22
    k3 = (V4.w eye) * m23
  in
    k0 + k1 + k2 + k3
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg4" href="#st200_p2s13ss4pg4">4</a></div><div class="st200_paragraph">
      Similarly, the <span class="st200_term variable">w</span>
      component of the resulting clip-space coordinates is given by:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo4" href="#st200_p2s13ss4fo4">2.13.4.4. Clip-space W Long (Diagram)</a></div><img class="st200_image" alt="Clip-space W Long (Diagram)" src="images/matrix_clip_w_long.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo5" href="#st200_p2s13ss4fo5">2.13.4.5. Clip-space W Long</a></div><pre class="st200_verbatim">module ClipSpaceWLong where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_w_long :: M4x4.T -&gt; V4.T -&gt; Float
clip_w_long m eye =
  let
    m30 = M4x4.row_column m (3, 0)
    m31 = M4x4.row_column m (3, 1)
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)

    k0 = (V4.x eye) * m30
    k1 = (V4.y eye) * m31
    k2 = (V4.z eye) * m32
    k3 = (V4.w eye) * m33
  in
    k0 + k1 + k2 + k3
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg5" href="#st200_p2s13ss4pg5">5</a></div><div class="st200_paragraph">
      However, in the perspective and orthographic projections provided
      by the <span class="st200_term package">io7m-r1</span> package,
      <span class="st200_term expression">Matrix4x4f.row_column m (2, 0) == 0</span>,
      <span class="st200_term expression">Matrix4x4f.row_column m (2, 1) == 0</span>,
      <span class="st200_term expression">Matrix4x4f.row_column m (3, 0) == 0</span>,
      and <span class="st200_term expression">Matrix4x4f.row_column m (3, 1) == 0</span>.
      Additionally, the <span class="st200_term variable">w</span> component of all
      eye-space coordinates is <span class="st200_term expression">1</span>. With
      these assumptions, the previous definitions simplify to:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo6" href="#st200_p2s13ss4fo6">2.13.4.6. Clip-space Z Simple (Diagram)</a></div><img class="st200_image" alt="Clip-space Z Simple (Diagram)" src="images/matrix_clip_z_simple.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo7" href="#st200_p2s13ss4fo7">2.13.4.7. Clip-space Z Simple</a></div><pre class="st200_verbatim">module ClipSpaceZSimple where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_z_simple :: M4x4.T -&gt; V4.T -&gt; Float
clip_z_simple m eye =
  let
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)
  in
    ((V4.z eye) * m22) + m23
</pre></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo8" href="#st200_p2s13ss4fo8">2.13.4.8. Clip-space W Simple (Diagram)</a></div><img class="st200_image" alt="Clip-space W Simple (Diagram)" src="images/matrix_clip_w_simple.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo9" href="#st200_p2s13ss4fo9">2.13.4.9. Clip-space W Simple</a></div><pre class="st200_verbatim">module ClipSpaceWSimple where

import qualified Matrix4f as M4x4;
import qualified Vector4f as V4;

clip_w_simple :: M4x4.T -&gt; V4.T -&gt; Float
clip_w_simple m eye =
  let
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)
  in
    ((V4.z eye) * m32) + m33
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg6" href="#st200_p2s13ss4pg6">6</a></div><div class="st200_paragraph">
      It should be noted that for perspective matrices in the
      <span class="st200_term package">io7m-r1</span> package,
      <span class="st200_term expression">Matrix4x4f.row_column m (3, 2) == -1</span> and
      <span class="st200_term expression">Matrix4x4f.row_column m (3, 3) == 0</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo10" href="#st200_p2s13ss4fo10">2.13.4.10. Clip-space W Simple (Perspective, Diagram)</a></div><img class="st200_image" alt="Clip-space W Simple (Perspective, Diagram)" src="images/matrix_clip_w_simple_perspective.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg7" href="#st200_p2s13ss4pg7">7</a></div><div class="st200_paragraph">
      This means that the <span class="st200_term variable">w</span> component of the
      resulting clip-space coordinates is equal to the negated (and therefore positive)
      eye-space <span class="st200_term variable">z</span> of the original coordinates.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg8" href="#st200_p2s13ss4pg8">8</a></div><div class="st200_paragraph">
      For orthographic projections in the
      <span class="st200_term package">io7m-r1</span> package,
      <span class="st200_term expression">Matrix4x4f.row_column m (3, 2) == 0</span> and
      <span class="st200_term expression">Matrix4x4f.row_column m (3, 3) == 1</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo11" href="#st200_p2s13ss4fo11">2.13.4.11. Clip-space W Simple (Orthographic, Diagram)</a></div><img class="st200_image" alt="Clip-space W Simple (Orthographic, Diagram)" src="images/matrix_clip_w_simple_orthographic.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg9" href="#st200_p2s13ss4pg9">9</a></div><div class="st200_paragraph">
      This means that the <span class="st200_term variable">w</span> component of the
      resulting clip-space coordinates is always equal to <span class="st200_term constant">1</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss4pg10" href="#st200_p2s13ss4pg10">10</a></div><div class="st200_paragraph">
      As stated previously, normalized-device space coordinates are calculated
      by dividing a set of clip-space coordinates by their own 
      <span class="st200_term variable">w</span> component. So, given
      <span class="st200_term expression">clip_z = ClipSpaceZSimple.clip_z_simple m eye</span>
      and
      <span class="st200_term expression">clip_w = ClipSpaceWSimple.clip_w_simple m eye</span>
      for some arbitrary projection matrix <span class="st200_term variable">m</span> and
      eye-space position <span class="st200_term variable">eye</span>, the normalized-device
      space Z coordinate is given by <span class="st200_term expression">ndc_z = clip_z / clip_w</span>. 
      Rearranging the definitions of <span class="st200_term expression">clip_z</span> and
      <span class="st200_term expression">clip_w</span> algebraically yields an equation
      that takes an arbitrary projection matrix <span class="st200_term variable">m</span>
      and a normalized-device space Z value <span class="st200_term expression">ndc_z</span>
      and returns an eye-space Z value:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss4fo12" href="#st200_p2s13ss4fo12">2.13.4.12. Eye-space Z</a></div><pre class="st200_verbatim">module EyeSpaceZ where

import qualified Matrix4f as M4x4;

eye_z :: M4x4.T -&gt; Float -&gt; Float
eye_z m ndc_z =
  let
    m22 = M4x4.row_column m (2, 2)
    m23 = M4x4.row_column m (2, 3)
    m32 = M4x4.row_column m (3, 2)
    m33 = M4x4.row_column m (3, 3)
    
    a = (ndc_z * m33) - m32
    b = (ndc_z * m23) - m22
  in
    - (a / b)
</pre></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss5" href="#st200_p2s13ss5">2.13.5</a></div><div class="st200_subsection_title">Recovering Eye-space Position</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg1" href="#st200_p2s13ss5pg1">1</a></div><div class="st200_paragraph">
      Given that the eye-space Z value is known, it's now necessary to reconstruct
      the full eye-space position <span class="st200_term expression">surface_eye</span>
      of the surface that resulted in <span class="st200_term variable">f</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg2" href="#st200_p2s13ss5pg2">2</a></div><div class="st200_paragraph">
      When the current projection is a perspective projection, there is conceptually
      a ray passing through the near clipping plane (<span class="st200_term variable">near</span>)
      from the origin, oriented towards the eye-space position 
      (<span class="st200_term variable">eye</span>) of <span class="st200_term variable">f</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo1" href="#st200_p2s13ss5fo1">2.13.5.1. Perspective projection (Diagram)</a></div><img class="st200_image" alt="Perspective projection (Diagram)" src="images/reconstruction_view_perspective.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg3" href="#st200_p2s13ss5pg3">3</a></div><div class="st200_paragraph">
      When the current projection is an orthographic projection, the ray is always
      perpendicular to the clipping planes and is offset by a certain amount 
      (<span class="st200_term variable">q</span>) on the X and Y axes:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo2" href="#st200_p2s13ss5fo2">2.13.5.2. Orthographic projection (Diagram)</a></div><img class="st200_image" alt="Orthographic projection (Diagram)" src="images/reconstruction_view_ortho.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg4" href="#st200_p2s13ss5pg4">4</a></div><div class="st200_paragraph">
      Assuming <span class="st200_term expression">ray = Vector3f.V3 ray_x ray_y 1.0</span>,
      the eye-space position of <span class="st200_term variable">f</span> is given by
      <span class="st200_term expression">surface_eye = Vector3f.add3 q (Vector3f.scale ray eye_z)</span>.
      In the case of perspective projections, 
      <span class="st200_term expression">q = Vector3f.V3 0.0 0.0 0.0</span>. The
      <span class="st200_term variable">q</span> term is sometimes referred to as the
      origin (because <span class="st200_term variable">q</span> is the origin of the view ray), 
      but that terminology is not used here in order to avoid confusion
      between the <span class="st200_term variable">ray</span> origin and the
      eye-space coordinate system origin. It's
      therefore necessary to calculate <span class="st200_term variable">q</span> and
      <span class="st200_term variable">ray</span> in order to reconstruct the full eye-space
      position of the fragment. The way this is achieved in the 
      <span class="st200_term package">io7m-r1</span> 
      package is to calculate <span class="st200_term variable">q</span> and
      <span class="st200_term variable">ray</span> for each of the viewing frustum corners
      <span class="st200_footnote_reference"><a id="st200_fn_24_ref" href="#st200_fn_24">[24]</a></span>
      and then bilinearly interpolate between the calculated values during rendering
      based on <span class="st200_term expression">screen_uv_x</span> and 
      <span class="st200_term expression">screen_uv_y</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg5" href="#st200_p2s13ss5pg5">5</a></div><div class="st200_paragraph">
      As stated previously, normalized-device space coordinates are in the range 
      <span class="st200_term expression">[(-1, -1, -1), (1, 1, 1)]</span>. Stating each
      of the eight corners of the cube that defines normalized-device space as 
      4D homogeneous coordinates <span class="st200_footnote_reference"><a id="st200_fn_25_ref" href="#st200_fn_25">[25]</a></span> yields the following values:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo3" href="#st200_p2s13ss5fo3">2.13.5.3. Normalized-device space corners</a></div><pre class="st200_verbatim">module NDCCorners where

import qualified Vector4f as V4

near_x0y0 :: V4.T
near_x0y0 = V4.V4 (-1.0) (-1.0) (-1.0) 1.0

near_x1y0 :: V4.T
near_x1y0 = V4.V4 1.0 (-1.0) (-1.0) 1.0

near_x0y1 :: V4.T
near_x0y1 = V4.V4 (-1.0) 1.0 (-1.0) 1.0

near_x1y1 :: V4.T
near_x1y1 = V4.V4 1.0 1.0 (-1.0) 1.0

far_x0y0 :: V4.T
far_x0y0 = V4.V4 (-1.0) (-1.0) 1.0 1.0

far_x1y0 :: V4.T
far_x1y0 = V4.V4 1.0 (-1.0) 1.0 1.0

far_x0y1 :: V4.T
far_x0y1 = V4.V4 (-1.0) 1.0 1.0 1.0

far_x1y1 :: V4.T
far_x1y1 = V4.V4 1.0 1.0 1.0 1.0

</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg6" href="#st200_p2s13ss5pg6">6</a></div><div class="st200_paragraph">
      Then, for the four pairs of near/far corners
      (<span class="st200_term expression">(near_x0y0, far_x0y0)</span>,
      <span class="st200_term expression">(near_x1y0, far_x1y0)</span>,
      <span class="st200_term expression">(near_x0y1, far_x0y1)</span>,
      <span class="st200_term expression">(near_x1y1, far_x1y1)</span>), a
      <span class="st200_term variable">q</span> and
      <span class="st200_term variable">ray</span> value is calculated. The
      <span class="st200_term expression">ray_and_q</span> function describes the
      calculation for a given pair of near/far corners:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo4" href="#st200_p2s13ss5fo4">2.13.5.4. Ray and Q calculation (Single)</a></div><pre class="st200_verbatim">module RayAndQ where

import qualified Matrix4f as M4x4
import qualified Vector4f as V4

-- | Calculate @(ray, q)@ for the given inverse projection matrix and frustum corners
ray_and_q :: M4x4.T -&gt; (V4.T, V4.T) -&gt; (V4.T, V4.T)
ray_and_q inverse_m (near, far) =
  let
    -- Unproject the NDC coordinates to eye-space
    near_hom    = M4x4.mult_v inverse_m near
    near_eye    = V4.div_s near_hom (V4.w near_hom)
    far_hom     = M4x4.mult_v inverse_m far
    far_eye     = V4.div_s far_hom (V4.w far_hom)
    
    -- Calculate a ray with ray.z == 1.0
    ray_initial = V4.sub4 far_eye near_eye
    ray = V4.div_s ray_initial (V4.z ray_initial)
    
    -- Subtract the scaled ray from the near corner to calculate q
    q = V4.sub4 near_eye (V4.scale ray (V4.z near_eye))
  in
    (ray, q)
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg7" href="#st200_p2s13ss5pg7">7</a></div><div class="st200_paragraph">
      The function takes a matrix representing the <span class="st200_term term">inverse</span>
      of the current projection matrix, and "unprojects" the given near and far frustum
      corners from normalized-device space to eye-space. The desired 
      <span class="st200_term variable">ray</span> value for the pair of corners is simply
      the vector that results from subtracting the near corner from the far corner,
      divided by its own <span class="st200_term variable">z</span> component. The desired
      <span class="st200_term variable">q</span> value is the vector that results from
      subtracting <span class="st200_term variable">ray</span> scaled by the 
      <span class="st200_term variable">z</span> component of the near corner, from
      the near corner. 
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg8" href="#st200_p2s13ss5pg8">8</a></div><div class="st200_paragraph">
      Note: The function calculates <span class="st200_term variable">ray</span> in eye-space, 
      but the resulting value will have a non-negative <span class="st200_term variable">z</span> component. 
      The reason for this is that the resulting ray will be multiplied by the calculated
      <a class="st200_link" href="#st200_p2s13ss2">eye-space Z value</a>
      <span class="st200_footnote_reference"><a id="st200_fn_26_ref" href="#st200_fn_26">[26]</a></span>
      to produce an eye-space position. If the <span class="st200_term variable">z</span> component of 
      <span class="st200_term variable">ray</span> was negative, the resulting position
      would have a positive <span class="st200_term variable">z</span> component.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg9" href="#st200_p2s13ss5pg9">9</a></div><div class="st200_paragraph">
      Calculating the <span class="st200_term variable">ray</span>
      and <span class="st200_term variable">q</span> value for each of the pairs of
      corners is straightforward:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo5" href="#st200_p2s13ss5fo5">2.13.5.5. Ray and Q calculation (All)</a></div><pre class="st200_verbatim">module RayAndQAll where

import qualified NDCCorners
import qualified RayAndQ
import qualified Matrix4f as M4x4
import qualified Vector4f as V4

data T = T {
  q_x0y0 :: V4.T,
  q_x1y0 :: V4.T,
  q_x0y1 :: V4.T,
  q_x1y1 :: V4.T,
  ray_x0y0 :: V4.T,
  ray_x1y0 :: V4.T,
  ray_x0y1 :: V4.T,
  ray_x1y1 :: V4.T
} deriving (Eq, Ord, Show)

-- | Calculate all rays and qs for the four pairs of near/far frustum corners
calculate :: M4x4.T -&gt; T
calculate inverse_m =
  let
    (x0y0_ray, x0y0_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x0y0, NDCCorners.far_x0y0)
    (x1y0_ray, x1y0_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x1y0, NDCCorners.far_x1y0)
    (x0y1_ray, x0y1_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x0y1, NDCCorners.far_x0y1)
    (x1y1_ray, x1y1_q) = RayAndQ.ray_and_q inverse_m (NDCCorners.near_x1y1, NDCCorners.far_x1y1)
  in
    T {
      q_x0y0 = x0y0_q,
      q_x1y0 = x1y0_q,
      q_x0y1 = x0y1_q,
      q_x1y1 = x1y1_q,
      ray_x0y0 = x0y0_ray,
      ray_x1y0 = x1y0_ray,
      ray_x0y1 = x0y1_ray,
      ray_x1y1 = x1y1_ray
    }
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg10" href="#st200_p2s13ss5pg10">10</a></div><div class="st200_paragraph">
      Then, by reusing the <span class="st200_term expression">position = (screen_uv_x, screen_uv_y)</span>
      values calculated during the initial
      <a class="st200_link" href="#st200_p2s13ss2pg2">eye-space Z</a>
      calculation, determining <span class="st200_term variable">ray</span> and
      <span class="st200_term variable">q</span> for the current fragment involves
      simply bilinearly interpolating between the precalculated values above.
      Bilinear interpolation between four vectors is defined as:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss5fo6" href="#st200_p2s13ss5fo6">2.13.5.6. Bilinear interpolation (Vector4f)</a></div><pre class="st200_verbatim">module Bilinear4 where

import qualified Vector2f as V2
import qualified Vector4f as V4

interpolate :: (V4.T, V4.T, V4.T, V4.T) -&gt; V2.T -&gt; V4.T
interpolate (x0y0, x1y0, x0y1, x1y1) position =
  let u0 = V4.interpolate x0y0 (V2.x position) x1y0
      u1 = V4.interpolate x0y1 (V2.x position) x1y1
  in V4.interpolate u0 (V2.y position) u1
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss5pg11" href="#st200_p2s13ss5pg11">11</a></div><div class="st200_paragraph">
      Finally, now that all of the required components are known, the eye-space
      position <span class="st200_term variable">surface_eye</span> of <span class="st200_term variable">f</span>
      is calculated as <span class="st200_term expression">surface_eye = Vector3f.add3 q (Vector3f.scale ray eye_z)</span>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s13ss6" href="#st200_p2s13ss6">2.13.6</a></div><div class="st200_subsection_title">Implementation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss6pg1" href="#st200_p2s13ss6pg1">1</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package,
      the <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KViewRays.html">KViewRays</a>
      class precalculates the
      <a class="st200_link" href="#st200_p2s13ss5pg7">rays and q values</a>
      for each of the current frustum corners, and the results of which are cached
      and re-used based on the current projection each time the scene is rendered.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss6pg2" href="#st200_p2s13ss6pg2">2</a></div><div class="st200_paragraph">
      The actual position reconstruction is performed in a
       <span class="st200_term term">fragment shader</span>, producing an eye-space
       Z value using the <span class="st200_term package">Parasol</span> functions in
       [<a class="st200_link_external" href="parasol/LogDepth.p">LogDepth.p</a>]
       and the final position in
       [<a class="st200_link_external" href="parasol/Reconstruction.p">Reconstruction.p</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss6fo1" href="#st200_p2s13ss6fo1">2.13.6.1. Position reconstruction (LogDepth)</a></div><pre class="st200_verbatim">--
-- Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com
-- 
-- Permission to use, copy, modify, and/or distribute this software for any
-- purpose with or without fee is hereby granted, provided that the above
-- copyright notice and this permission notice appear in all copies.
-- 
-- THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
-- WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
-- MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
-- SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
-- WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
-- ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
-- IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
--

package com.io7m.r1.core;

--
-- Functions for handling logarithmic depth buffers.
--

module LogDepth is

  import com.io7m.parasol.Float as F;

  function prepare_eye_z (z : float) : float =
    F.add (F.negate (z), 1.0);

  function encode_partial (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let 
      value half_co = F.multiply (depth_coefficient, 0.5);
      value clamp_z = F.maximum (0.000001, z);
    in
      F.multiply (F.log2 (clamp_z), half_co)
    end;

  function encode_full (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let 
      value half_co = F.multiply (depth_coefficient, 0.5);
      value clamp_z = F.maximum (0.000001, F.add (z, 1.0));
    in
      F.multiply (F.log2 (clamp_z), half_co)
    end;

  function decode (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let value half_co = F.multiply (depth_coefficient, 0.5); in
      F.subtract (F.power (2.0, F.divide (z, half_co)), 1.0)
    end;

end;
</pre></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss6fo2" href="#st200_p2s13ss6fo2">2.13.6.2. Position reconstruction (Parasol)</a></div><pre class="st200_verbatim">--
-- Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com
--
-- Permission to use, copy, modify, and/or distribute this software for any
-- purpose with or without fee is hereby granted, provided that the above
-- copyright notice and this permission notice appear in all copies.
--
-- THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
-- WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
-- MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
-- SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
-- WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
-- ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
-- IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
--

package com.io7m.r1.core;

--
-- Position reconstruction for deferred rendering.
--

module Reconstruction is

  import com.io7m.parasol.Float as F;
  import com.io7m.parasol.Vector2f as V2;
  import com.io7m.parasol.Vector3f as V3;
  import com.io7m.parasol.Vector4f as V4;

  import com.io7m.r1.core.Bilinear;
  import com.io7m.r1.core.Transform;
  import com.io7m.r1.core.Viewport;
  import com.io7m.r1.core.ViewRays;

  function reconstruct_eye (
    screen_depth : float,
    screen_uv    : vector_2f,
    m_projection : matrix_4x4f,
    view_rays    : ViewRays.t
  ) : vector_4f =
    let
      value eye_depth =
        Transform.ndc_to_eye_z (
          m_projection,
          Transform.screen_depth_to_ndc (screen_depth)
        );
    in
      reconstruct_eye_with_eye_z (
        eye_depth, 
        screen_uv, 
        m_projection, 
        view_rays
      )
    end;

  function reconstruct_eye_with_eye_z (
    eye_depth    : float,
    screen_uv    : vector_2f,
    m_projection : matrix_4x4f,
    view_rays    : ViewRays.t
  ) : vector_4f =
    let
      value origin =
        Bilinear.interpolate_3f (
          view_rays.origin_x0y0,
          view_rays.origin_x1y0,
          view_rays.origin_x0y1,
          view_rays.origin_x1y1,
          screen_uv
        );

      value ray_normal =
        Bilinear.interpolate_3f (
          view_rays.ray_x0y0,
          view_rays.ray_x1y0,
          view_rays.ray_x0y1,
          view_rays.ray_x1y1,
          screen_uv
        );
        
      value ray =
        V3.multiply_scalar (
          ray_normal,
          eye_depth
        );
    in
      new vector_4f (V3.add (origin, ray), 1.0)
    end;

end;
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s13ss6pg3" href="#st200_p2s13ss6pg3">3</a></div><div class="st200_paragraph">
      The precalculated view ray vectors are passed to the fragment shader
      in a value of type <span class="st200_term type">ViewRays.t</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s13ss6fo3" href="#st200_p2s13ss6fo3">2.13.6.3. View Rays (Parasol)</a></div><pre class="st200_verbatim">--
-- Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com
--
-- Permission to use, copy, modify, and/or distribute this software for any
-- purpose with or without fee is hereby granted, provided that the above
-- copyright notice and this permission notice appear in all copies.
--
-- THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
-- WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
-- MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
-- SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
-- WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
-- ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
-- IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
--

package com.io7m.r1.core;

module ViewRays is

  type t is record
    origin_x0y0 : vector_3f,
    origin_x1y0 : vector_3f,
    origin_x0y1 : vector_3f,
    origin_x1y1 : vector_3f,
    ray_x0y0    : vector_3f,
    ray_x1y0    : vector_3f,
    ray_x0y1    : vector_3f,
    ray_x1y1    : vector_3f
  end;

end;
</pre></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s14" href="#st200_p2s14">2.14</a></div><div class="st200_section_title">Logarithmic Depth</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s14ss1">2.14.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s14ss2">2.14.2. OpenGL Depth Issues</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s14ss3">2.14.3. Logarithmic Encoding</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s14ss1" href="#st200_p2s14ss1">2.14.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss1pg1" href="#st200_p2s14ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      exclusively utilizes a so-called 
      <span class="st200_term term">logarithmic depth buffer</span> for all
      rendering operations.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s14ss2" href="#st200_p2s14ss2">2.14.2</a></div><div class="st200_subsection_title">OpenGL Depth Issues</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss2pg1" href="#st200_p2s14ss2pg1">1</a></div><div class="st200_paragraph">
      By default, OpenGL (effectively) stores a depth value
      proportional to the reciprocal of the
      <span class="st200_term variable">z</span> component of the 
      <a class="st200_link" href="#st200_p2s3ss6">clip-space</a>
      coordinates of each vertex projected onto the screen
      <span class="st200_footnote_reference"><a id="st200_fn_27_ref" href="#st200_fn_27">[27]</a></span>. Informally,
      the <span class="st200_term term">perspective projection</span> matrix 
      used to transform
      <a class="st200_link" href="#st200_p2s3ss5">eye-space</a>
      coordinates to clip-space will place the negated 
      <span class="st200_term variable">z</span> component of the original
      eye-space coordinates into the 
      <span class="st200_term variable">w</span> component of the resulting
      clip-space coordinates. When the hardware performs the
      <a class="st200_link" href="#st200_p2s3ss7">division by w</a>
      to produce normalized-device-space coordinates, the resulting
      <span class="st200_term variable">z</span> component falls within
      the range <span class="st200_term expression">[-1.0, 1.0]</span>
      (although any point with a <span class="st200_term variable">z</span> component
      less than <span class="st200_term constant">0</span> will be clipped
      away by the clipping hardware). This final value is linearly
      mapped to a configurable range (typically 
      <span class="st200_term expression">[0.0, 1.0]</span>) to produce a 
      <a class="st200_link" href="#st200_p2s3ss8">screen-space</a>
      depth value.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss2pg2" href="#st200_p2s14ss2pg2">2</a></div><div class="st200_paragraph">
      Unfortunately, the encoding scheme above means that most of
      the depth buffer is essentially wasted. The above scheme will
      give excessive precision for objects close to the viewing plane,
      and almost none for objects further away. Fortunately, a better
      encoding scheme known as <span class="st200_term term">logarithmic depth</span>
      <span class="st200_footnote_reference"><a id="st200_fn_28_ref" href="#st200_fn_28">[28]</a></span> can be implemented that provides 
      <span class="st200_term emphasis">vastly</span> greater precision
      and coexists happily with the standard projection matrices
      used in OpenGL-based renderers.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s14ss3" href="#st200_p2s14ss3">2.14.3</a></div><div class="st200_subsection_title">Logarithmic Encoding</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg1" href="#st200_p2s14ss3pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">logarithmic depth value</span> is
      produced by encoding a negated (and therefore <span class="st200_term term">positive</span>)
      eye-space <span class="st200_term variable">z</span> value in the
      manner specified by <span class="st200_term function">encode</span>
      [<a class="st200_link_external" href="haskell/LogDepth.hs">LogDepth.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s14ss3fo1" href="#st200_p2s14ss3fo1">2.14.3.1. Logarithmic Depth (Encoding)</a></div><pre class="st200_verbatim">module LogDepth where

newtype LogDepth =
  LogDepth Float
    deriving (Eq, Ord, Show)

type Depth = Float

log2 :: Float -&gt; Float
log2 = logBase 2.0

depth_coefficient :: Float -&gt; Float
depth_coefficient far = 2.0 / log2 (far + 1.0)

encode :: Float -&gt; Depth -&gt; LogDepth
encode depth_co depth =
  let hco = depth_co * 0.5 in
    LogDepth $ log2 (depth + 1.0) * hco

decode :: Float -&gt; LogDepth -&gt; Depth
decode depth_co (LogDepth depth) =
  let hco = depth_co * 0.5 in
    (2.0 ** (depth / hco)) - 1
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg2" href="#st200_p2s14ss3pg2">2</a></div><div class="st200_paragraph">
      The function is parameterized by a so-called
      <span class="st200_term term">depth coefficient</span> that is
      derived from the <span class="st200_term term">far plane distance</span>
      as shown by <span class="st200_term expression">depth_coefficient</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg3" href="#st200_p2s14ss3pg3">3</a></div><div class="st200_paragraph">
      The inverse of <span class="st200_term function">encode</span> is
      <span class="st200_term function">decode</span>, such that 
      for a given negated eye-space <span class="st200_term variable">z</span>,
      <span class="st200_term expression">z = decode d (encode d z)</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg4" href="#st200_p2s14ss3pg4">4</a></div><div class="st200_paragraph">
      A graph of the functions is as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s14ss3fo2" href="#st200_p2s14ss3fo2">2.14.3.2. Logarithmic Depth (Graph)</a></div><img class="st200_image" alt="Logarithmic Depth (Graph)" src="images/log_depth.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg5" href="#st200_p2s14ss3pg5">5</a></div><div class="st200_paragraph">
      An interactive <a class="st200_link_external" href="http://geogebra.org">GeoGebra</a>
      construction is provided in
      [<a class="st200_link_external" href="log_depth.ggb">log_depth.ggb</a>]
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg6" href="#st200_p2s14ss3pg6">6</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      uses a slightly modified version of the encoding function that clamps
      the original <span class="st200_term variable">z</span> value to the range
      <span class="st200_term expression">[0.000001, â]</span>. The reason for this
      is that <span class="st200_term expression">log2 (0)</span> is undefined, and
      so attempting to derive a depth value in this manner tends to cause
      issues with triangle clipping. The encoding function is also separated
      into two parts as a simple optimization: The encoding function contains
      a term <span class="st200_term expression">z + 1.0</span>, and this term can
      be calculated by a <span class="st200_term term">vertex shader</span> and
      interpolated. The actual functions as implemented are given by
      [<a class="st200_link_external" href="parasol/LogDepth.p">LogDepth.p</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s14ss3fo3" href="#st200_p2s14ss3fo3">2.14.3.3. Logarithmic Depth (Parasol)</a></div><pre class="st200_verbatim">--
-- Copyright Â© 2014 &lt;code@io7m.com&gt; http://io7m.com
-- 
-- Permission to use, copy, modify, and/or distribute this software for any
-- purpose with or without fee is hereby granted, provided that the above
-- copyright notice and this permission notice appear in all copies.
-- 
-- THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
-- WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
-- MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
-- SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
-- WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
-- ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR
-- IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
--

package com.io7m.r1.core;

--
-- Functions for handling logarithmic depth buffers.
--

module LogDepth is

  import com.io7m.parasol.Float as F;

  function prepare_eye_z (z : float) : float =
    F.add (F.negate (z), 1.0);

  function encode_partial (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let 
      value half_co = F.multiply (depth_coefficient, 0.5);
      value clamp_z = F.maximum (0.000001, z);
    in
      F.multiply (F.log2 (clamp_z), half_co)
    end;

  function encode_full (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let 
      value half_co = F.multiply (depth_coefficient, 0.5);
      value clamp_z = F.maximum (0.000001, F.add (z, 1.0));
    in
      F.multiply (F.log2 (clamp_z), half_co)
    end;

  function decode (
    z                 : float,
    depth_coefficient : float  
  ) : float =
    let value half_co = F.multiply (depth_coefficient, 0.5); in
      F.subtract (F.power (2.0, F.divide (z, half_co)), 1.0)
    end;

end;
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg7" href="#st200_p2s14ss3pg7">7</a></div><div class="st200_paragraph">
      A fragment shader can use <span class="st200_term function">encode_full</span>
      to compute a logarithmic depth value from a given positive eye-space 
      <span class="st200_term variable">z</span> value. Alternatively, a vertex
      shader can compute the <span class="st200_term expression">z + 1.0</span>
      term <span class="st200_term variable">r</span> from a non-negated eye-space 
      <span class="st200_term variable">z</span>
      value, and pass <span class="st200_term variable">r</span> to a cooperating
      fragment shader which then finishes the computation by applying
      <span class="st200_term function">encode_partial</span> to
      <span class="st200_term variable">r</span>. When performing 
      <a class="st200_link" href="#st200_p2s13">position reconstruction</a>
      during <span class="st200_term term">deferred rendering</span>, the original
      eye-space <span class="st200_term variable">z</span> value of a fragment is
      retrieved by negating the result of <span class="st200_term function">decode</span>
      applied to a given logarithmic depth sample.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s14ss3pg8" href="#st200_p2s14ss3pg8">8</a></div><div class="st200_paragraph">
      The original derivation of the encoding and decoding functions as
      described by Brano Kemen used the <span class="st200_term variable">w</span> component
      of the resulting clip-space coordinates. Unfortunately, this does not
      work correctly with orthographic projections, as the typical orthographic
      projection matrix will produce clip-space coordinates with a
      <span class="st200_term variable">w</span> component always equal to
      <span class="st200_term constant">1</span>. Aside from the effects that this will
      have on depth testing (essentially mapping the depth of all fragments to the
      far plane), it also makes position reconstruction impossible as the original eye-space
      <span class="st200_term variable">z</span> value cannot be recovered.
      Instead, the <span class="st200_term package">io7m-r1</span> package uses
      the negated eye-space <span class="st200_term variable">z</span> value directly
      in all cases.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s15" href="#st200_p2s15">2.15</a></div><div class="st200_section_title">Forward Rendering (Translucents)</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s15ss1">2.15.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s15ss2">2.15.2. Lit</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s15ss3">2.15.3. Unlit</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s15ss1" href="#st200_p2s15ss1">2.15.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s15ss1pg1" href="#st200_p2s15ss1pg1">1</a></div><div class="st200_paragraph">
      Because the <a class="st200_link" href="#st200_p2s12">deferred renderer</a> in
      the <span class="st200_term package">io7m-r1</span> package is incapable
      of rendering <span class="st200_term term">translucent instances</span>, a separate
      <span class="st200_term term">forward renderer</span> is provided. The
      <span class="st200_term term">forward renderer</span> in the package can only work
      with a subset of the available <a class="st200_link" href="#st200_p2s18">light types</a>,
      in order to prevent the 
      <a class="st200_link" href="#st200_p2s12ss1pg2">combinatorial explosion</a>
      of shaders required to support a large number of light and surface types.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s15ss1pg2" href="#st200_p2s15ss1pg2">2</a></div><div class="st200_paragraph">
      Translucent instances are divided into 
      <a class="st200_link" href="#st200_p2s15ss2">lit</a>
      and
      <a class="st200_link" href="#st200_p2s15ss3">unlit</a> categories.
      As stated previously, translucent instances are drawn in the order that they are
      submitted to the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KVisibleSetTranslucentsBuilderType.html">visible set builder</a>.
      A lit instance is submitted to the builder with the set of lights that affect it.
      Only lights of type
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightTranslucentType.html">KLightTranslucentType</a>
      can be applied to translucent instances. Rendering of translucent instances
      typically occurs after the rendering of opaque instances and so rendering
      works with a depth buffer that has already been populated. Depth testing is
      enabled to ensure that instances overlap and are overlapped by existing opaque
      instances, but translucent instances
      do not have their depths written into the depth buffer, and so care should be
      taken when rendering translucent instances that intersect with each other
      <span class="st200_footnote_reference"><a id="st200_fn_29_ref" href="#st200_fn_29">[29]</a></span>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s15ss2" href="#st200_p2s15ss2">2.15.2</a></div><div class="st200_subsection_title">Lit</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s15ss2pg1" href="#st200_p2s15ss2pg1">1</a></div><div class="st200_paragraph">
      Lit translucent instances can have
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRegular.html">regular</a>
      and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentSpecularOnly.html">specular-only</a>
      materials. Specular-only materials result in only a specular term
      being calculated for a given object, which is useful for implementing
      glass-like objects:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s15ss2fo1" href="#st200_p2s15ss2fo1">2.15.2.1. Specular Only</a></div><img class="st200_image" alt="Specular Only" src="images/speconly.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s15ss2pg2" href="#st200_p2s15ss2pg2">2</a></div><div class="st200_paragraph">
      Rendering of lit instances proceeds as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s15ss2fo2" href="#st200_p2s15ss2fo2">2.15.2.2. Lit instance rendering</a></div><ol class="st200_list_ordered"><li class="st200_list_item">
          For each light <span class="st200_term variable">k</span> affecting the instance
          <span class="st200_term variable">o</span>:
          <ol class="st200_list_ordered"><li class="st200_list_item">
              If <span class="st200_term variable">k</span> is the first light in the set,
              set the blending functions to 
              <span class="st200_term expression">(BlendFunction.BLEND_ONE, BlendFunction.BLEND_ONE_MINUS_SOURCE_ALPHA)</span>.
              That is, the source color will be multiplied by <span class="st200_term expression">1</span>
              and the destination color will be multiplied by
              <span class="st200_term expression">1 - alpha</span>. This has the effect of
              setting the overall "opacity" of the object for subsequent light contributions. 
              If <span class="st200_term variable">k</span>
              is not the first light in the set, set the blending functions to
              <span class="st200_term expression">(BlendFunction.BLEND_ONE, BlendFunction.BLEND_ONE)</span>.
              This is the standard additive blending used to sum light contributions.
            </li><li class="st200_list_item">
              Render <span class="st200_term variable">o</span>, lit by
              <span class="st200_term variable">k</span>.
            </li></ol>
        </li></ol></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s15ss3" href="#st200_p2s15ss3">2.15.3</a></div><div class="st200_subsection_title">Unlit</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s15ss3pg1" href="#st200_p2s15ss3pg1">1</a></div><div class="st200_paragraph">
      Unlit translucent instances can have
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRegular.html">regular</a>
      and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRefractive.html">refractive</a>
      materials. Refractive materials are implemented using the
      <a class="st200_link" href="#st200_p2s25">generic refraction</a>
      effect.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s16" href="#st200_p2s16">2.16</a></div><div class="st200_section_title">Normal Mapping</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s16ss1">2.16.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s16ss2">2.16.2. Tangent Space</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s16ss3">2.16.3. Tangent/Bitangent Generation</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s16ss4">2.16.4. Normal Maps</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s16ss5">2.16.5. Rendering With Normal Maps</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s16ss1" href="#st200_p2s16ss1">2.16.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss1pg1" href="#st200_p2s16ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      supports the use of <span class="st200_term term">tangent-space normal mapping</span>
      to allow for per-pixel control over the surface normal of rendered triangles.
      This allows for meshes to appear to have very complex surface details without
      requiring those details to actually be rendered as triangles within the scene.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s16ss2" href="#st200_p2s16ss2">2.16.2</a></div><div class="st200_subsection_title">Tangent Space</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss2pg1" href="#st200_p2s16ss2pg1">1</a></div><div class="st200_paragraph">
      Conceptually, there is a three-dimensional coordinate system based
      at each vertex, formed by three orthonormal basis vectors: The vertex <span class="st200_term term">normal</span>,
      <span class="st200_term term">tangent</span> and <span class="st200_term term">bitangent</span>
      vectors. The <span class="st200_term term">normal</span> vector is a the vector perpendicular
      to the surface at that vertex. The <span class="st200_term term">tangent</span> and
      <span class="st200_term term">bitangent</span> vectors are parallel to the surface, and
      each vector is obviously perpendicular to the other two vectors. This coordinate
      space is often referred to as <span class="st200_term term">tangent space</span>. The
      <span class="st200_term term">normal</span> vector actually forms the 
      <span class="st200_term constant">Z</span> axis of the coordinate space, and this
      fact is central to the process of normal mapping. The coordinate system at
      each vertex may be left or right-handed depending on the arrangement of UV 
      coordinates at that vertex.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss2fo1" href="#st200_p2s16ss2fo1">2.16.2.1. Vertex coordinate system</a></div><img class="st200_image" alt="Vertex coordinate system" src="images/normal.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s16ss3" href="#st200_p2s16ss3">2.16.3</a></div><div class="st200_subsection_title">Tangent/Bitangent Generation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg1" href="#st200_p2s16ss3pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Tangent</span> and <span class="st200_term term">bitangent</span> 
      vectors can be generated by the modelling programs that artists use to
      create polygon meshes, but, additionally, the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/RMeshTangents.html">RMeshTangents</a>
      class can take an arbitrary mesh with only normal vectors and UV 
      coordinates and produce tangent and bitangent vectors. The full
      description of the algorithm used is given in
      <a class="st200_link_external" href="http://www.mathfor3dgameprogramming.com/">Mathematics for 3D Game Programming and Computer Graphics, Third Edition</a>
      <span class="st200_footnote_reference"><a id="st200_fn_30_ref" href="#st200_fn_30">[30]</a></span>,
      and also in an
      <a class="st200_link_external" href="http://www.terathon.com/code/tangent.html">article</a>
      by the same author. The actual aim of tangent/bitangent generation
      is to produce a pair of orthogonal vectors that are oriented to the
      <span class="st200_term variable">x</span> and <span class="st200_term variable">y</span>
      axes of an arbitrary texture. In order to do achieve this,
      the generated vectors are oriented according to the UV 
      coordinates in the mesh.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg2" href="#st200_p2s16ss3pg2">2</a></div><div class="st200_paragraph">
      In the <span class="st200_term package">io7m-r1</span> package, the
      <span class="st200_term term">bitangent</span> vector is not actually stored in
      the mesh data, and the <span class="st200_term term">tangent</span> vector for 
      any given vertex is instead stored as a four-component vector.
      The reasons for this are as follows: Because the normal, tangent, and 
      bitangent vectors are known to be orthonormal, it should be possible to
      reconstruct any one of the three vectors given the other two at run-time. 
      This would eliminate the need to store one of the vectors and would
      reduce the size of mesh data (including the on-disk size, and the 
      size of mesh data allocated on the GPU) by a significant amount.
      Given any two orthogonal vectors <span class="st200_term constant">V0</span>
      and <span class="st200_term constant">V1</span>, a vector orthogonal to both
      can be calculated by taking the <span class="st200_term term">cross product</span>
      of both, denoted <span class="st200_term expression">(cross V0 V1)</span>. The
      problem here is that if <span class="st200_term constant">V0</span> is assumed
      to be the original normal vector <span class="st200_term constant">N</span>,
      and <span class="st200_term constant">V1</span> is assumed to be the original
      tangent vector <span class="st200_term constant">T</span>, there is no guarantee
      that <span class="st200_term expression">(cross N T)</span> will produce a
      vector equal to the original bitangent vector 
      <span class="st200_term constant">B</span>: There are two possible
      choices of value for <span class="st200_term constant">B</span> that differ
      only in the sign of their coordinate values.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg3" href="#st200_p2s16ss3pg3">3</a></div><div class="st200_paragraph">
      As an example, a triangle that will produce <span class="st200_term constant">T</span>
      and <span class="st200_term constant">B</span> vectors that form a right-handed
      coordinate system with the normal vector <span class="st200_term constant">N</span>
      (with UV coordinates indicated at each vertex):
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss3fo1" href="#st200_p2s16ss3fo1">2.16.3.1. Tangent generation (RHC)</a></div><img class="st200_image" alt="Tangent generation (Resulting in a right-handed coordinate system)" src="images/tangent_gen_RHC.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg4" href="#st200_p2s16ss3pg4">4</a></div><div class="st200_paragraph">
      The same triangle will produce vectors that form a left-handed system when
      generating vectors for another vertex (note that the result of
      <span class="st200_term expression">(Vector3f.cross N T) = (Vector3f.negation B)</span>):
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss3fo2" href="#st200_p2s16ss3fo2">2.16.3.2. Tangent generation (LHC)</a></div><img class="st200_image" alt="Tangent generation (Resulting in a left-handed coordinate system)" src="images/tangent_gen_LHC.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg5" href="#st200_p2s16ss3pg5">5</a></div><div class="st200_paragraph">
      However, if the
      original tangent vector <span class="st200_term constant">T</span> was augmented
      with a piece of extra information that indicated whether or not the result of
      <span class="st200_term expression">(cross N T)</span> needed to be inverted, then
      reconstructing <span class="st200_term constant">B</span> would be trivial.
      Therefore, the fourth component of the tangent vector <span class="st200_term constant">T</span>
      contains <span class="st200_term constant">1.0</span> if 
      <span class="st200_term expression">(cross N T) = B</span>, and
      <span class="st200_term constant">-1.0</span> if <span class="st200_term expression">(cross N T) = -B</span>.
      The bitangent vector can therefore be
      reconstructed by calculating <span class="st200_term expression">cross (N, T.xyz) * T.w</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg6" href="#st200_p2s16ss3pg6">6</a></div><div class="st200_paragraph">
      With the three vectors <span class="st200_term expression">(T, B, N)</span>, it's now possible
      construct a <span class="st200_term expression">3x3</span> matrix that can transform arbitrary
      vectors in <a class="st200_link" href="#st200_p2s16ss2">tangent space</a>
      to <a class="st200_link" href="#st200_p2s3ss3">object space</a>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss3fo3" href="#st200_p2s16ss3fo3">2.16.3.3. Tangent â Object matrix</a></div><img class="st200_image" alt="Tangent â Object matrix" src="images/tangent_object_matrix.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss3pg7" href="#st200_p2s16ss3pg7">7</a></div><div class="st200_paragraph">
      With this matrix, it's now obviously possible to take an arbitrary vector in
      tangent space and transform it to object space. Then, with the
      current <span class="st200_term term">normal matrix</span> (object â eye),
      transform the object space vector all the way to 
      <a class="st200_link" href="#st200_p2s3ss5">eye space</a> 
      in the same manner as ordinary per-vertex object space normal vectors. 
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s16ss4" href="#st200_p2s16ss4">2.16.4</a></div><div class="st200_subsection_title">Normal Maps</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss4pg1" href="#st200_p2s16ss4pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">normal map</span> is an ordinary RGB texture
      where each texel represents a tangent space normal vector. The 
      <span class="st200_term variable">x</span> coordinate is stored in the
      red channel, the <span class="st200_term variable">y</span> coordinate is
      stored in the green channel, and the <span class="st200_term variable">z</span>
      coordinate is stored in the blue channel. The original
      coordinate values are assumed to fall within the inclusive range
      <span class="st200_term expression">[-1.0, 1.0]</span>, and these values
      are mapped to the range <span class="st200_term expression">[0.0, 1.0]</span>
      before being encoded to a specific pixel format.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss4pg2" href="#st200_p2s16ss4pg2">2</a></div><div class="st200_paragraph">
      As an example, the vector <span class="st200_term constant">(0.0, 0.0, 1.0)</span>
      is first mapped to <span class="st200_term constant">(0.5, 0.5, 1.0)</span> and
      then, assuming an image format with 8-bits of precision per color channel,
      encoded to <span class="st200_term constant">(0x7f, 0x7f, 0xff)</span>. This
      results in a pale blue color that is characteristic of tangent space
      normal maps:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss4fo1" href="#st200_p2s16ss4fo1">2.16.4.1. (0.0, 0.0, 1.0)</a></div><img class="st200_image" alt="(0.0, 0.0, 1.0)" src="images/normalmap_zerozeroone.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss4pg3" href="#st200_p2s16ss4pg3">3</a></div><div class="st200_paragraph">
      Typically, tangent space normal maps are generated from a simple
      height maps: Greyscale images where <span class="st200_term constant">0.0</span>
      denotes the lowest possible height, and <span class="st200_term constant">1.0</span>
      indicates the highest possible height. There are multiple algorithms
      that are capable of generating normal vectors from height maps, but
      the majority of them work from the same basic principle: For a given
      pixel with value <span class="st200_term variable">h</span> at location 
      <span class="st200_term expression">(x, y)</span> in an image, the neighbouring
      pixel values at <span class="st200_term expression">(x - 1, y)</span>,
      <span class="st200_term expression">(x - 1, y - 1)</span>, 
      <span class="st200_term expression">(x + 1, y)</span>,
      <span class="st200_term expression">(x + 1, y + 1)</span> are compared 
      with <span class="st200_term variable">h</span>
      in order to determine the <span class="st200_term term">slope</span> between 
      the height values. As an example, the
      <a class="st200_link_external" href="https://en.wikipedia.org/wiki/Prewitt_operator">Prewitt (3x3) operator</a>
      when used from the
      <a class="st200_link_external" href="https://code.google.com/p/gimp-normalmap/">gimp-normalmap</a>
      plugin will produce the following map from a given greyscale height map:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss4fo2" href="#st200_p2s16ss4fo2">2.16.4.2. Prewitt 3x3 normal map</a></div><img class="st200_image" alt="Prewitt 3x3 normal map" src="images/normalmap_fromheight.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss4pg4" href="#st200_p2s16ss4pg4">4</a></div><div class="st200_paragraph">
      It is reasonably easy to infer the general directions of vectors from
      a visual inspection of a tangent space normal map alone. In the above
      image, the flat faces of the bricks are mostly pale blue. This is because the
      tangent space normal for that surface is pointing straight towards the
      viewer - mostly towards the positive <span class="st200_term variable">z</span>
      direction. The right edges of the bricks in the image are tinted with a
      pinkish hue - this indicates that the normal vectors at that pixel point
      mostly towards the positive <span class="st200_term variable">x</span> direction.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s16ss5" href="#st200_p2s16ss5">2.16.5</a></div><div class="st200_subsection_title">Rendering With Normal Maps</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss5pg1" href="#st200_p2s16ss5pg1">1</a></div><div class="st200_paragraph">
      As stated, the purpose of a normal map is to give per-pixel control
      over the surface normal for a given triangle during rendering. The
      process is as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss5fo1" href="#st200_p2s16ss5fo1">2.16.5.1. Rendering process</a></div><ol class="st200_list_ordered"><li class="st200_list_item">
          Calculate the bitangent vector <span class="st200_term constant">B</span>
          from the <span class="st200_term constant">N</span> and
          <span class="st200_term constant">T</span> vectors. This step is
          performed on a per-vertex basis 
          (in the <span class="st200_term term">vertex shader</span>).
        </li><li class="st200_list_item">
          Construct a <span class="st200_term constant">3x3</span> tangent â object
          matrix <span class="st200_term variable">M</span> 
          from the <span class="st200_term expression">(T, B, N)</span> vectors.
          This step is performed on a per-fragment basis 
          (in the <span class="st200_term term">fragment shader</span>)
          using the interpolated vectors calculated in the previous step.
        </li><li class="st200_list_item">
          Sample a tangent space normal vector <span class="st200_term variable">P</span>
          from the current normal map.
        </li><li class="st200_list_item">
          Transform the vector <span class="st200_term variable">P</span> with
          the matrix <span class="st200_term variable">M</span> by calculating
          <span class="st200_term expression">M * P</span>, resulting in
          an object space normal vector <span class="st200_term variable">Q</span>.
        </li><li class="st200_list_item">
          Transform the vector <span class="st200_term variable">Q</span> to
          eye space, in the same manner that an ordinary per-vertex 
          normal vector would be (using the 
          <a class="st200_link" href="#st200_p2s3ss5pg4">3x3 normal matrix</a>).
        </li></ol></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss5pg2" href="#st200_p2s16ss5pg2">2</a></div><div class="st200_paragraph">
      Effectively, a "replacement" normal vector is sampled from the
      map, and transformed to object space using the existing
      <span class="st200_term expression">(T, B, N)</span> vectors. When
      the replacement normal vector is used when applying lighting,
      the effect is dramatic. Given a simple two-polygon
      square textured with the following albedo texture and normal map:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss5fo2" href="#st200_p2s16ss5fo2">2.16.5.2. Example albedo and normal maps</a></div><img class="st200_image" alt="Example albedo and normal maps" src="images/normalmap_metalpanels.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss5pg3" href="#st200_p2s16ss5pg3">3</a></div><div class="st200_paragraph">
      The square when textured and normal mapped, with three spherical
      lights:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss5fo3" href="#st200_p2s16ss5fo3">2.16.5.3. Lit and normal mapped</a></div><img class="st200_image" alt="Lit and normal mapped" src="images/normalmap_applied.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s16ss5pg4" href="#st200_p2s16ss5pg4">4</a></div><div class="st200_paragraph">
      The same square with the same lights but missing the normal map:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s16ss5fo4" href="#st200_p2s16ss5fo4">2.16.5.4. Lit and not normal mapped</a></div><img class="st200_image" alt="Lit and not normal mapped" src="images/normalmap_none.png"/></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s17" href="#st200_p2s17">2.17</a></div><div class="st200_section_title">Environment Mapping</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s17ss1">2.17.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s17ss2">2.17.2. Cube Maps</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s17ss3">2.17.3. Reflections</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s17ss4">2.17.4. Handedness</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s17ss1" href="#st200_p2s17ss1">2.17.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss1pg1" href="#st200_p2s17ss1pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Environment mapping</span> is conceptually
      the process of constructing an artificial environment around an object
      in order to provide, for example, effects such as reflective surfaces
      or refractive objects.
      In the <span class="st200_term package">io7m-r1</span> package,
      the artificial environment is represented by 
      <a class="st200_link" href="#st200_p2s17ss2">cube maps</a>,
      and the only supported effect is <span class="st200_term reflection">reflection</span>.
      Effects such as refraction are instead provided via
      <a class="st200_link" href="#st200_p2s25">generic refraction</a>,
      which doesn't use environment mapping.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s17ss2" href="#st200_p2s17ss2">2.17.2</a></div><div class="st200_subsection_title">Cube Maps</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss2pg1" href="#st200_p2s17ss2pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">cube map</span> is a <span class="st200_term term">texture</span>
      with six <span class="st200_term term">faces</span>. When used for environment mapping,
      each face represents a 90Â° image of the environment visible in the direction 
      (in <a class="st200_link" href="#st200_p2s3ss4">world space</a>) of
      that face. Cube maps are normally constructed by placing an observer in a scene
      and then orienting the observer in the direction of each cube face in turn and 
      rendering an image. As an example:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s17ss2fo1" href="#st200_p2s17ss2fo1">2.17.2.1. Cube map scene</a></div><img class="st200_image" alt="Cube map scene" src="images/envmap_cube_scene.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss2pg2" href="#st200_p2s17ss2pg2">2</a></div><div class="st200_paragraph">
      Given the above scene, with the observer placed exactly in the center of the
      indicated magenta circle and assuming a 90Â° field of view, the six images visible
      from that location corresponding to the <span class="st200_term constant">-x</span>,
      <span class="st200_term constant">+x</span>, <span class="st200_term constant">-y</span>,
      <span class="st200_term constant">-z</span>, <span class="st200_term constant">-z</span>,
      <span class="st200_term constant">+z</span> cube faces are:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s17ss2fo2" href="#st200_p2s17ss2fo2">2.17.2.2. Cube map example</a></div><img class="st200_image" alt="Cube map example" src="images/envmap_cubemap.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss2pg3" href="#st200_p2s17ss2pg3">3</a></div><div class="st200_paragraph">
      While sampling from ordinary two-dimensional textures involves looking up texels 
      by their two-dimensional coordinates, sampling from cube maps requires 
      three-dimensional coordinates. The three-dimensional coordinates are interpreted
      as a direction vector or ray emanating from the center of the cube, and the point of
      intersection between the ray and the corresponding cube face is
      used to select a texel from that face. Note that in OpenGL there are
      issues with 
      <a class="st200_link" href="#st200_p2s17ss4">coordinate system handedness</a>
      that the <span class="st200_term package">io7m-r1</span> package
      corrects.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s17ss3" href="#st200_p2s17ss3">2.17.3</a></div><div class="st200_subsection_title">Reflections</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss3pg1" href="#st200_p2s17ss3pg1">1</a></div><div class="st200_paragraph">
      So-called <span class="st200_term term">environment-mapped reflections</span> are
      trivially provided by cube maps. For a given surface with a normal vector
      <span class="st200_term variable">n</span>, and given the view direction 
      <span class="st200_term variable">v</span> (from the observer to the surface),
      a <span class="st200_term term">reflection vector</span> is given by
      <span class="st200_term expression">r = Reflection.reflection v n</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s17ss3fo1" href="#st200_p2s17ss3fo1">2.17.3.1. Reflection vector</a></div><pre class="st200_verbatim">module Reflection where

import qualified Vector3f as V3

reflection :: V3.T -&gt; V3.T -&gt; V3.T
reflection v0 v1 = V3.sub3 v0 (V3.scale v1 (2.0 * (V3.dot3 v1 v0)))
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss3pg2" href="#st200_p2s17ss3pg2">2</a></div><div class="st200_paragraph">
      The reflection vector <span class="st200_term variable">r</span> is then used to 
      look up a texel in the current cube map directly. This gives a convincing 
      illusion of reflection that will change as the observer moves relative to 
      the surface. Combining normal mapping and environment mapped reflections
      gives a striking effect:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s17ss3fo2" href="#st200_p2s17ss3fo2">2.17.3.2. Normal/Environment mapping</a></div><img class="st200_image" alt="Normal/Environment mapping" src="images/envmap_tiles.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s17ss3fo3" href="#st200_p2s17ss3fo3">2.17.3.3. Normal/Environment mapping (Cube map)</a></div><img class="st200_image" alt="Normal/Environment mapping (Cube map)" src="images/envmap_toronto.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss3pg3" href="#st200_p2s17ss3pg3">3</a></div><div class="st200_paragraph">
      Note that in the actual <span class="st200_term package">io7m-r1</span> 
      implementation, the vectors <span class="st200_term variable">n</span> and
      <span class="st200_term variable">v</span> will be in eye-space and therefore
      so will <span class="st200_term variable">r</span>. The vector 
      <span class="st200_term variable">r</span> is transformed back to
      <a class="st200_link" href="#st200_p2s3ss4">world space</a>
      by the inverse of the current view matrix for use with the cube map.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s17ss4" href="#st200_p2s17ss4">2.17.4</a></div><div class="st200_subsection_title">Handedness</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s17ss4pg1" href="#st200_p2s17ss4pg1">1</a></div><div class="st200_paragraph">
      For reasons lost to time, cube maps in
      OpenGL use a left-handed coordinate system in contrast to the usual
      right-handed coordinate system. Because of this, calculated 
      reflection vectors actually have to be inverted to prevent sampling
      from the wrong cube face. The 
      <span class="st200_term package">io7m-r1</span> package
      enforces a consistent right-handed coordinate system everywhere. The
      direction of each cube face corresponds to the same direction in
      <a class="st200_link" href="#st200_p2s3ss4">world space</a>, without
      exception.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s18" href="#st200_p2s18">2.18</a></div><div class="st200_section_title">Lighting</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s18ss1">2.18.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s18ss2">2.18.2. Diffuse/Specular Terms</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s18ss3">2.18.3. Diffuse-Only Lights</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s18ss4">2.18.4. Attenuation</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s18ss1" href="#st200_p2s18ss1">2.18.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss1pg1" href="#st200_p2s18ss1pg1">1</a></div><div class="st200_paragraph">
      The following sections of documentation attempt to describe the theory and
      implementation of <span class="st200_term term">lighting</span> in the
      <span class="st200_term package">io7m-r1</span> package. All lighting
      in the package is <span class="st200_term term">dynamic</span> - there is no support
      for precomputed lighting and all contributions from lights are recalculated every
      time a scene is rendered. Lighting is configured by adding instances of
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightType.html">KLightType</a>
      to a scene.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s18ss2" href="#st200_p2s18ss2">2.18.2</a></div><div class="st200_subsection_title">Diffuse/Specular Terms</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg1" href="#st200_p2s18ss2pg1">1</a></div><div class="st200_paragraph">
      The light applied to a surface by a given light is divided
      into <span class="st200_term term">diffuse</span> and
      <span class="st200_term term">specular</span> terms
      <span class="st200_footnote_reference"><a id="st200_fn_31_ref" href="#st200_fn_31">[31]</a></span>. The actual light applied to a surface is dependent upon
      the properties of the surface. Conceptually, the diffuse and specular 
      terms are multiplied by the final color of the surface and summed. In
      practice, the materials applied to surfaces have control over how
      light is actually applied to the surface. For example, materials may
      include a 
      <a class="st200_link" href="#st200_p2s6ss5">specular map</a>
      which is used to manipulate the specular term as it is applied to the surface.
      Additionally, if a light supports <span class="st200_term term">attenuation</span>,
      then the diffuse and specular terms are scaled by the attenuation factor
      prior to being applied.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg2" href="#st200_p2s18ss2pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term term">diffuse</span> term is modelled by
      <a class="st200_link_external" href="http://en.wikipedia.org/wiki/Lambertian_reflectance">Lambertian reflectance</a>.
      Specifically, the amount of diffuse light reflected from a surface
      is given by <span class="st200_term function">diffuse</span>
      [<a class="st200_link_external" href="haskell/LightDiffuse.hs">LightDiffuse.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss2fo1" href="#st200_p2s18ss2fo1">2.18.2.1. Diffuse term</a></div><pre class="st200_verbatim">module LightDiffuse where

import qualified Color3
import qualified Direction
import qualified Normal
import qualified Spaces
import qualified Vector3f

diffuse ::  Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Vector3f.T
diffuse stl n light_color light_intensity =
  let 
    factor       = max 0.0 (Vector3f.dot3 stl n)
    light_scaled = Vector3f.scale light_color light_intensity
  in 
    Vector3f.scale light_scaled factor</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg3" href="#st200_p2s18ss2pg3">3</a></div><div class="st200_paragraph">
      Where <span class="st200_term variable">stl</span> is a unit length direction vector
      from the surface to the light source, <span class="st200_term variable">n</span> is the surface
      normal vector, <span class="st200_term variable">light_color</span> is the 
      light color, and <span class="st200_term variable">light_intensity</span> 
      is the light intensity. Informally, the algorithm determines how much diffuse light
      should be reflected from a surface based on how directly that surface
      points towards the light. When <span class="st200_term expression">stl == n</span>,
      <span class="st200_term expression">Vector3f.dot3 stl n == 1.0</span>, and
      therefore the light is reflected exactly as received. When 
      <span class="st200_term expression">stl</span> is perpendicular to 
      <span class="st200_term expression">n</span> (such that 
      <span class="st200_term expression">Vector3f.dot3 stl n == 0.0</span>), no
      light is reflected at all. If the two directions are greater than 
      <span class="st200_term constant">90Â°</span> perpendicular, the dot product 
      is negative, but the algorithm clamps negative values to 
      <span class="st200_term constant">0.0</span> so the effect is the same.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss2fo2" href="#st200_p2s18ss2fo2">2.18.2.2. Diffuse light</a></div><img class="st200_image" alt="Diffuse light" src="images/directional_diffuse.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg4" href="#st200_p2s18ss2pg4">4</a></div><div class="st200_paragraph">
      The specular term is modelled by 
      <a class="st200_link_external" href="http://en.wikipedia.org/wiki/Phong_reflection_model">Phong reflection</a>
      <span class="st200_footnote_reference"><a id="st200_fn_32_ref" href="#st200_fn_32">[32]</a></span>.
      Specifically, the amount of specular light reflected from a surface is given by 
      <span class="st200_term function">specular</span>
      [<a class="st200_link_external" href="haskell/LightSpecular.hs">LightSpecular.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss2fo3" href="#st200_p2s18ss2fo3">2.18.2.3. Specular Term</a></div><pre class="st200_verbatim">module LightSpecular where

import qualified Color3
import qualified Direction
import qualified Normal
import qualified Reflection
import qualified Spaces
import qualified Specular
import qualified Vector3f

specular :: Direction.T Spaces.Eye -&gt; Direction.T Spaces.Eye -&gt; Normal.T -&gt; Color3.T -&gt; Float -&gt; Specular.T -&gt; Vector3f.T
specular stl view n light_color light_intensity (Specular.S surface_spec surface_exponent) =
  let 
    reflection   = Reflection.reflection view n
    factor       = (max 0.0 (Vector3f.dot3 reflection stl)) ** surface_exponent
    light_raw    = Vector3f.scale light_color light_intensity
    light_scaled = Vector3f.scale light_raw factor
  in 
    Vector3f.mult3 light_scaled surface_spec
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg5" href="#st200_p2s18ss2pg5">5</a></div><div class="st200_paragraph">
      Where <span class="st200_term variable">stl</span> is a unit length direction vector
      from the surface to the light source, 
      <span class="st200_term variable">view</span> is a unit length 
      direction vector from the observer to the surface, 
      <span class="st200_term variable">n</span> is the surface
      normal vector, <span class="st200_term variable">light_color</span> is the 
      light color, <span class="st200_term variable">light_intensity</span> 
      is the light intensity, <span class="st200_term variable">surface_exponent</span> is the
      <span class="st200_term term">specular exponent</span> defined by the surface,
      and <span class="st200_term variable">surface_spec</span> is the surface
      specularity factor.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss2pg6" href="#st200_p2s18ss2pg6">6</a></div><div class="st200_paragraph">
      The specular exponent is a value, ordinarily in the range 
      <span class="st200_term expression">[0, 255]</span>, that
      controls how sharp the <span class="st200_term term">specular highlights</span>
      appear on the surface. The exponent is a property of the surface, as opposed
      to being a property of the light. Low specular exponents result in soft and widely
      dispersed specular highlights (giving the appearance of a rough surface), while 
      high specular exponents result in hard and focused highlights (giving the appearance of a polished 
      surface). As an example, three models lit with 
      progressively lower specular exponents from left to right (<span class="st200_term constant">128</span>,
      <span class="st200_term constant">32</span>, and <span class="st200_term constant">8</span>,
      respectively):
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss2fo4" href="#st200_p2s18ss2fo4">2.18.2.4. Specular exponents</a></div><img class="st200_image" alt="Specular exponents" src="images/directional_specular_exponents.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s18ss3" href="#st200_p2s18ss3">2.18.3</a></div><div class="st200_subsection_title">Diffuse-Only Lights</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss3pg1" href="#st200_p2s18ss3pg1">1</a></div><div class="st200_paragraph">
      Some lights have <span class="st200_term term">diffuse-only</span> variants.
      Little explanation is required: The 
      <a class="st200_link" href="#st200_p2s18ss2pg4">specular</a>
      term is simply not calculated and only the <span class="st200_term term">diffuse</span>
      term is used.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s18ss4" href="#st200_p2s18ss4">2.18.4</a></div><div class="st200_subsection_title">Attenuation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg1" href="#st200_p2s18ss4pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Attenuation</span> is the property of the influence
      of a given light on a surface in inverse proportion to the distance from the
      light to the surface. In other words, for lights that support attenuation,
      the further a surface is from a light source, the less that surface will
      appear to be lit by the light. For light types that support attenuation,
      an <span class="st200_term term">attenuation factor</span> is calculated based
      on a given <span class="st200_term variable">inverse_maximum_range</span> 
      (where the <span class="st200_term variable">maximum_range</span> is a
      light-type specific positive value that represents the maximum possible
      range of influence for the light), a configurable 
      <span class="st200_term term">inverse falloff</span> value, and the current
      <span class="st200_term variable">distance</span> between the surface being 
      lit and the light source. The  attenuation factor is a value in the range 
      <span class="st200_term expression">[0.0, 1.0]</span>, with
      <span class="st200_term expression">1.0</span> meaning "no attenuation" and
      <span class="st200_term expression">0.0</span> meaning "maximum attenuation".
      The resulting attenuation factor is multiplied by the raw unattenuated
      light values produced for the light in order to produce the illusion of
      distance attenuation. Specifically:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss4fo1" href="#st200_p2s18ss4fo1">2.18.4.1. Attenuation</a></div><pre class="st200_verbatim">module Attenuation where

attenuation_from_inverses :: Float -&gt; Float -&gt; Float -&gt; Float
attenuation_from_inverses inverse_maximum_range inverse_falloff distance =
  max 0.0 (1.0 - (distance * inverse_maximum_range) ** inverse_falloff)

attenuation :: Float -&gt; Float -&gt; Float -&gt; Float
attenuation maximum_range falloff distance =
  attenuation_from_inverses (1.0 / maximum_range) (1.0 / falloff) distance
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg2" href="#st200_p2s18ss4pg2">2</a></div><div class="st200_paragraph">
      Given the above definitions, a number of observations can be made.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg3" href="#st200_p2s18ss4pg3">3</a></div><div class="st200_paragraph">
      If <span class="st200_term expression">falloff == 1</span>, then the
      attenuation is linear over distance <span class="st200_footnote_reference"><a id="st200_fn_33_ref" href="#st200_fn_33">[33]</a></span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss4fo2" href="#st200_p2s18ss4fo2">2.18.4.2. Linear attenuation</a></div><img class="st200_image" alt="Linear attenuation" src="images/attenuation_linear.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg4" href="#st200_p2s18ss4pg4">4</a></div><div class="st200_paragraph">
      If <span class="st200_term expression">maximum_range == 0</span>, then the
      inverse range is undefined, and therefore the results of lighting are 
      undefined. The <span class="st200_term package">io7m-r1</span> package
      handles this case by raising an exception when the light is created.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg5" href="#st200_p2s18ss4pg5">5</a></div><div class="st200_paragraph">
      If <span class="st200_term expression">falloff == 0</span>, then the
      inverse falloff is undefined, and therefore the results of lighting are 
      undefined. The <span class="st200_term package">io7m-r1</span> package
      handles this case by raising an exception when the light is created.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg6" href="#st200_p2s18ss4pg6">6</a></div><div class="st200_paragraph">
      As <span class="st200_term expression">falloff</span> decreases towards
      <span class="st200_term expression">0.0</span>, then the attenuation curve 
      remains at <span class="st200_term expression">1.0</span> for increasingly
      higher distance values before falling sharply to 
      <span class="st200_term expression">0.0</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss4fo3" href="#st200_p2s18ss4fo3">2.18.4.3. Low falloff attenuation</a></div><img class="st200_image" alt="Low falloff attenuation" src="images/attenuation_low_falloff.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s18ss4pg7" href="#st200_p2s18ss4pg7">7</a></div><div class="st200_paragraph">
      As <span class="st200_term expression">falloff</span> increases away from
      <span class="st200_term expression">0.0</span>, then the attenuation curve 
      decreases more for lower distance values:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s18ss4fo4" href="#st200_p2s18ss4fo4">2.18.4.4. High falloff attenuation</a></div><img class="st200_image" alt="High falloff attenuation" src="images/attenuation_high_falloff.png"/></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s19" href="#st200_p2s19">2.19</a></div><div class="st200_section_title">Directional Lighting</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s19ss1">2.19.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s19ss2">2.19.2. Types</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s19ss3">2.19.3. Attenuation</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s19ss4">2.19.4. Application</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s19ss1" href="#st200_p2s19ss1">2.19.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s19ss1pg1" href="#st200_p2s19ss1pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">directional light</span> in the 
      <span class="st200_term package">io7m-r1</span> package
      is a light that emits parallel rays of light in a given 
      eye space <span class="st200_term term">direction</span>.
      It has a <span class="st200_term term">color</span> and an
      <span class="st200_term term">intensity</span>, but does not have
      an <span class="st200_term term">origin</span> and therefore is not attenuated
      over distance. It does not cause objects to cast shadows.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s19ss1fo1" href="#st200_p2s19ss1fo1">2.19.1.1. Directional lighting</a></div><img class="st200_image" alt="Directional lighting" src="images/directional_diagram.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s19ss2" href="#st200_p2s19ss2">2.19.2</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s19ss2pg1" href="#st200_p2s19ss2pg1">1</a></div><div class="st200_paragraph">
      Directional lights are represented in the 
      <span class="st200_term package">io7m-r1</span> 
      package by the following types:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s19ss2fo1" href="#st200_p2s19ss2fo1">2.19.2.1. Types</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightDirectional.html">KLightDirectional</a> -
          a directional light.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightDirectionalDiffuseOnly.html">KLightDirectionalDiffuseOnly</a> -
          a <a class="st200_link" href="#st200_p2s18ss3">diffuse-only</a>
          variant of the standard directional light.
        </li></ul></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s19ss3" href="#st200_p2s19ss3">2.19.3</a></div><div class="st200_subsection_title">Attenuation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s19ss3pg1" href="#st200_p2s19ss3pg1">1</a></div><div class="st200_paragraph">
      Directional lights do not have origins and cannot therefore be attenuated
      over distance.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s19ss4" href="#st200_p2s19ss4">2.19.4</a></div><div class="st200_subsection_title">Application</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s19ss4pg1" href="#st200_p2s19ss4pg1">1</a></div><div class="st200_paragraph">
      The final light applied to the surface is given by <span class="st200_term function">directional</span>
      [<a class="st200_link_external" href="haskell/Directional.hs">Directional.hs</a>], where
      <span class="st200_term variable">sr</span>, <span class="st200_term variable">sg</span>,
      <span class="st200_term variable">sb</span> are the red, green, and blue channels,
      respectively, of the surface being lit. Note that the surface-to-light vector
      <span class="st200_term variable">stl</span> is simply the negation of the light
      direction.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s19ss4fo1" href="#st200_p2s19ss4fo1">2.19.4.1. Directional lighting (Application)</a></div><pre class="st200_verbatim">module Directional where

import qualified Color4
import qualified Direction
import qualified LightDirectional
import qualified LightDiffuse
import qualified LightSpecular
import qualified Normal
import qualified Position3
import qualified Spaces
import qualified Specular
import qualified Vector3f
import qualified Vector4f

directional :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightDirectional.T -&gt; Specular.T -&gt; Color4.T -&gt; Vector3f.T
directional view n position light specular (Vector4f.V4 sr sg sb _) =
  let
    stl             = Vector3f.normalize (Vector3f.negation position)
    light_color     = LightDirectional.color light
    light_intensity = LightDirectional.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specular stl view n light_color light_intensity specular
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_d
    lit_s           = Vector3f.add3 lit_d light_s
  in
    lit_s
</pre></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s20" href="#st200_p2s20">2.20</a></div><div class="st200_section_title">Spherical Lighting</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s20ss1">2.20.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s20ss2">2.20.2. Types</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s20ss3">2.20.3. Attenuation</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s20ss4">2.20.4. Application</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s20ss5">2.20.5. Shadows</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s20ss1" href="#st200_p2s20ss1">2.20.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss1pg1" href="#st200_p2s20ss1pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">spherical light</span> in the 
      <span class="st200_term package">io7m-r1</span> package
      is a light that emits rays of light in all directions from
      a given <span class="st200_term term">origin</span> specified in
      <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      up to a given maximum <span class="st200_term term">radius</span>.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s20ss1fo1" href="#st200_p2s20ss1fo1">2.20.1.1. Spherical lighting</a></div><img class="st200_image" alt="Spherical lighting" src="images/spherical_diagram.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss1pg2" href="#st200_p2s20ss1pg2">2</a></div><div class="st200_paragraph">
      The term <span class="st200_term term">spherical</span> comes from the
      fact that the light has a defined radius. Most rendering systems
      instead use <span class="st200_term term">point</span> lights that 
      specify multiple <span class="st200_term term">attenuation</span> 
      constants to control how light is attenuated over distance. The
      problem with this approach is that it requires solving a quadratic
      equation to determine a minimum bounding sphere that can contain
      the light. Essentially, the programmer/artist is forced to determine 
      "at which radius does the contribution from this light effectively reach
      zero?". With spherical lights, the maximum radius is declared up
      front, and a single falloff value is used to determine the
      attenuation curve within that radius. This makes spherical
      lights more intuitive to use: The programmer/artist simply places a
      sphere within the scene and knows exactly from the radius which
      objects are lit by it. It also means that bounding light volumes
      can be trivially constructed from unit spheres by simply scaling
      those spheres by the light radius, when performing
      <a class="st200_link" href="#st200_p2s12">deferred rendering</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s20ss2" href="#st200_p2s20ss2">2.20.2</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss2pg1" href="#st200_p2s20ss2pg1">1</a></div><div class="st200_paragraph">
      Spherical lights are represented in the <span class="st200_term package">io7m-r1</span> 
      package by the following types:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s20ss2fo1" href="#st200_p2s20ss2fo1">2.20.2.1. Types</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereWithoutShadow.html">KLightSphereWithoutShadow</a> -
          a spherical light that does not cast shadows.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereWithoutShadowDiffuseOnly.html">KLightSphereWithoutShadowDiffuseOnly</a> -
          a spherical light that does not cast shadows and does not cause specular highlights.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSphereTexturedCubeWithoutShadow.html">KLightSphereTexturedCubeWithoutShadow</a> -
          a spherical light that does not cast shadows, with an additional color term sampled from an associated cube map.
        </li></ul></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s20ss3" href="#st200_p2s20ss3">2.20.3</a></div><div class="st200_subsection_title">Attenuation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss3pg1" href="#st200_p2s20ss3pg1">1</a></div><div class="st200_paragraph">
      The light supports <a class="st200_link" href="#st200_p2s18ss4">attenuation</a> 
      using the <span class="st200_term term">radius</span> as the maximum range.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s20ss4" href="#st200_p2s20ss4">2.20.4</a></div><div class="st200_subsection_title">Application</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss4pg1" href="#st200_p2s20ss4pg1">1</a></div><div class="st200_paragraph">
      The final light applied to the surface is given by <span class="st200_term function">spherical</span>
      [<a class="st200_link_external" href="haskell/Spherical.hs">Spherical.hs</a>], where
      <span class="st200_term variable">sr</span>, <span class="st200_term variable">sg</span>,
      <span class="st200_term variable">sb</span> are the red, green, and blue channels,
      respectively, of the surface being lit. The surface-to-light vector 
      <span class="st200_term variable">stl</span> is calculated by normalizing the
      negation of the difference between the the current eye space
      <span class="st200_term variable">surface_position</span> and the eye space
      origin of the light.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s20ss4fo1" href="#st200_p2s20ss4fo1">2.20.4.1. Spherical lighting (Application)</a></div><pre class="st200_verbatim">module Spherical where

import qualified Attenuation
import qualified Color4
import qualified Direction
import qualified LightDiffuse
import qualified LightSpecular
import qualified LightSpherical
import qualified Normal
import qualified Position3
import qualified Specular
import qualified Spaces
import qualified Vector3f
import qualified Vector4f

spherical :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightSpherical.T -&gt; Specular.T -&gt; Color4.T -&gt; Vector3f.T
spherical view n surface_position light specular (Vector4f.V4 sr sg sb _) =
  let
    position_diff   = Position3.sub3 surface_position (LightSpherical.origin light)
    stl             = Vector3f.normalize (Vector3f.negation position_diff)
    distance        = Vector3f.magnitude (position_diff)
    attenuation     = Attenuation.attenuation (LightSpherical.radius light) (LightSpherical.falloff light) distance
    light_color     = LightSpherical.color light
    light_intensity = LightSpherical.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specular stl view n light_color light_intensity specular
    light_da        = Vector3f.scale light_d attenuation
    light_sa        = Vector3f.scale light_s attenuation
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_da
    lit_s           = Vector3f.add3 lit_d light_sa
  in 
    lit_s
</pre></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s20ss5" href="#st200_p2s20ss5">2.20.5</a></div><div class="st200_subsection_title">Shadows</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s20ss5pg1" href="#st200_p2s20ss5pg1">1</a></div><div class="st200_paragraph">
      Spherical lights cannot project shadows. However, the
      <span class="st200_term package">io7m-r1</span> provides
      a so-called <a class="st200_link" href="#st200_p2s21ss8">pseudo-spherical</a>
      lights implemented with six
      <a class="st200_link" href="#st200_p2s21">projective</a> lights,
      each of which can project shadows.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s21" href="#st200_p2s21">2.21</a></div><div class="st200_section_title">Projective Lighting</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss1">2.21.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss2">2.21.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss3">2.21.3. Back projection</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss4">2.21.4. Clamping</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss5">2.21.5. Types</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss6">2.21.6. Attenuation</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss7">2.21.7. Application</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s21ss8">2.21.8. Pseudo-Spherical Lights</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss1" href="#st200_p2s21ss1">2.21.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss1pg1" href="#st200_p2s21ss1pg1">1</a></div><div class="st200_paragraph">
      A <span class="st200_term term">projective light</span> in the 
      <span class="st200_term package">io7m-r1</span> package
      is a light that <span class="st200_term term">projects</span> a texture
      onto the visible set from a given <span class="st200_term term">origin</span> 
      specified in <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      up to a given maximum <span class="st200_term term">radius</span>. Projective
      lights are the only types of lights in the 
      <span class="st200_term package">io7m-r1</span> package that
      are able to project <span class="st200_term term">shadows</span>.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss1fo1" href="#st200_p2s21ss1fo1">2.21.1.1. Projective lighting</a></div><img class="st200_image" alt="Projective lighting" src="images/projective.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss1fo2" href="#st200_p2s21ss1fo2">2.21.1.2. Projective lighting (Texture)</a></div><img class="st200_image" alt="Projective lighting (Texture)" src="images/sunflower.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss2" href="#st200_p2s21ss2">2.21.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss2pg1" href="#st200_p2s21ss2pg1">1</a></div><div class="st200_paragraph">
      At a basic level, a projective light performs the same operations that
      occur when an ordinary 3D position is projected onto the screen during
      rendering. During normal rendering, a point <span class="st200_term expression">p</span>
      given in <a class="st200_link" href="#st200_p2s3ss4">world space</a>
      is transformed to <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      given the current camera's <span class="st200_term term">view matrix</span>, and
      is then transformed to <a class="st200_link" href="#st200_p2s3ss6">clip space</a>
      using the current camera's <span class="st200_term term">projection matrix</span>.
      During rendering of a scene lit by a projective light, a given point
      <span class="st200_term expression">q</span> in the scene is transformed back to
      <span class="st200_term term">world space</span> given the current camera's
      <span class="st200_term term">inverse view matrix</span>, and is then transformed
      to <span class="st200_term term">eye space from the point of view of the light</span>
      (subsequently referred to as <span class="st200_term term">light-eye space</span>)
      using the light's <span class="st200_term term">view matrix</span>. Finally,
      <span class="st200_term expression">q</span> is transformed to
      <span class="st200_term term">clip space from the point of view of the light</span>
      (subsequently referred to as <span class="st200_term term">light-clip space</span>)
      using the light's <span class="st200_term term">projection matrix</span>. It should
      be noted (in order to indicate that there is nothing unusual about the light's
      view or projection matrices) that if the camera and light have the same position,
      orientation, scale, and projection, then the resulting transformed values of
      <span class="st200_term expression">q</span> and <span class="st200_term expression">p</span>
      are identical. The resulting transformed value of <span class="st200_term expression">q</span>
      is mapped from the range <span class="st200_term expression">[(-1, -1, -1), (1, 1, 1)]</span>
      to <span class="st200_term expression">[(0, 0, 0), (1, 1, 1)]</span>, and the resulting
      coordinates are used to retrieve a texel from the 2D texture associated with
      the light.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss2pg2" href="#st200_p2s21ss2pg2">2</a></div><div class="st200_paragraph">
      Intuitively, an ordinary <span class="st200_term term">perspective projection</span> will cause
      the light to appear to take the shape of a <span class="st200_term term">frustum</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss2fo1" href="#st200_p2s21ss2fo1">2.21.2.1. Projective lighting (Frustum)</a></div><img class="st200_image" alt="Projective lighting (Frustum)" src="images/projective_frustum.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss2pg3" href="#st200_p2s21ss2pg3">3</a></div><div class="st200_paragraph">
      There are two issues with the projective lighting algorithm that also have to be solved: 
      <a class="st200_link" href="#st200_p2s21ss3">back projection</a>
      and
      <a class="st200_link" href="#st200_p2s21ss4">clamping</a>.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss3" href="#st200_p2s21ss3">2.21.3</a></div><div class="st200_subsection_title">Back projection</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss3pg1" href="#st200_p2s21ss3pg1">1</a></div><div class="st200_paragraph">
      The <a class="st200_link" href="#st200_p2s21ss2">algorithm</a>
      described above will produce a so-called 
      <span class="st200_term term">dual</span> or <span class="st200_term term">back projection</span>.
      In other words, the texture will be projected along the view direction of the
      camera, but will also be projected along the <span class="st200_term term">negative</span>
      view direction
      <span class="st200_footnote_reference"><a id="st200_fn_34_ref" href="#st200_fn_34">[34]</a></span>. The visual result is that it appears that there are two projective
      lights in the scene, oriented in opposite directions. 
      As <a class="st200_link" href="#st200_p2s3ss6">mentioned previously</a>,
      given the typical projection matrix, the <span class="st200_term expression">w</span>
      component of a given clip-space position is the negation of the eye-space
      <span class="st200_term expression">z</span> component. 
      Because it is assumed that the observer is looking towards the negative 
      <span class="st200_term expression">z</span> direction, all positions that are in front
      of the observer must have positive <span class="st200_term expression">w</span> components. 
      Therefore, if <span class="st200_term expression">w</span> is negative, then the position 
      is behind the observer. The standard fix for this
      problem is to check to see if the <span class="st200_term expression">w</span> component
      of the <span class="st200_term term">light-clip space</span> coordinate is negative, and
      simply return a pure black color (indicating no light contribution) rather than
      sampling from the projected texture.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss3pg2" href="#st200_p2s21ss3pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package takes an
      arguably simpler approach to the problem. Because projective lights are only applied
      by the <a class="st200_link" href="#st200_p2s12">deferred renderer</a>, and because
      the deferred renderer uses accurate light volumes, pixels that fall outside of the
      light volume are simply not shaded (meaning that back-projection is free to occur, but
      pixels that would receive light contributions due to it are simply outside of the
      light volume). The package essentially depends on the rasterization process and
      depth testing to ensure that no pixels that would have received a back-projection
      will be shaded during rendering of the light.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss4" href="#st200_p2s21ss4">2.21.4</a></div><div class="st200_subsection_title">Clamping</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss4pg1" href="#st200_p2s21ss4pg1">1</a></div><div class="st200_paragraph">
      The <a class="st200_link" href="#st200_p2s21ss2">algorithm</a>
      described above takes an arbitrary point in the scene and projects it from the
      point of view of the light. There is no guarantee that the point actually falls
      within the light's view frustum (although this is mitigated slightly by the
      <span class="st200_term package">io7m-r1</span> package's use of
      <a class="st200_link" href="#st200_p2s21ss3pg2">light volumes</a>
      for deferred rendering), and therefore the calculated texture coordinates used
      to sample from the projected texture are not guaranteed to be in the range
      <span class="st200_term expression">[(0, 0), (1, 1)]</span>. In order to get the
      intended visual effect, the texture used must be set to
      <span class="st200_term term">clamp-to-edge</span> and have black pixels on
      all of the edges of the texture image, or <span class="st200_term term">clamp-to-border</span>
      with a black border color. Failing to do this can result in strange visual
      anomalies, as the texture will be unexpectedly repeated or smeared across
      the area outside of the intersection between the light volume and the
      receiving surface:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss4fo1" href="#st200_p2s21ss4fo1">2.21.4.1. Projective lighting (Correct, clamped)</a></div><img class="st200_image" alt="Projective lighting (Correct, clamped)" src="images/projective_clamped.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss4fo2" href="#st200_p2s21ss4fo2">2.21.4.2. Projective lighting (Incorrect, not clamped)</a></div><img class="st200_image" alt="Projective lighting (Incorrect, not clamped)" src="images/projective_not_clamped.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss4pg2" href="#st200_p2s21ss4pg2">2</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package will
      raise an exception if a non-clamped texture is assigned to a projective light.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss5" href="#st200_p2s21ss5">2.21.5</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss5pg1" href="#st200_p2s21ss5pg1">1</a></div><div class="st200_paragraph">
      Projective lights are represented in the <span class="st200_term package">io7m-r1</span> 
      package by the following types:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss5fo1" href="#st200_p2s21ss5fo1">2.21.5.1. Types</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithoutShadow.html">KLightProjectiveWithoutShadow</a> -
          a projective light that does not project shadows.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithoutShadowDiffuseOnly.html">KLightProjectiveWithoutShadowDiffuseOnly</a> -
          a projective light that does not project shadows, and does not cause specular highlights.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowBasic.html">KLightProjectiveWithShadowBasic</a> -
          a projective light that projects <a class="st200_link" href="#st200_p2s23">basic shadows</a>.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowBasicDiffuseOnly.html">KLightProjectiveWithShadowBasicDiffuseOnly</a> -
          a projective light that projects <a class="st200_link" href="#st200_p2s23">basic shadows</a>, and does not cause specular highlights.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowVariance.html">KLightProjectiveWithShadowVariance</a> -
          a projective light that projects <a class="st200_link" href="#st200_p2s24">variance shadows</a>.
        </li><li class="st200_list_item">
          <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightProjectiveWithShadowVarianceDiffuseOnly.html">KLightProjectiveWithShadowVarianceDiffuseOnly</a> -
          a projective light that projects <a class="st200_link" href="#st200_p2s24">variance shadows</a>, and does not cause specular highlights.
        </li></ul></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss6" href="#st200_p2s21ss6">2.21.6</a></div><div class="st200_subsection_title">Attenuation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss6pg1" href="#st200_p2s21ss6pg1">1</a></div><div class="st200_paragraph">
      The light supports <a class="st200_link" href="#st200_p2s18ss4">attenuation</a> 
      using the maximum range taken from the projection.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss7" href="#st200_p2s21ss7">2.21.7</a></div><div class="st200_subsection_title">Application</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss7pg1" href="#st200_p2s21ss7pg1">1</a></div><div class="st200_paragraph">
      The final light applied to the surface is given by <span class="st200_term function">projective</span>
      [<a class="st200_link_external" href="haskell/Projective.hs">Projective.hs</a>], where
      <span class="st200_term variable">sr</span>, <span class="st200_term variable">sg</span>,
      <span class="st200_term variable">sb</span> are the red, green, and blue channels,
      respectively, of the surface being lit. The surface-to-light vector 
      <span class="st200_term variable">stl</span> is calculated by normalizing the
      negation of the difference between the the current eye space
      <span class="st200_term variable">surface_position</span> and the eye space
      origin of the light.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss7fo1" href="#st200_p2s21ss7fo1">2.21.7.1. Projective lighting (Application)</a></div><pre class="st200_verbatim">module Projective where

import qualified Attenuation
import qualified Color3
import qualified Color4
import qualified Direction
import qualified LightDiffuse
import qualified LightSpecular
import qualified LightProjective
import qualified Normal
import qualified Position3
import qualified Specular
import qualified Spaces
import qualified Vector3f
import qualified Vector4f

projective :: Direction.T Spaces.Eye -&gt; Normal.T -&gt; Position3.T Spaces.Eye -&gt; LightProjective.T -&gt; Specular.T -&gt; Float -&gt; Color3.T -&gt; Color4.T -&gt; Vector3f.T
projective view n surface_position light specular shadow texture (Vector4f.V4 sr sg sb _) =
  let
    position_diff   = Position3.sub3 surface_position (LightProjective.origin light)
    stl             = Vector3f.normalize (Vector3f.negation position_diff)
    distance        = Vector3f.magnitude (position_diff)
    attenuation_raw = Attenuation.attenuation (LightProjective.radius light) (LightProjective.falloff light) distance
    attenuation     = attenuation_raw * shadow
    light_color     = Vector3f.mult3 (LightProjective.color light) texture
    light_intensity = LightProjective.intensity light
    light_d         = LightDiffuse.diffuse stl n light_color light_intensity
    light_s         = LightSpecular.specular stl view n light_color light_intensity specular
    light_da        = Vector3f.scale light_d attenuation
    light_sa        = Vector3f.scale light_s attenuation
    lit_d           = Vector3f.mult3 (Vector3f.V3 sr sg sb) light_da
    lit_s           = Vector3f.add3 lit_d light_sa
  in 
    lit_s
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss7pg2" href="#st200_p2s21ss7pg2">2</a></div><div class="st200_paragraph">
      The given <span class="st200_term variable">shadow</span> factor is a value in the
      range <span class="st200_term expression">[0, 1]</span>, where 
      <span class="st200_term expression">0</span> indicates that the lit point is fully
      in shadow for the current light, and <span class="st200_term expression">1</span>
      indicates that the lit point is not in shadow. This is calculated for
      <a class="st200_link" href="#st200_p2s23">basic</a> and 
      <a class="st200_link" href="#st200_p2s24">variance</a> shadows
      and is assumed to be <span class="st200_term expression">1</span> for
      lights without shadows. As can be seen, a value of <span class="st200_term expression">0</span>
      has the effect of fully attenuating the light.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss7pg3" href="#st200_p2s21ss7pg3">3</a></div><div class="st200_paragraph">
      The color denoted by <span class="st200_term variable">texture</span> is assumed
      to have been sampled from the projected texture. Assuming the eye-space
      position being shaded <span class="st200_term expression">p</span>, the matrix
      to get from eye-space to light-clip space is given by 
      The final light applied to the surface is given by <span class="st200_term function">projective_matrix</span>
      [<a class="st200_link_external" href="haskell/ProjectiveMatrix.hs">ProjectiveMatrix.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss7fo2" href="#st200_p2s21ss7fo2">2.21.7.2. Projective matrix</a></div><pre class="st200_verbatim">module ProjectiveMatrix where

import qualified Matrix4f

projective_matrix :: Matrix4f.T -&gt; Matrix4f.T -&gt; Matrix4f.T -&gt; Matrix4f.T
projective_matrix camera_view light_view light_projection =
  case Matrix4f.inverse camera_view of
    Just cv -&gt; Matrix4f.mult (Matrix4f.mult light_projection light_view) cv
    Nothing -&gt; undefined -- A view matrix is always invertible

</pre></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s21ss8" href="#st200_p2s21ss8">2.21.8</a></div><div class="st200_subsection_title">Pseudo-Spherical Lights</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss8pg1" href="#st200_p2s21ss8pg1">1</a></div><div class="st200_paragraph">
      As mentioned, the <span class="st200_term package">io7m-r1</span> package
      does not support shadow projection for
      <a class="st200_link" href="#st200_p2s20">spherical</a> lights. However,
      spherical lights can be emulated with six projective lights, each of which
      can be configured to project shadows.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss8pg2" href="#st200_p2s21ss8pg2">2</a></div><div class="st200_paragraph">
      A <span class="st200_term term">pseudo-spherical</span> light is six projective 
      <span class="st200_term term">sub-lights</span>,
      each of which are oriented along the major axis directions with projections that
      have a <span class="st200_term expression">90Â°</span> field of view.
      <a class="st200_link" href="#st200_p2s11ss3">Shadow casters</a> are assigned
      to each sub-light as with any ordinary projective light.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s21ss8fo1" href="#st200_p2s21ss8fo1">2.21.8.1. Pseudo-spherical Lighting</a></div><img class="st200_image" alt="Pseudo-spherical Lighting" src="images/projective_pseudosphere.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s21ss8pg3" href="#st200_p2s21ss8pg3">3</a></div><div class="st200_paragraph">
      Pseudo-spherical lights are provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithShadowBasic.html">KLightSpherePseudoWithShadowBasic</a>,
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithShadowVariance.html">KLightSpherePseudoWithShadowVariance</a>,
      and
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KLightSpherePseudoWithoutShadow.html">KLightSpherePseudoWithoutShadow</a>
      types.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s22" href="#st200_p2s22">2.22</a></div><div class="st200_section_title">Shadows</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s22ss1">2.22.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s22ss2">2.22.2. Caching</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s22ss1" href="#st200_p2s22ss1">2.22.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s22ss1pg1" href="#st200_p2s22ss1pg1">1</a></div><div class="st200_paragraph">
      Because the <span class="st200_term package">io7m-r1</span> package
      implements <span class="st200_term term">local illumination</span>, it is necessary
      to associate <span class="st200_term term">shadows</span> with those light sources
      capable of projecting them (currently only 
      <a class="st200_link" href="#st200_p2s21">projective</a> lights).
      The <span class="st200_term package">io7m-r1</span> package currently
      supports <a class="st200_link" href="#st200_p2s23">basic</a> and
      <a class="st200_link" href="#st200_p2s24">variance</a> 
      <span class="st200_term term">shadow mapping</span>. So-called
      <span class="st200_term term">mapped</span> shadows allow efficient per-pixel
      shadows to be calculated with varying degrees of visual quality.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s22ss2" href="#st200_p2s22ss2">2.22.2</a></div><div class="st200_subsection_title">Caching</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s22ss2pg1" href="#st200_p2s22ss2pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      creates new shadow maps on demand during rendering, and the maps are
      returned to a soft-bounded <span class="st200_footnote_reference"><a id="st200_fn_35_ref" href="#st200_fn_35">[35]</a></span>
      cache after use. This implies that in a visible
      set with <span class="st200_term expression">n</span> shadow-projecting lights,
      there will be at least <span class="st200_term expression">n</span> shadow maps 
      allocated and in use at any one time. Shadow maps are requested from the cache
      based on their
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KShadowMapDescriptionType.html">map description</a>,
      and unused maps are discarded from the cache after a configurable time
      period. The intention is to avoid having to frequently allocate new
      shadow maps without requiring that all maps be allocated up-front, and
      without exhausting all available memory on shadow maps.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s22ss2pg2" href="#st200_p2s22ss2pg2">2</a></div><div class="st200_paragraph">
      The functions responsible for creating a new shadow map based on a
      map description are given in
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KShadowMapCacheLoader.html">KShadowMapCacheLoader</a>,
      with the actual map implementation for basic shadow mapping given in
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KShadowMapBasic.html">KShadowMapBasic</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s22ss2pg3" href="#st200_p2s22ss2pg3">3</a></div><div class="st200_paragraph">
      The actual production of all shadow maps is managed by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KShadowMapRenderer.html">KShadowMapRenderer</a>
      type.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s23" href="#st200_p2s23">2.23</a></div><div class="st200_section_title">Shadow mapping - Basic</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s23ss1">2.23.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s23ss2">2.23.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s23ss3">2.23.3. Issues</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s23ss4">2.23.4. Types</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s23ss1" href="#st200_p2s23ss1">2.23.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss1pg1" href="#st200_p2s23ss1pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Basic shadow mapping</span> is a technique
      that results in simple per-pixel hard-edged shadows. Using the same
      view and projection matrices used to apply
      <a class="st200_link" href="#st200_p2s21">projective lights</a>,
      a <span class="st200_term term">depth-only</span> image of the current
      scene is rendered, and those stored depth values
      are compared with those in the rendered scene to determine if a given
      point is in shadow with respect to the current light.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s23ss2" href="#st200_p2s23ss2">2.23.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss2pg1" href="#st200_p2s23ss2pg1">1</a></div><div class="st200_paragraph">
      Prior to actually <a class="st200_link" href="#st200_p2s12">rendering</a> 
      a visible set, <span class="st200_term term">shadow maps</span> are generated
      for all <span class="st200_term term">shadow-projecting</span> lights in
      the set. A <span class="st200_term term">shadow map</span> for basic shadow
      mapping for a light <span class="st200_term expression">k</span> is an image of all of the 
      <a class="st200_link" href="#st200_p2s11ss3">shadow casters</a>
      associated with <span class="st200_term expression">k</span>
      in the visible set, rendered from the point of
      view of <span class="st200_term expression">k</span>. Each pixel in the image
      represents the <a class="st200_link" href="#st200_p2s14">logarithmic depth</a>
      of the closest surface at that pixel. For example:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s23ss2fo1" href="#st200_p2s23ss2fo1">2.23.2.1. Depth-only image</a></div><img class="st200_image" alt="Depth-only image" src="images/d_depth.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss2pg2" href="#st200_p2s23ss2pg2">2</a></div><div class="st200_paragraph">
      Darker pixels indicate a lower depth value than light pixels, 
      which indicate that the surface was closer to the observer than
      in the lighter case.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss2pg3" href="#st200_p2s23ss2pg3">3</a></div><div class="st200_paragraph">
      Then, when actually applying lighting during rendering of the
      scene, a given <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      position <span class="st200_term expression">p</span> is transformed to
      <a class="st200_link" href="#st200_p2s21ss2">light-clip space</a>
      and mapped to the range
      <span class="st200_term expression">[(0, 0, 0), (1, 1, 1)]</span>, producing
      a position <span class="st200_term variable">pos_light_clip</span>. The
      same <span class="st200_term expression">p</span> is also transformed to
      light-eye space, producing a position 
      <span class="st200_term variable">pos_light_eye</span>.
      The <span class="st200_term variable">pos_light_clip</span> position is used
      directly in order to sample a value <span class="st200_term expression">d</span>
      from the shadow map (as with sampling from a projected texture with projective 
      lighting). The negated <span class="st200_term expression">z</span> component of 
      <span class="st200_term expression">pos_light_eye</span> is encoded as a logarithmic
      depth value using the same <span class="st200_term term">depth coefficient</span>
      as was used when populating the shadow map, producing a value
      <span class="st200_term expression">k</span>. Then,
      <span class="st200_term expression">k</span> is compared against
      <span class="st200_term expression">d</span>. If the 
      <span class="st200_term expression">k</span>
      is less than <span class="st200_term expression">d</span>, then this
      means that <span class="st200_term expression">p</span> is closer to
      the light than whatever surface resulted in 
      <span class="st200_term expression">d</span> during the population
      of the shadow map, and therefore <span class="st200_term expression">p</span>
      is not in shadow with respect to the light.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s23ss3" href="#st200_p2s23ss3">2.23.3</a></div><div class="st200_subsection_title">Issues</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss3pg1" href="#st200_p2s23ss3pg1">1</a></div><div class="st200_paragraph">
      Unfortunately, the basic shadow mapping algorithm is subject
      to a number of issues related to numerical imprecision, and
      the <span class="st200_term package">io7m-r1</span> package
      applies a number of user-adjustable workarounds for the problems.
      Firstly, the algorithm is prone to a problem known as
      <span class="st200_term term">shadow acne</span>, which
      generally manifests as strange moirÃ© patterns and dots on
      surfaces. This is caused by <span class="st200_term term">self-shadowing</span>
      which is caused by, amongst other things, <span class="st200_term term">quantization</span> 
      in the storage of depth values:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s23ss3fo1" href="#st200_p2s23ss3fo1">2.23.3.1. Depth quantization</a></div><img class="st200_image" alt="Depth quantization" src="images/basic_shadow_depth_quant.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss3pg2" href="#st200_p2s23ss3pg2">2</a></div><div class="st200_paragraph">
      One widely used workaround to prevent <span class="st200_term term">self-shadowing</span>
      is to <span class="st200_term term">bias</span> stored depth values by
      a user-configurable amount, effectively increasing the likelihood
      that a given point will not be considered to be in shadow. Unfortunately,
      adding a <span class="st200_term term">bias</span> value that is too large
      tends to result in a visual effect where shadows appear to 
      become "detached" from their casting objects, because the the bias
      value is causing the depth test to pass at positions where the shadow
      touches the caster.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss3pg3" href="#st200_p2s23ss3pg3">3</a></div><div class="st200_paragraph">
      Another workaround to help prevent <span class="st200_term term">self-shadowing</span>
      is to only render the <span class="st200_term term">back-faces</span> of
      geometry into the shadow map. Unfortunately, this can result in very
      thin geometry failing to cast shadows.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss3pg4" href="#st200_p2s23ss3pg4">4</a></div><div class="st200_paragraph">
      Finally, it is generally beneficial to increase the precision of
      stored values in the shadow map by using a 
      <span class="st200_term term">projection</span> for the light that has
      the <span class="st200_term term">near</span> and
      <span class="st200_term term">far</span> planes as close together as the
      light will allow. In other words, if the light has a radius of
      <span class="st200_term expression">10</span> units, then it is beneficial
      to use a far plane at <span class="st200_term expression">10</span> units,
      in order to allow for the best distribution of depth values in
      that range.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss3pg5" href="#st200_p2s23ss3pg5">5</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      implements both <span class="st200_term term">back-face</span>-only rendering,
      and a configurable per-shadow <span class="st200_term term">bias</span> value.
      Unfortunately, neither of these workarounds can ever fully solve the
      problems, so the package also provides
      <a class="st200_link" href="#st200_p2s24">variance shadows</a>
      which have far fewer artifacts and better visual quality at a slightly
      higher computational cost.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s23ss4" href="#st200_p2s23ss4">2.23.4</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss4pg1" href="#st200_p2s23ss4pg1">1</a></div><div class="st200_paragraph">
      Basic mapped shadows are represented by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KShadowMappedBasic.html">KShadowMappedBasic</a>
      type, and can be associated with
      <a class="st200_link" href="#st200_p2s21">projective lights</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s23ss4pg2" href="#st200_p2s23ss4pg2">2</a></div><div class="st200_paragraph">
      Rendering of depth-only images is handled by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KDepthRendererType.html">KDepthRendererType</a>
      type.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s24" href="#st200_p2s24">2.24</a></div><div class="st200_section_title">Shadow mapping - Variance</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s24ss1">2.24.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s24ss2">2.24.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s24ss3">2.24.3. Types</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s24ss1" href="#st200_p2s24ss1">2.24.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss1pg1" href="#st200_p2s24ss1pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Variance shadow mapping</span> is a technique
      that can give attractive soft-edged shadows. Using the same
      view and projection matrices used to apply
      <a class="st200_link" href="#st200_p2s21">projective lights</a>,
      a <span class="st200_term term">depth-variance</span> image of the current
      scene is rendered, and those stored depth distribution values
      are used to determine the probability that a given
      point in the scene is in shadow with respect to the current light.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss1pg2" href="#st200_p2s24ss1pg2">2</a></div><div class="st200_paragraph">
      The algorithm implemented in the <span class="st200_term package">io7m-r1</span> 
      package is described in
      <a class="st200_link_external" href="http://http.developer.nvidia.com/GPUGems3/gpugems3_ch08.html">GPU Gems 3</a>,
      which is a set of improvements to the original variance shadow mapping
      algorithm by William Donnelly and Andrew Lauritzen. The
      <span class="st200_term package">io7m-r1</span> package implements
      all of the improvements to the algorithm except
      <span class="st200_term term">summed area tables</span>. The package also provides
      optional box blurring of shadows as described in the chapter.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s24ss2" href="#st200_p2s24ss2">2.24.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg1" href="#st200_p2s24ss2pg1">1</a></div><div class="st200_paragraph">
      Prior to actually <a class="st200_link" href="#st200_p2s12">rendering</a> 
      a visible set, <span class="st200_term term">shadow maps</span> are generated
      for all <span class="st200_term term">shadow-projecting</span> lights in
      the set. A <span class="st200_term term">shadow map</span> for variance shadow
      mapping, for a light <span class="st200_term expression">k</span>, is a two-component 
      red/green image of all of the 
      <a class="st200_link" href="#st200_p2s11ss3">shadow casters</a>
      associated with <span class="st200_term expression">k</span> in the visible set.
      The image is produced by rendering the instances from the point of view of
      <span class="st200_term expression">k</span>. The red
      channel of each pixel in the image represents the 
      <a class="st200_link" href="#st200_p2s14">logarithmic depth</a>
      of the closest surface at that pixel, and the green channel represents
      the depth squared (literally <span class="st200_term expression">depth * depth</span>). 
      For example:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo1" href="#st200_p2s24ss2fo1">2.24.2.1. Depth-variance image</a></div><img class="st200_image" alt="Depth-variance image" src="images/depth_variance.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg2" href="#st200_p2s24ss2pg2">2</a></div><div class="st200_paragraph">
      Then, when actually applying lighting during rendering of the
      scene, a given <a class="st200_link" href="#st200_p2s3ss5">eye space</a>
      position <span class="st200_term expression">p</span> is transformed to
      <a class="st200_link" href="#st200_p2s21ss2">light-clip space</a>
      and then mapped to the range
      <span class="st200_term expression">[(0, 0, 0), (1, 1, 1)]</span> in order
      to sample the <span class="st200_term term">depth</span> and
      <span class="st200_term term">depth squared</span> values
      <span class="st200_term expression">(d, ds)</span>
      from the shadow map (as with sampling from a projected texture
      with projective lighting). 
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg3" href="#st200_p2s24ss2pg3">3</a></div><div class="st200_paragraph">
      As stated previously, the intent of variance
      shadow mapping is to essentially calculate the 
      <span class="st200_term term">probability</span> that a given point is in shadow,
      rather than the binary <span class="st200_term term">is/is not</span> of
      <a class="st200_link" href="#st200_p2s23">basic shadow mapping</a>.
      A <span class="st200_term term">one-tailed</span> variant of
      <a class="st200_link_external" href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">Chebyshev's inequality</a>
      is used to calculate the upper bound <span class="st200_term expression">u</span>
      on the probability that, given
      <span class="st200_term expression">(d, ds)</span>, a given point with depth
      <span class="st200_term expression">t</span> is in shadow:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo2" href="#st200_p2s24ss2fo2">2.24.2.2. Chebyshev 0</a></div><pre class="st200_verbatim">module ShadowVarianceChebyshev0 where

chebyshev :: (Float, Float) -&gt; Float -&gt; Float
chebyshev (d, ds) t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = ds - (d * d)
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

factor :: (Float, Float) -&gt; Float -&gt; Float
factor = chebyshev
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg4" href="#st200_p2s24ss2pg4">4</a></div><div class="st200_paragraph">
      One of the improvements suggested to the original variance shadow
      algorithm is to clamp the minimum variance to some small value
      (the <span class="st200_term package">io7m-r1</span> package uses <span class="st200_term constant">0.00002</span>
      by default, but this is configurable on a per-shadow basis). The
      equation above becomes:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo3" href="#st200_p2s24ss2fo3">2.24.2.3. Chebyshev 1</a></div><pre class="st200_verbatim">module ShadowVarianceChebyshev1 where

data T = T {
  minimum_variance :: Float
} deriving (Eq, Show)

chebyshev :: (Float, Float) -&gt; Float -&gt; Float -&gt; Float
chebyshev (d, ds) min_variance t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = max (ds - (d * d)) min_variance
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

factor :: T -&gt; (Float, Float) -&gt; Float -&gt; Float
factor shadow (d, ds) t =
  chebyshev (d, ds) (minimum_variance shadow) t
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg5" href="#st200_p2s24ss2pg5">5</a></div><div class="st200_paragraph">
      The above is sufficient to give shadows that are roughly equivalent
      in visual quality to <a class="st200_link" href="#st200_p2s23">basic shadow mapping</a>
      with the added benefit of being generally better behaved and with
      far fewer artifacts. However, the algorithm can suffer from
      <span class="st200_term term">light bleeding</span>, where the penumbrae
      of overlapping shadows can be unexpectedly bright despite the fact
      that the entire area should be in shadow. One of the suggested
      improvements to reduce light bleeding is to modify the upper bound
      <span class="st200_term expression">u</span> such that all values below
      a configurable threshold are mapped to zero, and values above the
      threshold are rescaled to map them to the range
      <span class="st200_term expression">[0, 1]</span>. The original article
      suggests a linear step function applied to 
      <span class="st200_term expression">u</span>:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo4" href="#st200_p2s24ss2fo4">2.24.2.4. Chebyshev 2</a></div><pre class="st200_verbatim">module ShadowVarianceChebyshev2 where

data T = T {
  minimum_variance :: Float,
  bleed_reduction  :: Float
} deriving (Eq, Show)

chebyshev :: (Float, Float) -&gt; Float -&gt; Float -&gt; Float
chebyshev (d, ds) min_variance t =
  let p        = if t &lt;= d then 1.0 else 0.0
      variance = max (ds - (d * d)) min_variance
      du       = t - d
      p_max    = variance / (variance + (du * du))
  in max p p_max

clamp :: Float -&gt; (Float, Float) -&gt; Float
clamp x (lower, upper) = max (min x upper) lower

linear_step :: Float -&gt; Float -&gt; Float -&gt; Float
linear_step lower upper x = clamp ((x - lower) / (upper - lower)) (0.0, 1.0)

factor :: T -&gt; (Float, Float) -&gt; Float -&gt; Float
factor shadow (d, ds) t =
  let u = chebyshev (d, ds) (minimum_variance shadow) t in
    linear_step (bleed_reduction shadow) 1.0 u
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg6" href="#st200_p2s24ss2pg6">6</a></div><div class="st200_paragraph">
      The amount of light bleed reduction is adjustable on a per-shadow
      basis.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg7" href="#st200_p2s24ss2pg7">7</a></div><div class="st200_paragraph">
      To reduce problems involving numeric inaccuracy, the
      original article suggests the use of 32-bit floating point textures
      in depth variance maps. The <span class="st200_term package">io7m-r1</span>
      package allows 16-bit or 32-bit textures, configurable on a per-shadow basis.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss2pg8" href="#st200_p2s24ss2pg8">8</a></div><div class="st200_paragraph">
      Finally, as mentioned previously, the <span class="st200_term package">io7m-r1</span>
      package allows both optional box blurring and mipmap generation for shadow
      maps. Both blurring and mipmapping can reduce aliasing artifacts,
      with the former also allowing the edges of shadows to be significantly
      softened as a visual effect:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo5" href="#st200_p2s24ss2fo5">2.24.2.5. Depth-variance shadows (Minimal blur)</a></div><img class="st200_image" alt="Depth-variance shadows (Minimal blur)" src="images/variance_0.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s24ss2fo6" href="#st200_p2s24ss2fo6">2.24.2.6. Depth-variance shadows (High blur)</a></div><img class="st200_image" alt="Depth-variance shadows (High blur)" src="images/variance_1.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s24ss3" href="#st200_p2s24ss3">2.24.3</a></div><div class="st200_subsection_title">Types</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss3pg1" href="#st200_p2s24ss3pg1">1</a></div><div class="st200_paragraph">
      Variance mapped shadows are represented by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KShadowMappedVariance.html">KShadowMappedVariance</a>
      type, and can be associated with
      <a class="st200_link" href="#st200_p2s21">projective lights</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s24ss3pg2" href="#st200_p2s24ss3pg2">2</a></div><div class="st200_paragraph">
      Rendering of depth-variance images is handled by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KDepthVarianceRendererType.html">KDepthVarianceRendererType</a>
      type.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s25" href="#st200_p2s25">2.25</a></div><div class="st200_section_title">Generic Refraction</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s25ss1">2.25.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s25ss2">2.25.2. Algorithm</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s25ss3">2.25.3. Masking</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s25ss4">2.25.4. Vectors</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s25ss5">2.25.5. Color</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s25ss1" href="#st200_p2s25ss1">2.25.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss1pg1" href="#st200_p2s25ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> package
      implements the <span class="st200_term term">generic refraction</span> effect
      described in <a class="st200_link_external" href="http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter19.html">GPU Gems 2</a>.
      The technique lends itself to a huge range of effects such as lenses, glass,
      heat haze, and water - simply by varying the meshes and textures used 
      when performing refraction.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s25ss2" href="#st200_p2s25ss2">2.25.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss2pg1" href="#st200_p2s25ss2pg1">1</a></div><div class="st200_paragraph">
      For a given instance with a
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/types/KMaterialTranslucentRefractive.html">refractive</a>
      material applied, the process to render the instance is as follows:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss2fo1" href="#st200_p2s25ss2fo1">2.25.2.1. Rendering process</a></div><ul class="st200_list_unordered"><li class="st200_list_item">
          Make a temporary copy <span class="st200_term variable">b</span> of the current scene's color buffer.
        </li><li class="st200_list_item">
          If <a class="st200_link" href="#st200_p2s25ss3">masking</a> is
          enabled for the material, render a mask for the instance into a temporary
          mask image <span class="st200_term variable">m</span>.
        </li><li class="st200_list_item">
          Render the instance, using <span class="st200_term variable">b</span> as the
          refraction source, material-dependent 
          <a class="st200_link" href="#st200_p2s25ss4">refraction vectors</a>,
          a <a class="st200_link" href="#st200_p2s25ss5">refraction color</a>,
          and optionally <span class="st200_term variable">m</span> for masking.
        </li></ul></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss2pg2" href="#st200_p2s25ss2pg2">2</a></div><div class="st200_paragraph">
      The actual rendering technique is very simple: Given a screen-space position 
      <span class="st200_term expression">(x, y)</span>, sample the color from a saved
      image of the scene at <span class="st200_term expression">(x + s, y + t)</span>,
      where <span class="st200_term expression">(s, t)</span> are signed per-pixel offset values -
      the <a class="st200_link" href="#st200_p2s25ss4">refraction vectors</a> -
      that are sampled from textures or derived from existing normal vectors.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s25ss3" href="#st200_p2s25ss3">2.25.3</a></div><div class="st200_subsection_title">Masking</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss3pg1" href="#st200_p2s25ss3pg1">1</a></div><div class="st200_paragraph">
      Because refractive instances are 
      <a class="st200_link" href="#st200_p2s15">translucent</a>, they
      are normally rendered after having already rendered all of the opaque
      objects in the scene. Because rendering of translucent instances occurs with
      depth testing enabled, it is therefore possible for opaque instances to
      occlude refractive instances. This poses a problem for the implementation
      of refraction described above, because the pixels of an occluding object
      may be sampled when performing the refraction, as shown in the following
      image:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss3fo1" href="#st200_p2s25ss3fo1">2.25.3.1. Occluding pixel bleeding</a></div><img class="st200_image" alt="Occluding pixel bleeding" src="images/refract_bleed.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss3pg2" href="#st200_p2s25ss3pg2">2</a></div><div class="st200_paragraph">
      Note how the pixels of the opaque instances are bleeding into the refracting
      object, despite being conceptually "in front of" it. This is because the
      refraction effect is implemented in screen space and is just sampling pixels
      from the surrounding area to simulate the bending of light rays. Using
      a <span class="st200_term term">mask</span> prevents this:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss3fo2" href="#st200_p2s25ss3fo2">2.25.3.2. Occluding pixels masked</a></div><img class="st200_image" alt="Occluding pixels masked" src="images/refract_nobleed.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss3pg3" href="#st200_p2s25ss3pg3">3</a></div><div class="st200_paragraph">
      A mask is produced by rendering a black and white silhouette of the
      refracting object, and then using the values of this mask to linearly
      interpolate between the colors at
      <span class="st200_term expression">(x, y)</span> and
      <span class="st200_term expression">(x + s, y + t)</span>. This has the effect
      of preventing the refraction simulation from using pixels that fall outside
      of the mask area.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss3fo3" href="#st200_p2s25ss3fo3">2.25.3.3. Mask</a></div><img class="st200_image" alt="Mask" src="images/refract_mask.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s25ss4" href="#st200_p2s25ss4">2.25.4</a></div><div class="st200_subsection_title">Vectors</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss4pg1" href="#st200_p2s25ss4pg1">1</a></div><div class="st200_paragraph">
      Refraction vectors may either be sampled from the current instance's
      (possibly <a class="st200_link" href="#st200_p2s16">mapped</a>)
      normals, or from the red and green components of a 
      <span class="st200_term term">delta texture</span>. The sampled values are
      scaled by the material's <span class="st200_term term">scale</span> factor
      and used directly to calculate 
      <span class="st200_term expression">(x + s, y + t)</span>. For example,
      a simple noisy red/green <span class="st200_term term">delta texture</span> 
      applied to a quad results in the following effect:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss4fo1" href="#st200_p2s25ss4fo1">2.25.4.1. Noise quad</a></div><img class="st200_image" alt="Noise quad" src="images/refract_noise_quad.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss4fo2" href="#st200_p2s25ss4fo2">2.25.4.2. Noise quad (texture)</a></div><img class="st200_image" alt="Noise quad (texture)" src="images/refract_noise_quad_texture.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s25ss5" href="#st200_p2s25ss5">2.25.5</a></div><div class="st200_subsection_title">Color</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss5pg1" href="#st200_p2s25ss5pg1">1</a></div><div class="st200_paragraph">
      The sampled scene colors used to perform the refraction effect are
      multiplied by a constant color, specified by each material. This
      allows for simple colored glass effects (shown here with a
      <a class="st200_link" href="#st200_p2s15ss2">specular-only</a>
      instance rendered over the top of the refractive instance to provide
      specular highlights):
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss5fo1" href="#st200_p2s25ss5fo1">2.25.5.1. Color 0</a></div><img class="st200_image" alt="Color 0" src="images/refract_color_0.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s25ss5pg2" href="#st200_p2s25ss5pg2">2</a></div><div class="st200_paragraph">
      Using pure RGBA white <span class="st200_term expression">(1.0, 1.0, 1.0, 1.0)</span>
      results in a clear glass material:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s25ss5fo2" href="#st200_p2s25ss5fo2">2.25.5.2. Color 1</a></div><img class="st200_image" alt="Color 1" src="images/refract_color_1.png"/></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s26" href="#st200_p2s26">2.26</a></div><div class="st200_section_title">Filter: Blur</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s26ss1">2.26.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s26ss2">2.26.2. Algorithm</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s26ss1" href="#st200_p2s26ss1">2.26.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s26ss1pg1" href="#st200_p2s26ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> offers
      a set of simple box blurs for use on both color and
      <a class="st200_link" href="#st200_p2s24ss2">depth-variance</a>
      data, with the effect being used on the latter to soften
      the edges of shadows.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s26ss2" href="#st200_p2s26ss2">2.26.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s26ss2pg1" href="#st200_p2s26ss2pg1">1</a></div><div class="st200_paragraph">
      The implemented algorithm is a simple box blur separated into
      horizontal and vertical passes. The package also allows for
      scaling of the image prior to blurring, in order to use bilinear
      filtering during scaling to accentuate the blur effect. The following
      image shows a blur of size <span class="st200_term expression">1.0</span>
      but with the image scaled to <span class="st200_term expression">0.5</span>
      times its original size, the blur applied, and then the
      image scaled back up to the original size again with bilinear
      filtering: 
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s26ss2fo1" href="#st200_p2s26ss2fo1">2.26.2.1. Blur</a></div><img class="st200_image" alt="Blur" src="images/blur.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s26ss2pg2" href="#st200_p2s26ss2pg2">2</a></div><div class="st200_paragraph">
      The blur effect for RGBA data is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterBlurRGBA.html">KImageFilterBlurRGBA</a>
      filter. The blur effect for depth-variance data is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterBlurDepthVariance.html">KImageFilterBlurDepthVariance</a>
      filter.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s27" href="#st200_p2s27">2.27</a></div><div class="st200_section_title">Filter: Emission</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s27ss1">2.27.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s27ss2">2.27.2. Algorithm</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s27ss1" href="#st200_p2s27ss1">2.27.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s27ss1pg1" href="#st200_p2s27ss1pg1">1</a></div><div class="st200_paragraph">
      An <span class="st200_term term">emissive</span> surface is a surface
      that appears to emit light. The <span class="st200_term package">io7m-r1</span> 
      package offers emission as a visual effect implemented as a filter. An optional
      <span class="st200_term term">glow</span> effect is provided to allow emissive
      surfaces to appear to have a configurable 
      <a class="st200_link_external" href="http://en.wikipedia.org/wiki/Halo_%28optical_phenomenon%29">aura</a>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s27ss1pg2" href="#st200_p2s27ss1pg2">2</a></div><div class="st200_paragraph">
      The emission effect is obviously not physically accurate - surfaces do not
      really emit light. The user is expected to make intelligent use of the
      standard <span class="st200_term r1.dai.lighting">light types</span> to provide
      lighting, and to use the emission effect to complement them.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s27ss1fo1" href="#st200_p2s27ss1fo1">2.27.1.1. Emission</a></div><img class="st200_image" alt="Emission" src="images/emission.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s27ss2" href="#st200_p2s27ss2">2.27.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s27ss2pg1" href="#st200_p2s27ss2pg1">1</a></div><div class="st200_paragraph">
      The plain emission effect without <span class="st200_term term">glow</span> is 
      implemented as trivially as possible by sampling the 
      <a class="st200_link" href="#st200_p2s12ss3">emission</a>
      value from a rendered scene's <span class="st200_term term">g-buffer</span>,
      multiplying it by the <span class="st200_term term">albedo</span> color and then
      simply adding the result to the current pixel color.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s27ss2pg2" href="#st200_p2s27ss2pg2">2</a></div><div class="st200_paragraph">
      The emission effect with <span class="st200_term term">glow</span> is implemented
      similarly, except that the <span class="st200_term expression">albedo * emission</span>
      term is stored in a separate image, and that image is blurred with a configurable
      <span class="st200_term term">box blur</span> before being additively blended over the
      original scene. Higher levels of blurring can give the impression of a dusty
      atmosphere.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s27ss2fo1" href="#st200_p2s27ss2fo1">2.27.2.1. Emission (Glow)</a></div><img class="st200_image" alt="Emission (Glow)" src="images/emission_glow.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s27ss2pg3" href="#st200_p2s27ss2pg3">3</a></div><div class="st200_paragraph">
      The emission effect without glow is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterEmission.html">KImageFilterEmission</a>
      filter. The emission effect with glow is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterEmissionGlow.html">KImageFilterEmissionGlow</a>
      filter.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s28" href="#st200_p2s28">2.28</a></div><div class="st200_section_title">Filter: FXAA</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s28ss1">2.28.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s28ss2">2.28.2. Implementation</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s28ss1" href="#st200_p2s28ss1">2.28.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s28ss1pg1" href="#st200_p2s28ss1pg1">1</a></div><div class="st200_paragraph">
      <span class="st200_term term">Fast Approximate Anti-Aliasing</span> is a simple
      algorithm that attempts to detect and smooth <span class="st200_term term">aliasing</span>
      in a color image. The algorithm works with only the color components of the
      image in question; no other per-pixel information or knowledge of the scene
      is required.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s28ss1fo1" href="#st200_p2s28ss1fo1">2.28.1.1. Without FXAA</a></div><img class="st200_image" alt="Without FXAA" src="images/fxaa_without.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s28ss1fo2" href="#st200_p2s28ss1fo2">2.28.1.2. With FXAA</a></div><img class="st200_image" alt="With FXAA" src="images/fxaa_with.png"/></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s28ss2" href="#st200_p2s28ss2">2.28.2</a></div><div class="st200_subsection_title">Implementation</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s28ss2pg1" href="#st200_p2s28ss2pg1">1</a></div><div class="st200_paragraph">
      Unfortunately, information on the FXAA algorithm is sparse, and much of it
      has been lost to time. The original FXAA algorithm was published in a
      whitepaper by NVIDIA
      <span class="st200_footnote_reference"><a id="st200_fn_36_ref" href="#st200_fn_36">[36]</a></span> and was severely optimized by the author on the suggestions
      of many mostly anonymous contributors. The latest published version of
      the algorithm (version 3.11) bears little resemblance to the original
      and no documentation exists on the changes. The 3.11 version of the
      algorithm is constructed from a maze of C preprocessor macros, and
      many different variations of the algorithm are possible based on how
      the parameter macros are defined.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s28ss2pg2" href="#st200_p2s28ss2pg2">2</a></div><div class="st200_paragraph">
      The implementation of FXAA in the <span class="st200_term package">io7m-r1</span>
      package is a set of GLSL expansions of the public domain
      <span class="st200_footnote_reference"><a id="st200_fn_37_ref" href="#st200_fn_37">[37]</a></span>
      <span class="st200_term file">Fxaa3_11.h</span> header with a few minor modifications
      (unused parameter removals). Specifically, the 
      <span class="st200_term term">PC</span> algorithm is used, with quality presets
      <span class="st200_term expression">(10, 15, 20, 25, 29, 39)</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s28ss2pg3" href="#st200_p2s28ss2pg3">3</a></div><div class="st200_paragraph">
      The algorithm is applied via the use of the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/kernel/KImageFilterFXAA.html">KImageFilterFXAA</a>
      filter.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s29" href="#st200_p2s29">2.29</a></div><div class="st200_section_title">Filter: Z Fog</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s29ss1">2.29.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s29ss2">2.29.2. Algorithm</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s29ss1" href="#st200_p2s29ss1">2.29.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s29ss1pg1" href="#st200_p2s29ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> offers
      a filter that provides simple <span class="st200_term term">distance fog</span>
      effects for roughly simulating the scattering of light due to atmosphere.
      It can also be used for special effects such as smoke and dust.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s29ss1fo1" href="#st200_p2s29ss1fo1">2.29.1.1. Fog</a></div><img class="st200_image" alt="Fog" src="images/fog_z.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s29ss1pg2" href="#st200_p2s29ss1pg2">2</a></div><div class="st200_paragraph">
      The fog filter applies a configurable fog color to all pixels in the
      scene, based on given near and far planes for the fog. The fog is
      applied based on the current view direction (the local negative Z axis).
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s29ss2" href="#st200_p2s29ss2">2.29.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s29ss2pg1" href="#st200_p2s29ss2pg1">1</a></div><div class="st200_paragraph">
      The implemented algorithm takes a color <span class="st200_term expression">c</span>,
      an eye-space near fog distance <span class="st200_term expression">near</span>, and an
      eye-space far fog distance <span class="st200_term expression">far</span>. It samples
      the depth of each pixel in the current scene, and
      <a class="st200_link" href="#st200_p2s13ss2">reconstructs</a>
      the eye-space Z component of the surface that produced the pixel in question
      and takes the absolute value of that component to yield a positive distance
      <span class="st200_term expression">z</span> from the observer.
      Then, a <span class="st200_term term">fog factor</span> <span class="st200_term expression">r</span>
      is calculated by <span class="st200_term expression">fog_factor</span>
      [<a class="st200_link_external" href="haskell/FogFactorZ.hs">FogFactorZ.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s29ss2fo1" href="#st200_p2s29ss2fo1">2.29.2.1. Fog factor</a></div><pre class="st200_verbatim">module FogFactorZ where

clamp :: Float -&gt; (Float, Float) -&gt; Float
clamp x (lower, upper) = max (min x upper) lower

fog_factor :: Float -&gt; (Float, Float) -&gt; Float
fog_factor z (near, far) =
  let r = (z - near) / (far - near) in
    clamp r (0.0, 1.0)
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s29ss2pg2" href="#st200_p2s29ss2pg2">2</a></div><div class="st200_paragraph">
      The value of <span class="st200_term expression">r</span> is then used to interpolate
      between the original color of the pixel and <span class="st200_term expression">c</span>.
      Surfaces with <span class="st200_term expression">z</span> less than <span class="st200_term expression">near</span>
      are unaffected by fog. Surfaces with <span class="st200_term expression">z</span> greater than or equal to
      <span class="st200_term expression">far</span> are maximally affected by fog and will actually
      have their color values completely replaced by <span class="st200_term expression">c</span>.
      Surfaces with <span class="st200_term expression">z</span> values that fall between 
      <span class="st200_term expression">near</span>
      and <span class="st200_term expression">far</span> will have differing amounts of fog applied
      based on the type of <span class="st200_term term">fog progression</span> selected.
      The filter offers <span class="st200_term term">linear</span>,
      <span class="st200_term term">exponential</span>, and <span class="st200_term term">logarithmic</span>
      fog progressions. With <span class="st200_term term">linear</span> fog, the
      <span class="st200_term expression">r</span> value linearly interpolates between the
      original surface color and <span class="st200_term expression">c</span>. With
      <span class="st200_term term">exponential</span> fog, the value of 
      <span class="st200_term expression">r * r</span> is used to linearly interpolate
      between the original surface color and <span class="st200_term expression">c</span>.
      Finally, with <span class="st200_term term">logarithmic</span> fog, the value of
      <span class="st200_term expression">sqrt(r)</span> is used to linearly interpolate
      between the original surface color and <span class="st200_term expression">c</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s29ss2pg3" href="#st200_p2s29ss2pg3">3</a></div><div class="st200_paragraph">
      The fog effect is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterFogZ.html">KImageFilterFogZ</a>
      filter.
    </div></div></div></div><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p2s30" href="#st200_p2s30">2.30</a></div><div class="st200_section_title">Filter: Y Fog</div><ul class="st200_contents st200_section_contents_outer st200_section_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s30ss1">2.30.1. Overview</a></li><li class="st200_contents_item st200_contents_item1 st200_contents_item_subsection"><a href="#st200_p2s30ss2">2.30.2. Algorithm</a></li></ul><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s30ss1" href="#st200_p2s30ss1">2.30.1</a></div><div class="st200_subsection_title">Overview</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss1pg1" href="#st200_p2s30ss1pg1">1</a></div><div class="st200_paragraph">
      The <span class="st200_term package">io7m-r1</span> offers
      a filter that provides simple <span class="st200_term term">vertical fog</span>
      effects for simulating various atmospheric effects such as ground fog
      and "house fire" smoke.
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s30ss1fo1" href="#st200_p2s30ss1fo1">2.30.1.1. Fog</a></div><img class="st200_image" alt="Fog" src="images/fog_y.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss1pg2" href="#st200_p2s30ss1pg2">2</a></div><div class="st200_paragraph">
      The fog filter applies a configurable fog color to all pixels in the
      scene, based on given upper and lower planes for the fog.
    </div></div></div><div class="st200_subsection_container"><div class="st200_subsection_title_number"><a id="st200_p2s30ss2" href="#st200_p2s30ss2">2.30.2</a></div><div class="st200_subsection_title">Algorithm</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg1" href="#st200_p2s30ss2pg1">1</a></div><div class="st200_paragraph">
      The implemented algorithm takes a color <span class="st200_term expression">c</span>,
      a world-space upper Y value <span class="st200_term expression">upper_y</span>, and a
      world-space lower Y value <span class="st200_term expression">lower_y</span>. It samples
      the depth of each pixel in the current scene, and
      <a class="st200_link" href="#st200_p2s13">reconstructs</a>
      the full eye-space position of the surface that produced the pixel in question. It
      then transforms this position back to world-space using the scene's inverse
      view matrix, yielding a Y component <span class="st200_term expression">y</span>. 
      Then, a <span class="st200_term term">fog factor</span> <span class="st200_term expression">r</span>
      is calculated by <span class="st200_term expression">fog_factor</span>
      [<a class="st200_link_external" href="haskell/FogFactorY.hs">FogFactorY.hs</a>]:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s30ss2fo1" href="#st200_p2s30ss2fo1">2.30.2.1. Fog factor</a></div><pre class="st200_verbatim">module FogFactorY where

clamp :: Float -&gt; (Float, Float) -&gt; Float
clamp x (lower, upper) = max (min x upper) lower

fog_factor :: Float -&gt; (Float, Float) -&gt; Float
fog_factor y (lower, upper) =
  let r = (y - lower) / (upper - lower) in
    clamp r (0.0, 1.0)
</pre></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg2" href="#st200_p2s30ss2pg2">2</a></div><div class="st200_paragraph">
      The value of <span class="st200_term expression">r</span> is then used to interpolate
      between the original color of the pixel and <span class="st200_term expression">c</span>.
      Surfaces with <span class="st200_term expression">y</span> less than <span class="st200_term expression">lower_y</span>
      are unaffected by fog. Surfaces with <span class="st200_term expression">y</span> greater than or equal to
      <span class="st200_term expression">upper_y</span> are maximally affected by fog and will actually
      have their color values completely replaced by <span class="st200_term expression">c</span>.
      Surfaces with <span class="st200_term expression">y</span> values that fall between 
      <span class="st200_term expression">lower_y</span>
      and <span class="st200_term expression">upper_y</span> will have differing amounts of fog applied
      based on the type of <span class="st200_term term">fog progression</span> selected.
      The filter offers <span class="st200_term term">linear</span>,
      <span class="st200_term term">exponential</span>, and <span class="st200_term term">logarithmic</span>
      fog progressions. With <span class="st200_term term">linear</span> fog, the
      <span class="st200_term expression">r</span> value linearly interpolates between the
      original surface color and <span class="st200_term expression">c</span>. With
      <span class="st200_term term">exponential</span> fog, the value of 
      <span class="st200_term expression">r * r</span> is used to linearly interpolate
      between the original surface color and <span class="st200_term expression">c</span>.
      Finally, with <span class="st200_term term">logarithmic</span> fog, the value of
      <span class="st200_term expression">sqrt(r)</span> is used to linearly interpolate
      between the original surface color and <span class="st200_term expression">c</span>.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg3" href="#st200_p2s30ss2pg3">3</a></div><div class="st200_paragraph">
      If the <span class="st200_term expression">upper_y</span> value is greater than
      the <span class="st200_term expression">lower_y</span> value, the fog will appear
      to get thicker as the Y position decreases. This can be used to give the effect
      of fog on the ground. Unfortunately, the illusion is somewhat ruined if the
      viewer goes below the fog plane:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s30ss2fo2" href="#st200_p2s30ss2fo2">2.30.2.2. Fog (Floor illusion broken)</a></div><img class="st200_image" alt="Fog (Floor illusion broken)" src="images/fog_y_floor_bad.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg4" href="#st200_p2s30ss2pg4">4</a></div><div class="st200_paragraph">
      If the <span class="st200_term expression">lower_y</span> value
      is greater than the <span class="st200_term expression">upper_y</span> value, the
      fog will appear to get thicker as the Y position increases. This can be used
      to give the effect of smoke accumulating at the top of an enclosed space. 
      Unfortunately, the illusion of both types of fog is ruined if the viewer 
      travels above the fog plane:
    </div></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s30ss2fo3" href="#st200_p2s30ss2fo3">2.30.2.3. Fog (Ceiling illusion OK)</a></div><img class="st200_image" alt="Fog (Ceiling illusion OK)" src="images/fog_y_ceil_ok.png"/></div><div class="st200_formal_item"><div class="st200_formal_item_title"><a id="st200_p2s30ss2fo4" href="#st200_p2s30ss2fo4">2.30.2.4. Fog (Ceiling illusion broken)</a></div><img class="st200_image" alt="Fog (Ceiling illusion broken)" src="images/fog_y_ceil_bad.png"/></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg5" href="#st200_p2s30ss2pg5">5</a></div><div class="st200_paragraph">
      The simple-minded nature of the effect means that it should be used to 
      supplement some other simulation of fog. Rendering a simple opaque flat 
      plane the same color as the fog and then applying the fog effect would 
      be sufficient.
    </div></div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p2s30ss2pg6" href="#st200_p2s30ss2pg6">6</a></div><div class="st200_paragraph">
      The fog effect is provided by the
      <a class="st200_link_external" href="apidocs/com/io7m/r1/meshes/KImageFilterFogY.html">KImageFilterFogY</a>
      filter.
    </div></div></div></div></div><div class="st200_part_container"><div class="st200_part_title_number"><a id="st200_p3" href="#st200_p3">3</a></div><div class="st200_part_title">API Reference</div><ul class="st200_contents st200_part_contents_outer st200_part_contents"><li class="st200_contents_item st200_contents_item1 st200_contents_item_section"><a href="#st200_p3s1">3.1. Javadoc</a></li></ul><div class="st200_section_container"><div class="st200_section_title_number"><a id="st200_p3s1" href="#st200_p3s1">3.1</a></div><div class="st200_section_title">Javadoc</div><div class="st200_paragraph_container"><div class="st200_paragraph_number"><a id="st200_p3s1pg1" href="#st200_p3s1pg1">1</a></div><div class="st200_paragraph">
        API documentation for the package is provided via the
        included <a class="st200_link_external" href="apidocs">Javadoc</a>.
      </div></div></div></div><div class="st200_footnotes"><hr/><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_0" href="#st200_fn_0_ref">0</a>]</div><div class="st200_footnote_body">
                  All materials are immutable once created, but if a material
                  is recreated every frame with varying parameters, the material
                  becomes effectively dynamic.
                </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_1" href="#st200_fn_1_ref">1</a>]</div><div class="st200_footnote_body">
                Such as <span class="st200_term term">shaders</span>, 
                <span class="st200_term term">temporary framebuffers</span>,
                <span class="st200_term term">shadow maps</span>, etc.
              </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_2" href="#st200_fn_2_ref">2</a>]</div><div class="st200_footnote_body">
                    Such as the mesh shapes required to represent light volumes when
                    performing deferred rendering.
                  </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_3" href="#st200_fn_3_ref">3</a>]</div><div class="st200_footnote_body">
                  The renderer does define two brutally simple on-disk static
                  <span class="st200_term term">mesh</span> formats for the sake of convenience,
                  the test suite, and to store some of its own rendering resources
                  <span class="st200_footnote_reference"><a id="st200_fn_2_ref" href="#st200_fn_2">[2]</a></span>, and provides tools to convert to those formats from
                  <span class="st200_term term">COLLADA</span> documents, but the programmer
                  is absolutely not required to use them.
                </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_4" href="#st200_fn_4_ref">4</a>]</div><div class="st200_footnote_body">
            <a class="st200_link_external" href="http://semver.org">http://semver.org</a>
          </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_5" href="#st200_fn_5_ref">5</a>]</div><div class="st200_footnote_body">
          The <a class="st200_link_external" href="http://mvn.io7m.com/io7m-jspatial">jspatial</a>
          package is intended to provide exactly these sorts of data structures.
        </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_6" href="#st200_fn_6_ref">6</a>]</div><div class="st200_footnote_body">
        That is, each surface is rendered as if it was the only surface
        in the visible set. There are no light bounces between surfaces, and
        shadows are created by explicit shadow mapping, rather than occuring
        naturally as part of a physically accurate 
        <span class="st200_term term">global illumination</span> algorithm.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_7" href="#st200_fn_7_ref">7</a>]</div><div class="st200_footnote_body">
        The believability of this effect is obviously
        very scene-specific. Shadow mapping gives results that look
        much more physically accurate, at the cost of being much more
        computationally expensive.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_8" href="#st200_fn_8_ref">8</a>]</div><div class="st200_footnote_body">
        Almost all rendering systems use different names to refer to the same 
        concepts, without ever bothering to document their conventions. This
        harms comprehension and generally wastes everybody's time.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_9" href="#st200_fn_9_ref">9</a>]</div><div class="st200_footnote_body">
        See <a class="st200_link_external" href="http://mathfor3dgameprogramming.com">Mathematics
        for 3D Game Programming and Computer
        Graphics</a> 3rd Edition, section 4.3.1 for the
        derivation.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_10" href="#st200_fn_10_ref">10</a>]</div><div class="st200_footnote_body">
        Note that matrix multiplication is not commutative.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_11" href="#st200_fn_11_ref">11</a>]</div><div class="st200_footnote_body">
        The reason for producing the 
        concatenated matrix on the CPU and then passing it to the shader
        is efficiency; if a mesh had <span class="st200_term constant">1000</span>
        vertices, and the shader was passed <span class="st200_term expression">m</span>
        and <span class="st200_term expression">v</span> separately, the shader
        would repeatedly perform the same <span class="st200_term expression">mv = v * m</span>
        multiplication to produce <span class="st200_term expression">mv</span> 
        for each vertex - yielding the exact same 
        <span class="st200_term expression">mv</span> each time!
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_12" href="#st200_fn_12_ref">12</a>]</div><div class="st200_footnote_body">
        See section 4.5, "Transforming normal vectors".
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_13" href="#st200_fn_13_ref">13</a>]</div><div class="st200_footnote_body">
        Because <a class="st200_link" href="#st200_p2s3ss7">normalized device space</a>
        is a left-handed system by default, with the viewer looking towards
        positive Z, and because the transformation from
        <span class="st200_term term">clip space</span> to
        <span class="st200_term term">normalized device space</span> for
        a given point is the division of the components of that point
        by the point's own <span class="st200_term expression">w</span>
        component.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_14" href="#st200_fn_14_ref">14</a>]</div><div class="st200_footnote_body">
        The handedness of the coordinate space is dependent on the
        <a class="st200_link" href="#st200_p2s3ss8pg2">depth range</a>
        configured for <a class="st200_link" href="#st200_p2s3ss8">screen space</a>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_15" href="#st200_fn_15_ref">15</a>]</div><div class="st200_footnote_body">
        It is actually the division by <span class="st200_term expression">w</span> that
        produces the scaling effect necessary to produce the illusion of perspective
        in <span class="st200_term term">perspective projections</span>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_16" href="#st200_fn_16_ref">16</a>]</div><div class="st200_footnote_body">
      Of course, it may be that the programmer actually loads many more
      meshes during the lifetime of the application in question. This step
      is just included for the purposes of the process description.
    </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_17" href="#st200_fn_17_ref">17</a>]</div><div class="st200_footnote_body">
            The <span class="st200_term package">io7m-r1</span> package
            actually uses the <a class="st200_link_external" href="http://mvn.io7m.com/io7m-jparasol">Parasol</a>
            language internally to avoid the mentioned issues, but does not expose
            this to programmers using the package.
          </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_18" href="#st200_fn_18_ref">18</a>]</div><div class="st200_footnote_body">
            This has the advantage that, if a texture is procedurally generated
            by an external system, the texture can be cached and re-used by many
            different surfaces. This is obviously not possible in systems that
            do all of that work during the actual rendering of an object.
          </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_19" href="#st200_fn_19_ref">19</a>]</div><div class="st200_footnote_body">
        There is a tension in rendering systems between providing something that
        is restrictive but easy to use, and providing something that is so 
        generalized that it is capable of anything but barely any easier to use
        than using the OpenGL API directly.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_20" href="#st200_fn_20_ref">20</a>]</div><div class="st200_footnote_body">
        Please see <a class="st200_link_external" href="http://io7m.com/documents/types/ccat/">A Crash Course in Algebraic Types</a>,
        and more or less any software written in a typed functional languages for
        a description of the immense correctness and maintenance benefits that 
        algebraic data types provide.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_21" href="#st200_fn_21_ref">21</a>]</div><div class="st200_footnote_body">
        The reason for this is that, for example, many skeletal animation systems
        store extra information in each vertex about the bones that influence said vertex.
        If the package did not ignore this extra data, then programmers would be forced
        to allocate whole new meshes and copy out only the attributes given above.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_22" href="#st200_fn_22_ref">22</a>]</div><div class="st200_footnote_body">
        An intuitive way to think about transforms concatenated in this
        manner is that a transform <span class="st200_term emphasis">always occurs about the origin</span>.
        So, if a translation is applied first, and then a rotation is applied, the
        object will appear to orbit around the origin (because the rotation
        happens around the origin, and the translation moved it away from
        the origin first).
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_23" href="#st200_fn_23_ref">23</a>]</div><div class="st200_footnote_body">
          Which, for many applications, may be once for the entire lifetime of the program.
        </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_24" href="#st200_fn_24_ref">24</a>]</div><div class="st200_footnote_body">
        This step is performed once on the CPU and is only repeated when the projection
        matrix changes
        <span class="st200_footnote_reference"><a id="st200_fn_23_ref" href="#st200_fn_23">[23]</a></span>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_25" href="#st200_fn_25_ref">25</a>]</div><div class="st200_footnote_body">By simply setting 
      the <span class="st200_term variable">w</span> component to <span class="st200_term constant">1</span>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_26" href="#st200_fn_26_ref">26</a>]</div><div class="st200_footnote_body">
        Which is guaranteed to be negative, as only a negative Z value could have resulted in
        a visible fragment in the g-buffer.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_27" href="#st200_fn_27_ref">27</a>]</div><div class="st200_footnote_body">
        See <a class="st200_link_external" href="http://www.sjbaker.org/steve/omniv/love_your_z_buffer.html">Learning To Love Your Depth Buffer</a>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_28" href="#st200_fn_28_ref">28</a>]</div><div class="st200_footnote_body">
        Apparently first discovered by <a class="st200_link_external" href="http://outerra.blogspot.co.uk/2012/11/maximizing-depth-buffer-range-and.html">Brano Kemen</a>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_29" href="#st200_fn_29_ref">29</a>]</div><div class="st200_footnote_body">
        It is fairly widely acknowledged that there is no completely satisfactory
        solution to the problem of rendering intersecting translucent objects. The
        <span class="st200_term package">io7m-r1</span> package makes no
        attempt to solve the problem.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_30" href="#st200_fn_30_ref">30</a>]</div><div class="st200_footnote_body">
        See section 7.8.3, "Calculating tangent vectors".
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_31" href="#st200_fn_31_ref">31</a>]</div><div class="st200_footnote_body">
        The <span class="st200_term package">io7m-r1</span> package
        does not use ambient terms.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_32" href="#st200_fn_32_ref">32</a>]</div><div class="st200_footnote_body">
        Note: Specifically <span class="st200_term term">Phong reflection</span> 
        and not the more commonly used 
        <a class="st200_link_external" href="http://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_shading_model">Blinn-Phong reflection</a>.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_33" href="#st200_fn_33_ref">33</a>]</div><div class="st200_footnote_body">
        The attenuation function development is available for experimentation
        in the included <a class="st200_link_external" href="http://geogebra.org">GeoGebra</a>
        file [<a class="st200_link_external" href="attenuation.ggb">attenuation.ggb</a>].
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_34" href="#st200_fn_34_ref">34</a>]</div><div class="st200_footnote_body">
        The same issue occurs when performing ordinary rendering of points in a scene. The
        issue is solved there by clipping primitives based on their
        <span class="st200_term expression">w</span> component so that primitives that are
        "behind" the observer are not rendered.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_35" href="#st200_fn_35_ref">35</a>]</div><div class="st200_footnote_body">
        In other words, the cache tries to keep itself to a given
        maximum size, but is permitted to overstep these bounds if asked: A
        scene that has <span class="st200_term expression">100</span> shadow
        casting lights requires <span class="st200_term expression">100</span>
        pre-populated shadow maps, regardless of whether or not this would
        exceed the stated maximum cache size.
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_36" href="#st200_fn_36_ref">36</a>]</div><div class="st200_footnote_body">
        <a class="st200_link_external" href="http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf">http://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf</a>
      </div></div><div class="st200_footnote_container"><div class="st200_footnote_number">[<a id="st200_fn_37" href="#st200_fn_37_ref">37</a>]</div><div class="st200_footnote_body">
        The included <span class="st200_term file">Fxaa3_11.h</span> file bears an NVIDIA
        copyright, but was placed into the public domain by the original author.
      </div></div></div></div></body></html>
